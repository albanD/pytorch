9b27e0926b,skip,new_features,Add callgrind collection to Timer (#44717)
7566823779,jit,new_features,Enable PE + TE (#45546)
e02868e12d,cpp_frontend,bug_fixes,Unify Transformer coder Constructors (#45515)
96540e918c,dataloader_frontend,new_features,Add ShuffleDataset with buffer (#45290)
7e863475d7,skip,Untopiced,Upgrade ReadMe document to guide user to install libuv(1.39) in conda env on Windows platform (#45553)
415ed434aa,skip,Untopiced,Add whitelist for complex backward (#45461)
939e0389de,foreach_frontend,improvements,Update test_multi_tensor_optimizers test (#45510)
4f3920951e,python_frontend,devs,type check for torch.quantization.quantize_jit (#45548)
6c4aa2a79c,skip,Untopiced,Revert D24002415: Some fixes to smooth_l1_loss
51d0ae9207,skip,Untopiced,Revert D24010742: [pytorch][PR] Add callgrind collection to Timer
5539066d12,fx,new_features,[quant][graphmode][fx] Support quantization for custom module (#44074)
a245dd4317,caffe2,Untopiced,add dllexport before template specialization functions for windows build (#45477)
ce9df084d5,python_frontend,improvements,"[pytorch] Replace ""blacklist"" in test/test_mobile_optimizer.py (#45512)"
c112e89cc6,quantization,Untopiced,[quant] Make choose_qparams_optimized return Tensors to preserve dtype (#45530)
181afd5220,distributed,improvements,Add an option to DDP to take a list of parameters to ignore upfront. (#44826)
c9bb990707,cpp_frontend,new_features,[c++] Distance-agnostic triplet margin loss (#45377)
ffd50b8220,build_frontend,bug_fixes,SET USE_DISTRIBUTED OFF when libuv is not installed (#45554)
ac9a708ed0,skip,Untopiced,[FX] Shape propagation example (#45589)
6b42ca2d69,onnx,improvements,[ONNX] Update embedding_bag export (#44693)
2596113a79,python_frontend,improvements,Add fuse support for batchnorm with affine=False (#45474)
56840f0a81,caffe2,Untopiced,Prevent overflow in bucketize binary search
85a70ce71f,jit,improvements,Add multiline string dedent support (#45580)
4be42034b6,quantization,bug_fixes,Clear shape information before finalizing graph-mode quantization (#45282)
6fde2df1b8,jit,devs,[JIT] Update JIT triage project board workflow (#45613)
f2c2b75e80,jit,improvements,flush the buffer when printing the IR (#45585)
869b05648d,skip,Untopiced,Revert D24024606: [FX] Shape propagation example
0b3ad5404a,quantization,devs,[bot] Add quantization triage bot script (#45622)
3a2d45304d,distributed,new_features,[Experimental][Partial] New implementation for torch.distributed APIs in C++ (#45547)
2b13d9413e,benchmark,new_features,Re-land: Add callgrind collection to Timer #44717 (#45586)
9d5607fcd9,quantization,Untopiced,[quant] Use PlaceholderObserver as default dynamic quant observer (#45343)
75fc263579,jit,docs,[TensorExpr] Add a tensor expressions tutorial. (#45527)
3f440d74fc,mobile,new_features,[PyTorch][QPL] Add instance_key into MOBILE_MODULE_STATS logging. (#45517)
ffcb0989e7,skip,Untopiced,[quant][graphmode][fx] Merge all quantization mode (#45292)
d306d0c2b1,skip,Untopiced,remove redundant PE(profiling executor) jobs in CI (#45397)
4339f5c076,mobile,Untopiced,[PyTorch][QPL] Add instance_key into MOBILE_MODULE_LOAD_STATS logging. (#45518)
78b95b6204,fx,docs,"Revert ""Revert D24024606: [FX] Shape propagation example"" (#45637)"
c36b354072,skip,Untopiced,Revert D23913105: [quant][graphmode][fx] Merge all quantization mode
592b398e82,skip,Untopiced,[AutoAccept][Codemod][FBSourceGoogleJavaFormatLinter] Daily `arc lint --take GOOGLEJAVAFORMAT`
84cf3372d1,skip,Untopiced,[AutoAccept][Codemod][FBSourceClangFormatLinter] Daily `arc lint --take CLANGFORMAT`
72bc3d9de4,cuda,new_features,"Use MTA for amp grad unscaling, enforce op math type in MTA functors, and allow op lambdas (#44778)"
a242ac8c27,skip,Untopiced,Update torchvision version to current latest master (#45342)
41bd5a5ee0,skip,Untopiced,Switch all Sequences in tools.codegen.model to Tuple (#45127)
4583edb5d6,skip,Untopiced,Add NativeFunction.signature and kind. (#45131)
77cd8e006b,complex_frontend,new_features,Added support for complex torch.symeig (#45121)
1efdbfabcc,python_frontend,docs,[docs] Fix back quote rendering in loss modules docs (#45662)
381f6d32a7,python_frontend,docs,[docs] Fix hyperlinks for nn.CrossEntropyLoss (#45660)
03e4e94d24,fx,improvements,Find single partition (#45429)
4564444c91,caffe2,Untopiced,[RFC][caffe2] TaskGroup.__repr__ shouldn't have side effects
93be03cec0,quantization,bug_fixes,[quant] torch.mean add path for unsupported QNNPACK modes (#45533)
5959de3aeb,build_frontend,bug_fixes,setup: Only include dataclasses for py < 3.8 (#45611)
18253f4a48,caffe2,Untopiced,Fix BUILD_CAFFE2 if FBGEMM and NNPACK are not built (#45610)
4f685ecc25,fx,new_features,[reland][quant][graphmode][fx] Merge all quantization mode (#45292) (#45672)
de3a48013a,autograd_frontend,bug_fixes,Use CAFFE2_USE_MSVC_STATIC_RUNTIME to determine when to avoid waiting for global destructors on Windows (#43532)
e8e0fca99e,skip,Untopiced,[iOS][CI] Update the dev cert (#45651)
0de5824f36,skip,Untopiced,[iOS][CI] Upgrade xcode version to 12.0 (#45677)
0393a1e8b9,jit,improvements,add an indexer to SymbolicShape (#45450)
cbdba7cc1e,jit,improvements,win job for the legacy executor (#45612)
4c1e50eb5c,jit,bug_fixes,remove skip annotations since we already disabled the tests wholesale (#45698)
fc4209bd4f,skip,Untopiced,Fix the bucketization wrong doc for right argument (#45684)
a015ba8dd5,dispatcher,improvements,migrating the take() fn from TH to ATen (#45283)
1552a926a3,dispatcher,improvements,migrate cuda implementation of take() from TH to ATen (#45430)
f6dc256bc6,fx,docs,example of splitting up an FX graph into smaller subgraphs with own submodules (#45404)
36de05dbf6,skip,Untopiced,"passing all arguments to sccache wrapper script should be quoted as ""$@"" (#45582)"
402caaeba5,python_frontend,docs,[docs] Update docs for NegativeBinomial (#45693)
a0d08b2199,jit,improvements,Set the default bailout depth to 20 (#45710)
04526a49d3,quantization,new_features,[quant] creating quint4x2 dtype for quantized tensors (#44678)
1a2d3b6a75,quantization,new_features,[quant] PerChannelFloatQParams support for quint4x2 dtype (#45594)
9201c37d02,performance_as_product,improvements,Use addmm directly for 1x1 convolution (#45557)
6e2eee2b9d,dispatcher,improvements,Add faithful C++ API (#44087)
82cc86b64c,dispatcher,improvements,VariableKernel calls into scattered C++ api (#44158)
c703602e17,python_frontend,docs,make broadcasting explanation clearer in matmul doc: #22763 (#45699)
869b2ca048,python_frontend,docs,some documentation and style fixes to smooth_l1_loss (#45587)
4d08930ccb,python_frontend,improvements,remove beta defaulting in smooth_l1_loss_backward. added to the bc whitelist (#45588)
888f3c12e7,skip,Untopiced,Test torch.svd using complex float and double numbers (#45572)
24187a0b42,quantization,improvements,Enable type check for torch.quantization.fake_quantize (#45701)
ad31068fe9,skip,Untopiced,Add a distributed package reviewer (#45744)
b234acd414,caffe2,Untopiced,Exposes SparseToDenseMask Caffe2 Operator (#45670)
cdf93b03de,jit,improvements,Add string versions of argument funcs in jit Node (#45464)
6e43f0db8b,distributed,devs,Use correct signatures for METH_NOARGS. (#45528)
a052597e6c,skip,Untopiced,Bump nightlies to 1.8.0 (#45696)
3799ba83e5,distributed,docs,[Docs] Adding Store API Docs (#45543)
6acd7b686c,skip,Untopiced,adding sharding option to run_test.py (#45583)
7726754e70,python_frontend,docs,Add function signature for pixel_shuffle (#45661)
db8b076272,python_frontend,docs,Change signature for torch.poisson (#45656)
322855e380,quantization,improvements,type check for torch.quantization.observer (#45630)
f8c1ca5dd8,distributed,improvements,Enable NamedTuple data type to work with DDP (#44220)
5a47a2126d,skip,Untopiced,Revert D24018160: [pytorch][PR] Test torch.svd using complex float and double numbers
e3d2defdc8,skip,Untopiced,[te] Get llvm codegen to compile with llvm9 and llvm-fb (#45726)
7d809f5d8e,skip,Untopiced,Update backward definition for more operators and reenable tests in test_ops.py (#44444)
c31066ac9d,caffe2,Untopiced,Torch Integration Test Formatting Changes (#45740)
73e9daa35f,caffe2,Untopiced,[caffe2] Optimize Dedup version of RowWiseSparseAdagrad fused op by WarpReduce (#45649)
d150d3e276,jit,improvements,Make sure each warnings.warn only executes once inside TorchScript. (#45382)
8cb7280242,skip,Untopiced,"Revert ""Remove device maps from TensorPipe for v1.7 release (#45353)"" (#45762)"
2fa062002e,cpp_frontend,new_features,CUDA BFloat16 infrastructure (#44925)
53aea60bce,fx,improvements,[FX] Make output a non-special Node (#45599)
31621c828d,jit,bug_fixes,Fix JIT tests when run locally in fbcode (#45776)
546aab66c1,skip,Untopiced,Revert D24027761: Update backward definition for more operators and reenable tests in test_ops.py
2b48dd168d,jit,improvements,[StaticRuntime] Integrate Static Runtime into PyTorchPredictor (#45640)
d8a9c2c27e,skip,Untopiced,[iOS][CI] Fix the timeout for nightlies (#45798)
3a27fc966a,complex_frontend,improvements,Test torch.svd using complex float and double numbers (take 2) (#45795)
ff568a0e6b,skip,Untopiced,Revert D24072697: [te] Get llvm codegen to compile with llvm9 and llvm-fb
24fa2daea6,jit,improvements,Revert D24100389: Revert D24072697: [te] Get llvm codegen to compile with llvm9 and llvm-fb
8a6b919163,jit,bug_fixes,[StaticRuntime] Fix broken tests (#45813)
2ab74a4839,fx,improvements,[FX] Make Tracer.trace() just return a Graph (#45704)
e1ff46b6e5,cuda,new_features,CUDA BFloat16 TopK (#44755)
f65ab89edd,python_frontend,new_features,[numpy] Add torch.nan_to_num (#44592)
e829d4fba9,benchmark,bug_fixes,[op-bench] fix jit mode (#45774)
3ab88c3903,jit,new_features,Enable TorchBind tests on ROCm (#45426)
162717e527,skip,Untopiced,grammatically update index.rst (#45801)
cf48872d28,caffe2,Untopiced,[C2] Add string equality operator
adc21c6db2,jit,improvements,Rename jobs and cli switches for testing GraphExecutor configurations to something a little bit more sensical. (#45715)
ffbffc0436,autograd_frontend,docs,fixed formatting in function rstrings in torch.autograd.functional (#45849)
14e6e50700,skip,Untopiced,Refactor computeLRWorkDim (#45812)
21fa877026,quantization,improvements,[quant][test] Remove numeric equivalence test for debug and non-debug option (#45852)
c80ec91b00,skip,Untopiced,[iOS] Bump up the cocoapods version (#45862)
a83696ad53,quantization,docs,quant docs: add API summary section (#45848)
9f4abcad9d,skip,Untopiced,Automated submodule update: FBGEMM (#45713)
f11f9a8c1f,python_frontend,improvements,[pytorch][improvement] Improve torch logging to identify problematic key (#45766)
9a668f94bb,jit,improvements,[jit] allow slicing multiple dimensions with indicies (#45239)
519c086418,caffe2,Untopiced,Revert D24042344: [C2] Add string equality operator
f18cc9c57d,jit,improvements,Change type inferred from empty annotation (#45360)
5177f8de2b,skip,Untopiced,Revert D23398534: [pytorch][PR] [ONNX] Improve error handling for adaptive_pool
26a9012f84,fx,improvements,[fx] import used modules for code gen (#45471)
78f055272c,python_frontend,docs,[docs] Add 3D reduction example to tensordot docs (#45697)
4ab73c1f74,python_frontend,docs,[docs] Fix EmbeddingBag docs (#45763)
54aaffb7c7,autograd_frontend,bug_fixes,Avoid NaN values in torch.cdist backward for p<1 (#45720)
1558a3657b,cuda,new_features,Add LazyNVRTC (#45674)
b04ae953b4,fx,new_features,[FX][WIP] Mutable Graph APIs (#45227)
59083d6176,distributed,new_features,[NCCL] Support NCCL Send/Recv (#44921)
10d86d1196,distributed,new_features,[NCCL] create NCCL communicator for send/recv on demand (#44922)
bf85642c4c,autograd_frontend,bug_fixes,Remove lock from GraphTask::set_exception_without_signal. (#45867)
7eb0a71484,skip,Untopiced,update persons of interest (#45803)
e4efc420ae,python_frontend,docs,Correct `Categorical` docstring (#45804)
d44eaf63d1,python_frontend,new_features,torch.fft helper functions (#44877)
2fbe5971b3,skip,Untopiced,[pytorch/cuda] apply 16-bit mask to the index for device guard registry (#45485)
8a1e100466,skip,Untopiced,Stricter backward compatibility check (#45773)
8bc0c755be,skip,Untopiced,adding option to move excluding to run_test.py instead of test.sh (#45868)
67889db8aa,build_frontend,docs,Replaced BLACKLIST with BLOCKLIST (#45781)
be137e45cd,skip,Untopiced,reorganizing tests so that test1 and test2 are balanced in timing (#45778)
b1373a74e0,cuda,improvements,Don't export enums for CUDA sources on Windows (#45829)
a09e1098e7,mobile,new_features,Profiling allocator for mobile. (#43951)
9728584cca,skip,Untopiced,Replaced whitelist with allowlist (#45796)
abedd9a274,jit,bug_fixes,Reduce size of test_unsqueeze to resolve consistent timeout issue (#45877)
3510f19c5f,skip,Untopiced,added some more details + debugging steps to CONTRIBUTING.md (#45903)
001a7998b4,skip,Untopiced,Disabling XNNPACK integration test in tsan mode (#45850)
d1fc1555d4,quantization,new_features,[quant] Add quantized::leaky_relu that takes scale/zero_point as input (#45702)
930bddd403,skip,Untopiced,Cleanup nccl.cpp (#45899)
8b7ee33ee6,quantization,new_features,[quant] Add quantized LeakyReLU module (#45711)
ba642d36ff,python_frontend,improvements,ReplicationPad accepts 0-dim batch size. (#39137)
fcc7f272de,cuda,bug_fixes,maximum number of threads per block for sm_86 is 1536 (#45889)
fb50fcaa82,caffe2,Untopiced,[C2] Add string equality operator (#45886)
0da6730f02,fx,new_features,[quant][graphmode][fx][eagermode] Add leaky relu support in quantization workflows (#45712)
64681d6bec,distributed,improvements,Add all remaining method declarations from torch.distributed Python API to C++ (#45768)
3fbddb92b1,caffe2,Untopiced,caffe2/plan_executor: wait for 1 minute after exception and then abort (#45297)
c1af91a13a,caffe2,Untopiced,[caffe2] SliceOp axes indexing fixes. (#45432)
a69a78daa2,foreach_frontend,improvements,Use smaller N to speed up TestForeach (#45785)
e154b36685,python_frontend,bc_breaking,Standardized clamp kernels to Numpy-like implementation (#43288)
a3662fa78c,autograd_frontend,improvements,Minor gradcheck update to reduce computations (#45757)
255b0e839f,cuda,docs,C++ APIs CUDA Stream Note (Set/Get part) (#45754)
5072728d88,jit,improvements,Fix stride printing/parsing formatting (#45156)
14997f2125,fx,improvements,[quant][graphmode][fx] Add warning for unsupported case (#45714)
5ff31620b7,jit,improvements,[te] Add a 2D convolution example test (#45514)
50f89578dd,jit,improvements,[te] Add a benchmark harness (#45875)
f2e569461b,jit,improvements,[te] Tiled (m=32 x n=32) gemm benchmark (#45905)
624084e6d6,jit,improvements,[te][llvm] Enable fused multiply-add (fma) in code generation (#45906)
f5e70a7504,skip,Untopiced,fix test flakiness caused by sys.getrefcount(None) (#45876)
49af421143,benchmark,improvements,Embed callgrind headers (#45914)
4fdba30500,jit,new_features,[JIT] Add API for ignoring arbitrary module attributes (#45262)
e8d8de32b4,jit,new_features,[StaticRuntime] Implement StaticRuntime::benchmark (#45639)
5c283fa292,quantization,new_features,[quant] Add 4-bit embedding_bag prepack/unpack support using quint4x2 (#45751)
11c32611d7,quantization,improvements,[quant] Support 4-bit embedding_bag operators using the dtype quint4x2 (#45752)
43dc7ef933,quantization,improvements,[quant] Support for 4-bit quantized EmbeddingBag module (#45865)
1b31ed3ad6,quantization,improvements,[quant] Refactor qembeddingbag to remove duplicate code (#45881)
8b39498a23,dispatcher,devs,codegen: Allow string arguments to have defaults (#45665)
ed1552a48f,python_frontend,docs,Add note about in-place weight modification for nn.Embedding (#45595)
317b6516bc,quantization,improvements,[quant] Add quantized::sigmoid that take output_scale/output_zero_point as input (#45882)
205ab49612,package,improvements,[packaging] simpler dependency plotting (#45686)
8cdb638c62,fx,new_features,[FX] Track use nodes in Node (#45775)
be45c3401a,jit,improvements,[JIT] Make objects throw Python AttributeError on nonexistant attr access (#45911)
bb99bea774,build_frontend,devs,Compress NVCC flags for Windows (#45842)
5640b79bf8,cuda,improvements,Allow consumer ops to sync on GraphRoot's gradient (#45787)
1bb2d41b68,skip,Untopiced,Revert D20850851: caffe2/plan_executor: wait for 1 minute after exception and then abort
5ce31b6f3f,onnx,improvements,[ONNX] Improve error handling for adaptive_pool (#45874)
5a2773702f,skip,Untopiced,add test sharding to CUDA on linux (#45972)
b186831c08,skip,Untopiced,Automatic update of fbcode/foxi to 6a4e19a2aaf7ae4b9fa9597526e65b395d5e79ad (#45951)
30bf799f9c,python_frontend,docs,`torch.matrix_exp` doc fix (#45909)
83d2c9a232,quantization,new_features,[quant] Add quantized Sigmoid module (#45883)
8fb32b9f55,skip,Untopiced,Parametrize # of longest tests in print_test_stats (#45941)
c8d76ff7dc,skip,Untopiced,Improve logging in ProcessGroupNCCL for debugging purposes. (#45780)
0927e02a6a,caffe2,Untopiced,[caffe2] Do not run RemoveOpsByType on recurrent networks (#45986)
ce82b522c8,dataloader_frontend,improvements,Define objects using classes instead of namedtuples in torch.utils.data._utils.worker (#45870)
de0d0bd5ee,skip,Untopiced,Revert D24093032: Improve logging in ProcessGroupNCCL for debugging purposes.
72e4f51bc0,jit,bug_fixes,[JIT] fix dict update (#45857)
c86655a815,jit,bug_fixes,[JIT] Fix Dict bug in constant hashing (#45929)
a36f11a3a5,caffe2,Untopiced,[FakeLowP] T76913842 Make AddFakeFp16 take int inputs (#45992)
19da1d22fe,jit,new_features,"[NNC] Registerizer V2, supporting partial and conditional replacement (#45574)"
154347d82f,distributed,docs,Fix distributed documentation for asynchronous collective Work objects (#45709)
903acc6b83,cuda,improvements,"CUDA BFloat16 support of clamp, remainder, lshift, rshift (#45247)"
c59c4b0d77,skip,Untopiced,Fix cholesky TF32 tests (#45492)
81d40aaf96,skip,Untopiced,Add `[zc]heevd` to the list of MKL symbols exported from torch_cpu (#46002)
00b8ebe60c,fx,new_features,[FX] Preserve type annotations on generated code in Graph (#45880)
8d14b50e94,skip,Untopiced,codegen: Improve array default handing (#45163)
ef4817fe5a,python_frontend,new_features,"Add `tensor_split` function, based on `numpy.array_split` (#45168)"
c19b9cd18d,distributed,new_features,Add torch::cuda::ncll::all2all (#45900)
99d3f37bd4,autograd_frontend,improvements,Run gradgradcheck on torch.fft transforms (#46004)
a92b49f7c8,caffe2,Untopiced,[Onnxifi] Don't throw exception when we cannot write out debug files (#45979)
c9caa828f5,skip,Untopiced,Throw special exception when backend compilation is met with fatal error (#45952)
b65ffa365c,jit,devs,[TensorExpr] Nuke `Function` class and directly use `Tensor` instead. (#45936)
598caddd93,jit,improvements,"[TensorExpr] Add shorthand versions for `splitWith{Mask,Tail}` functions. (#45946)"
29da553dd9,jit,improvements,[TensorExpr] Loopnest: unify intermediate_tensors_ and temp_bufs_. (#45947)
1036b77416,jit,improvements,[TensorExpr] LoopNest: replace output_tensors_ with output_bufs_. (#45948)
6e4de44501,jit,improvements,[TensorExpr] LoopNest: add a constructor that takes Stmt instead of list of Tensors. (#45949)
9dc9a55bc4,jit,bug_fixes,Fix TypeError when torch.jit.load is passed a pathlib.Path (#45825)
d93cae00f2,skip,Untopiced,[HTE @ clang-tidy] Enable clang-tidy configs inheretence for caffe2 project
52f2db752d,python_frontend,docs,unify reproducibility notes (#45748)
acca11b898,jit,bug_fixes,[torchscript] Verbose logging of code location causing the error (#45908)
7d4f5060ad,benchmark,docs,Fix doc about operator benchmark (#45853)
735d5b8907,complex_frontend,new_features,Add complex32 dtype support to CPU/GPU implementation of (#45339)
ea4fbb2e5e,jit,improvements,[StaticRuntime] Replace hashtable based workspace with vector<IValue> (#45892)
283ae1998c,skip,Untopiced,Pin libuv to 1.39 in Windows CI in order to keep version alignment in read me document (#46015)
40828b68e1,skip,Untopiced,Revert D24099167: [HTE @ clang-tidy] Enable clang-tidy configs inheretence for caffe2 project
d3d8da7a8e,cuda,new_features,Enable CUDA Fuser for ROCm (#45965)
d360402f34,skip,Untopiced,"Use out variants of functions used by linalg.norm, where possible (#45641)"
298e0e0d57,caffe2,Untopiced,Refactor gather_ranges_to_dense from Python to C++ (#46021)
636eb18029,python_frontend,new_features,Fixed median nan propagation and implemented nanmedian (#45847)
1b97ffa07a,jit,bug_fixes,[1/3] [JIT] Make sure fusion occurs in test_tensorexpr file (#45788)
564296f051,jit,improvements,[2/3] [JIT] Make sure fusion occurs in test_tensorexpr (#45789)
338283057b,jit,improvements,[JIT] [3/3] Make sure fusion occurs in test_tensorexpr (#45790)
1197a38a63,jit,new_features,[JIT] Bind log1p and lgamma (#45791)
5f7545adf6,skip,Untopiced,Update randomtemp to v0.3 (#46025)
f010df35e5,complex_frontend,new_features,Added CUDA support for complex input for QR decomposition (#45032)
8e8fb8542e,skip,Untopiced,upgrade clang-tidy to 11 (#46043)
402abdfdf4,jit,improvements,[NNC] cacheAccesses transform (cache_reads + cache_writes) (#45869)
59e4803b94,caffe2,Untopiced,Recommit: caffe2/plan_executor: wait for 1 minute after exception and then abort (#45981)
ddcacc736d,skip,Untopiced,Do not rebase select nighly builds on top of master (#46038)
64b0686986,caffe2,Untopiced,Expose ChannelShuffle (#46000)
0cf0b5f2e8,skip,Untopiced,Minor refactor to normalize assignments (#45671)
8c80ee8ba5,quantization,improvements,[quant] Set sparse to False for embedding_bag ops in graph mode (#45997)
31888b2e77,quantization,improvements,[quant][pyper] Rename the sparse argument for embedding_bag ops (#46003)
c6672a608b,caffe2,Untopiced,caffe2 missing cctype header (#46052)
2b204e6db3,fx,improvements,[quant][fx][graphmode] Run symbolic_trace in quantization (#45919)
c86ee082a2,python_frontend,docs,torch.fft: Add helper functions section to docs (#46032)
96d48178c8,distributed,improvements,Make pipeWrite and pipeRead noexcept (#45783)
b7f7378b2d,distributed,improvements,[NCCL] support send/recv to/from self when communicator is created on demand (#45873)
8cd3857bc7,cuda,improvements,[NCCL] Add torch::cuda::nccl::send/recv (#45926)
487624e369,caffe2,Untopiced,[caffe2] plan executor error propagation test with blocking cancellable op (#45319)
f363a2e106,skip,Untopiced,Mark top 3 slowest tests as slow (#46068)
0983ddbfd2,skip,Untopiced,add sharding option to test framework (#45988)
87226f72d2,caffe2,Untopiced,[caffe2] temp remove ErrorPlanWithCancellableStuckNet (#46080)
a5c0dbc519,jit,new_features,Add support for Softmax. (#45286)
c734961e26,python_frontend,improvements,[cpp-extensions] Ensure default extra_compile_args (#45956)
9443033e71,skip,Untopiced,Automated submodule update: FBGEMM (#46079)
9fb8e33a5b,skip,Untopiced,[AutoAccept][Codemod][FBSourceClangFormatLinter] Daily `arc lint --take CLANGFORMAT`
c83314e982,distributed,improvements,[ci-all tests] Improve logging in ProcessGroupNCCL for debugging purposes. (#46010)
59414b359d,python_frontend,docs,Document fix for logspace and linspace (#46056)
f8b3af21f2,python_frontend,new_features,Allow Tensor-likes in torch.autograd.gradcheck (#45732)
0ddcc0ce35,dispatcher,devs,Add alias dispatch key DefaultBackend. (#45718)
da033e0b2d,caffe2,Untopiced,[Caffe2] use new fbgemm sparse adagrad interface with temp name (#46089)
3ffd2af8cd,distributed,improvements,Add exception classification to torch.multiprocessing.spawn (#45174)
281463ba0b,distributed,improvements,[NCCL] Enable send/recv tests (#45994)
2fa91fa305,jit,bug_fixes,[NNC] Fix crash when simplifying certain subtractions (#46108)
e33d455ef7,distributed,devs,[Distributed] Set smaller Store timeouts to make c10d tests run faster (#46067)
d811d4d7ba,dispatcher,devs,Support DefaultBackend keyword in native_functions.yaml. (#45719)
c73af6040e,fx,improvements,[FX] Make `graph_copy` examine existing values in val_map (#46104)
7094c09ff7,quantization,improvements,quantizaton: add API usage logging (#46095)
172036a565,distributed,improvements,[NCCL] Add Error log when ProcessGroupNCCL takes down process upon (#44988)
34951e9adc,caffe2,Untopiced,[shape inference] adding a new flag to the struct
5e4b3dd25a,skip,Untopiced,Automated submodule update: FBGEMM (#46125)
689499ffa8,build_frontend,improvements,remove duplicate autograd srcs (#46059)
43fe45ab0f,benchmark,new_features,[JIT] Add dynamic shape benchmark for NV Fuser (#46107)
b7261de0df,jit,improvements,[pytorch][te] Add compilation time benchmark (#46124)
9f743015bf,dispatcher,docs,a few more comments on dispatch key computation methods (#46128)
4c87d337af,caffe2,Untopiced,[Caffe2] use the real new fbgemm sparse adagrad interface (#46132)
496d72d700,jit,bug_fixes,[TensorExpr] Disable and/or fix some failing tests. (#46146)
a0a8bc8870,python_frontend,docs,Fix mistakes and increase clarity of norm documentation (#42696)
bbb3f09377,skip,Untopiced,Automated submodule update: FBGEMM (#46151)
1a99689d71,caffe2,Untopiced,[caffe2] Fix preprocessor checks for FMA
3883cdb87e,caffe2,Untopiced,TensorInferenceFunction checks
e1f74b1813,skip,Untopiced,Fix mkldnn build on legacy x64 arch (#46082)
6ba6ecb048,dispatcher,improvements,Only use hacky_wrapper_for_legacy_signatures if an op needs it (#45742)
6a001decf2,quantization,new_features,[quant][test] Add mul_scalar test (#46106)
146721f1df,python_frontend,docs,Fix typing errors in the torch.distributions module (#45689)
9202c44379,python_frontend,bug_fixes,Fix error in Binomial to retain lazy logit initialization (#46055)
8d5256e6dd,python_frontend,improvements,Made exception message for torch.LongTensor() legacy constructor more readable (#46147)
85c3ba5588,caffe2,Untopiced,[caffe2] add PlanExecutorTest ErrorPlanWithCancellableStuckNet (#46110)
ba78eb80ff,skip,Untopiced,including tensorexpr tests in CI for all configs (#46188)
8de9aa196a,skip,Untopiced,clean up dataclasses installation to only <3.7 (#46182)
c02efdefa8,complex_frontend,new_features,adding complex support for distributed functions and . fix #45760 (#45879)
b98e35948f,skip,Untopiced,fix test_serialization not working with Windows. (#46120)
bed3b40523,python_frontend,new_features,Implement ravel (#46098)
87a4baf616,quantization,new_features,[pt][quant] Support either min or max in qclamp (#45937)
ee3d3e6dba,distributed,new_features,[pytorch][PR][Gradient Compression] Reduce the peak memory of fp16 compression provided by ddp comm hook (#46078)
31ee5d8d8b,dataloader_frontend,docs,Adding information how to control randomness with DataLoader (#45749)
88dcb95e22,fx,improvements,[fx] use a linked list for nodes (#45708)
66505b64a5,cuda,bug_fixes,Fix incorrect CUDA `torch.nn.Embedding` result when max_norm is not None and indices are not sorted (#45248)
4ad4715643,skip,Untopiced,Fix JIT test config (#46230)
ba1e0a88bb,skip,Untopiced,Use const-references in nodes_to_rewrite range loop
1f9ddf64d2,skip,Untopiced,Update native_functions.yaml to add DefaultBackend. (#45938)
e6d30c89c1,skip,Untopiced,Revert D24165889: Update native_functions.yaml to add DefaultBackend.
7f6a1b2bd5,fx,new_features,[quant][fx][graphmode][api] Change API for custom module (#45920)
a277c097ac,mobile,new_features,[iOS][GPU] Add Metal/MPSCNN support on iOS (#46112)
a3caa719af,python_frontend,new_features,fix #45552 - adding add_done_callback(fn) to torch.futures.Future (#45675)
9079aea1ac,dispatcher,devs,Rewrite implementation of faithful cpp signatures (#45890)
944eb0e31d,skip,Untopiced,Add NativeFunctionGroup (#45918)
527a8bee02,dispatcher,devs,Reorder dispatcher/legacy_dispatcher types (#45973)
8d5c899b19,dispatcher,devs,Rename legacy_dispatcher to native. (#45974)
f086032676,dispatcher,improvements,Remove unnecessary byte-for-byte compatibility code that is not needed. (#45975)
d705083c2b,dispatcher,devs,Refactor dispatcher and native to use Signature structure. (#45990)
5741de883a,cuda,new_features,Define the record_stream method in native_functions.yaml (#44301)
1a57b390e8,foreach_frontend,new_features,"Add torch._foreach_maximum(TensorList, TensorList) & torch._foreach_minimum(TensorList, TensorList) APIs (#45692)"
ad376f1a62,python_frontend,bug_fixes,trying to make pow work for tensor raised to the power of a scalar (#46185)
faa9c22a51,skip,Untopiced,Support pytest for distribution testing (#45648)
5604997b09,quantization,devs,[quant][refactor] Alphabetize the entries in the quantized import (#46218)
fc846db667,skip,Untopiced,.circleci: Fix android publish snapshot job (#46266)
7b7f2519d9,python_frontend,improvements,Use storage.cpu() for moving storage to CPU in serialization. (#46028)
95ccf34fb9,quantization,bug_fixes,[quant][graph][fix] Set type for GetAttr nodes in remapTypes (#46250)
dac680721c,skip,Untopiced,Automated submodule update: FBGEMM (#46271)
67a0c0af27,quantization,new_features,[quant][fx][graphmode] Add prepare_custom_config_dict and convert_custom_config_dict (#46223)
a37f2749cd,dispatcher,performance,Avoid computing AutogradKey if not needed. (#46252)
1c3e335c4b,quantization,performance,[pytorch][glow][NNPI] Using int32 as indices for embedding_bag operators (#45878)
2118d58d45,skip,Untopiced,Add some more docs to expecttest. (#46263)
5c67cc7a9e,caffe2,Untopiced,[caffe2] Enable fp16 for SparseNormalize op (#45551)
6ef41953e6,skip,Untopiced,[RFC] Generate generated_unboxing_wrappers_everything.cpp for unboxing wrappers codegen to aid debugging (#45872)
b1d24dded1,benchmark,new_features,make a way to disable callgrind (#46116)
952dc7ed87,distributed,bug_fixes,[NCCL] Fix Hang in Async Error Handling due to Work logging (#46265)
e1c9aa918a,jit,devs,Reformat ivalue_inl.h and ivalue.h (#46174)
f89498f3f8,distributed,new_features,Allow RPC framework to use rank in addition to WorkerInfo and name. (#46221)
1fcec6e72b,caffe2,Untopiced,[caffe2] Add operator schema for FP16SparseNorm (#46300)
173363f31a,quantization,improvements,Use tensor's quantized properties directly in pickler (#46267)
ac3f23deb0,cpp_frontend,bug_fixes,Fixed usage of std::move function (#46199)
09842a44fa,fx,improvements,[FX] Allow tracing free functions (#46268)
31bcd96395,quantization,performance,Parallelize the quantization conversion operators (#45536)
f7398759b4,distributed,improvements,Only populate grad accumulator to var mapping for find_unused_parameters=True in DDP (#45942)
965046c445,distributed,improvements,[NCCL] Provide additional information about NCCL error codes. (#45950)
61df99b78e,skip,Untopiced,[fx] make sure args/kwargs are immutable (#46121)
d22455128f,dispatcher,improvements,[dispatcher] avoid autograd fixup step on non-backend keys (#46135)
d790ec6de0,jit,docs,[JIT] Update comment in jit_log.h. (#46301)
38e64cf949,skip,Untopiced,Revert D24232288: [fx] make sure args/kwargs are immutable
b64cf93f05,jit,new_features,[jit] support tracing tensor __setitem__ with dynamic shape (#45828)
62d37b9f26,fx,improvements,add size_based_partition final (#46282)
84771fc64f,caffe2,Untopiced,[caffe2] Add 10s deadline for all Caffe2 hypothesis fuzz tests
4534bf5799,dispatcher,improvements,Fix NativeFunctions.h for c10-full ops (#46090)
69e152e60b,skip,Untopiced,Fix device guard for c10-full ops (#46091)
f2e5ae4ba2,skip,Untopiced,Undefine bool and vector after including altivec.h (#46179)
8a074af929,foreach_frontend,new_features,Added scalar lists APIs for addcdiv and addcmul (#45932)
1f791c06f0,complex_frontend,improvements,adding BAND/BOR/BXOR reduce ops to unsupported list for complex numbers. added tests (#46270)
e7dbaa252e,python_frontend,docs,Update optim.rst for better understanding (#45944)
49903a5cd5,fx,new_features,[quant][graphmode][fx] Move custom_module_class config to prepare/convert_custom_config_dict (#46251)
9d389b1dcc,onnx,new_features,[ONNX] Preprocess index_put with bool inputs to masked_scatter/masked_fill (#45584)
53316e8b97,quantization,improvements,[quant] Remove prehook option (#46292)
dec61f93f2,skip,Untopiced,[ROCm] update GPG key URL in circleci Dockerfile (#46256)
5500b62f28,skip,Untopiced,Enable zero batch conv tests for ROCm (#46305)
74f13a8b8f,distributed,new_features,[Distributed] Adding getNumKeys support to the HashStore (#46048)
2ffb768607,distributed,new_features,[Distributed] deleteKey support for HashStore (#46049)
3ad797c937,skip,Untopiced,[quant][eagermode] Move custom_module registration to prepare/convert_custom_config_dict (#46293)
d655341adb,distributed,new_features,[Distributed] General Function for Parsing Environment Variable Flags in PG (#46045)
6ca03aeb96,onnx,bug_fixes,[ONNX] Fix flatten operator (#45632)
b28b5d3c68,onnx,improvements,[ONNX] Update squeeze test for opset 9 (#45369)
635aebdfab,quantization,devs,[quant] Refactoring the mappings files (#44847)
2bc6caa9e4,python_frontend,new_features,Add three-phase option to OneCycleLR (#42715)
fc1d6bf135,fx,improvements,[fx] make sure args/kwargs are immutable (#46325)
ff0af7242b,skip,Untopiced,Revert D24290811: [quant][eagermode] Move custom_module registration to prepare/convert_custom_config_dict
a69910868a,dataloader_frontend,bug_fixes,Fix possible padding length overflow in DistributedSampler (#45329)
af8c75e211,skip,Untopiced,[PyTorch] Stringize kernel tag names consistently during macro expansion and require all tag names to be a compile time character array (#46074)
103b100ddc,skip,Untopiced,Bazel build has warnings (#46233)
22f4a58a45,python_frontend,improvements,[pytorch] activation checkpointing: enable mixing tensor without requires_grad (#45934)
419dafe791,dispatcher,new_features,[Reland] Update native_functions.yaml to add DefaultBackend. (#46236)
4aaad88790,mobile,bug_fixes,Bug fixes in profiling allocator (#45993)
5393588e11,dispatcher,docs,Add guideline about which dispatch keyword to use in native_functions.yaml. (#46126)
86abc8cd48,jit,improvements,[JIT] Make InsertInstruction overflow check a warning instead of fatal (#46369)
a87a1c1103,cuda,performance,Fix perfornance issue of GroupNorm on CUDA when feature map is small. (#46170)
38c97fb6f0,caffe2,Untopiced,[shape inference] add shape inference support
053c252c66,performance_as_product,improvements,Update COMPILE_TIME_MAX_DEVICE_TYPES to 12 (#46327)
2d6fd22e24,performance_as_product,improvements,Rationalize inlining of kernels into the unboxing wrapper (#42845)
bd449334b8,python_frontend,docs,Fix formatting issues in torch.tensor_split documentation (#46328)
b5479737d7,mobile,new_features,Add windows JNI support (#44257)
908c23579d,jit,Untopiced,[JIT] Revert Freezing shared type PR (#46285)
7f458e16ba,dispatcher,improvements,Allow Undefined to get kernel from Math/DefaultBackend. (#46352)
528158af47,complex_frontend,new_features,"Updated derivatives for complex mm, mv, ger, bmm, triangular_solve (#45737)"
50f833248d,vulkan,new_features,Redo Vulkan command and descriptor pools. (#44496)
e3eef0cd7a,vulkan,new_features,Add image sampler. (#45037)
8c26111adb,vulkan,new_features,Add fence. (#45148)
5ce46fbbca,cuda,improvements,BFloat16 support for torch.sign (#45244)
c1141b6f68,complex_frontend,new_features,Added support for complex torch.pinverse (#45819)
e69f2f82ab,skip,Untopiced,Automated submodule update: FBGEMM (#46395)
8f61fa653f,caffe2,Untopiced,use @mode/ndk_libcxx instead of mode/gnustl
7d6d5f4be0,performance_as_product,new_features,Migrate CPU_tensor_apply to TensorIterator (#44242)
c99378af1b,python_frontend,bug_fixes,Fixing pow for special case between cuda tensors and cpu tensors and reframed test cases a tiny bit (#46320)
03c7d5be6b,benchmark,new_features,Add operator benchmark for 4bit/8bit embedding lookups
ba92920a28,dispatcher,improvements,Remove codegen for old RegistrationDeclarations.h (#46370)
401c85b4d3,vmap_frontend,improvements,Rename createLevelsBitset -> createVmapLevelsBitset; move it (#46190)
f96cb9de79,vmap_frontend,new_features,vmap: added fallback for in-place operators (#46191)
faf03bd226,mobile,improvements,Update default ouput extension in optimize_for_mobile.cc (#45598)
16c52d918b,caffe2,Untopiced,[caffe2] Bypass memonger for in-place ops (#46378)
757173a4da,caffe2,Untopiced,Add Sigmoid operator from Caffe2 (#46286)
dda95e6914,benchmark,new_features,More Timer refinement (#46023)
dc7cd97402,python_frontend,bug_fixes,Fixes bug in sspaddmm (#45113) (#45963)
d278e83e69,dispatcher,devs,Update VariableTypeManual.cpp to not use catchAllKernel. (#46353)
92921c82bb,mobile,improvements,Add named tuple's error message and workaround for RET failure (#46347)
d1745c36dc,quantization,improvements,fix type check for torch.quantization._numeric_suite (#46330)
ec5f81f9d3,dispatcher,improvements,Remove variable_excluded_from_dispatch() check for factory functions. (#46371)
ecf63351bc,caffe2,Untopiced,[mlf][efficiency] modify equalization scale operator to return single output (#46449)
7b788d113e,python_frontend,improvements,Fix deprecated warnings for nan_to_num (#46309)
d6e6073016,skip,Untopiced,install lcov in Docker image if coverage is specified (#46404)
b5702e2350,mobile,bug_fixes,Fix out-of-bounds access for caching allocator calls (#46439)
c37baa9177,caffe2,Untopiced,[caffe2] add concat benchmark (#46457)
5c5484c889,skip,Untopiced,[Flaky tests] Fix test_all_gather_timeout test (#45989)
9300a27702,complex_frontend,new_features,Make `torch.lu` support complex input on CUDA. (#45898)
be0c431874,autograd_frontend,bug_fixes,Fix implicit cast in custom_function (#46445)
2e2fe8cf3b,distributed,new_features,[NCCL] Modularize ncclCommWatchdog (#46051)
24ca2763e1,fx,new_features,"[fx] allow custom behavior for args, kwargs, and bool (#45193)"
dd169ca17c,caffe2,Untopiced,caffe2/plan_executor: propagate exceptions from reporter substeps (#46424)
28f8372bf4,autograd_frontend,performance,Avoid mat1 references in mm_mat1_backward (#45777)
997e672a27,skip,Untopiced,Move NCCL installation for xenial-cuda10.1 to Docker image instead of for every job (#46476)
89108ba6ea,quantization,improvements,type check for torch.quantization.stubs (#46475)
478fa180ee,skip,Untopiced,Removing hack so that NCCL is not removed in base Docker commands (#46495)
11cc7f143d,jit,bug_fixes,Run __setstate__ when cloning modules (#45858)
0c9787c758,caffe2,Untopiced,caffe2: use at::mt19937 instead of std::mt19937 (10x speedup) (#43987)
d1ca7ef33e,distributed,improvements,[Gradient Compression] Rename the first arg of pybinding of _register_comm_hook: ddp_model -> reducer. (#46498)
8c629ecc9a,dispatcher,new_features,[WIP] Move catchAll to Math (#45939)
5da4a08675,mobile,improvements,[GPU] Add metal to DispatchKeySet (#46455)
fa108bd264,jit,new_features,Add flatten loops transformation (#46365)
04e5fcc0ed,mobile,new_features,[GPU] Introduce USE_PYTORCH_METAL (#46383)
58f14d3a28,dispatcher,devs,Remove catchAllKernel_. (#46354)
5233ff9f15,jit,improvements,"[TensorExpr] Re-enable test for torch.cat, add a test for torch.cat being a single node in a fusion group. (#46447)"
cc471c6daf,mobile,performance,[Metal] Enable optimize_for_mobile on Linux (#46384)
e8ff0f6c5c,cpp_frontend,devs,[c10] add operator= of intrusive_ptr to weak_intrusive_ptr (#44045)
495070b388,mobile,improvements,[Metal] Add the Python binding for optimize_for_mobile (#46456)
da95eec613,python_frontend,new_features,torch.fft: Two dimensional FFT functions (#45164)
6a2f40dc66,jit,new_features,Expose script_if_tracing as public API (#46494)
351670f004,skip,Untopiced,Delete libtorch test jobs (#46508)
bcd68dfa5f,code_coverage,new_features,Change codecov comment style to be less verbose (#46499)
0c5cd8c2b9,build_frontend,new_features,[RFC] Switch PyTorch Selective Build (Custom Build) to use the SelectiveBuilder abstraction (#45722)
00c779a92b,autograd_frontend,improvements,detect inplace modifications of views earlier (fix #21875) (#46204)
eadc59df55,skip,Untopiced,Enable TP_USE_CUDA and TP_ENABLE_CUDA_IPC (#46523)
f06ea4bcac,skip,Untopiced,Add myself as owner of C++ APIs related folder (#46487)
e7564b076c,skip,Untopiced,Refactor scalar list APIs to use overloads (#45673)
172ed51a17,skip,Untopiced,Mark parts of spectral tests as slow (#46509)
7f8b02f5b7,onnx,improvements,[ONNX] Add test for Batchnorm (#45633)
d38a71d579,python_frontend,new_features,`torch.nn.modules.LazyModuleMixin` and `torch.nn.LazyLinear` (Shape Inference II) (#44538)
6dc763df30,quantization,new_features,PyTorch: add API usage logging to numeric suite (#46504)
7b2e8bec85,skip,Untopiced,[fx] Refactor Tracer so that find_module and root args creation could be overridden by implementations (#46493)
f0f10f82f4,skip,Untopiced,Automated submodule update: FBGEMM (#46443)
30d687522d,quantization,new_features,[reland][quant][eagermode] Move custom_module registration to prepare/convert_custom_config_dict (#46293) (#46364)
ac146c4820,jit,improvements,[nvFuser] Switching to `CudaFusionGuard` from `BailOut` for nvfuser - update 2 (#46452)
cda88e8e4b,jit,bug_fixes,Fix interval midpoint calculation in register_op_utils
8f12c0e786,skip,Untopiced,Revert D24269034: [fx] Refactor Tracer so that find_module and root args creation could be overridden by implementations
3d421b3137,dispatcher,new_features,[pytorch] rewrite of the python binding codegen with the v2 API (#46244)
5b0f400488,skip,Untopiced,Replace list(map(...)) constructs by list comprehensions (#46461)
a06b95b2ba,quantization,improvements,[quant][graphmode][fx] Support non_traceable_module/module_class (#46298)
17f8c329df,jit,new_features,[NNC] IRSimplifier rules for Compare and Mod (#46412)
e5ed037529,jit,performance,[StaticRuntime] Add a 'speed of light' benchmark. (#46308)
75322dbeb4,skip,Untopiced,[PyTorch] [BUCK] Replace pt_deps.bzl with a YAML operator dependency file which is generated by the code analyser (#46057)
0285618a11,vmap_frontend,new_features,Add utilities to support handling of nested python data structures (#46287)
6025f8148a,vmap_frontend,improvements,"Implement `_broadcast_to_and_flatten(pytree, spec)` (#46288)"
1c8d0d8cc9,vmap_frontend,improvements,Allow vmap to accept nested python data structures as inputs (#46289)
0d4590c279,skip,Untopiced,renaming env var IN_CIRCLECI to a broader name of IN_CI (#46567)
35a35c3498,skip,Untopiced,Move Open MPI installation to Ubuntu CUDA Docker images (#46569)
5e0bfd7455,skip,Untopiced,[Build] [CMake] [ROCm] find hsa-runtime64 properly (#45550)
5003fd189c,jit,improvements,Add an option to getWriteableTensorData to avoid copy CUDA tensor to CPU (#46524)
e6ed887908,python_frontend,improvements,Add view test for tensor_split (#46427)
9c02e2112e,skip,Untopiced,Automated submodule update: FBGEMM (#46578)
2f51ddb81f,skip,Untopiced,Replace flatten tensors with flatten loops. (#46539)
187e23397c,skip,Untopiced,Remove non-existent trusty image references (#46594)
e18a8aba95,cuda,new_features,Add CUDA 11.1 docker build (#46283)
1a3ea46dbf,jit,new_features,[StaticRuntime] Threading model (#46219)
2b221a9599,python_frontend,devs,Remove PyCFunction casts as much as possible. (#46227)
4f5b55f722,skip,Untopiced,Revert D24395956: [pytorch][PR] Replace flatten tensors with flatten loops.
f9446cb15a,quantization,improvements,[quant][refactor] Remove register api and rename get_*_mapping to get_default_*_mapping (#46337)
fdc5261a20,jit,new_features,Support %-based string formatting (#45976)
f83cf2dab3,jit,new_features,[JIT] adding torch.jit.isinstance support (#46062)
253918ec55,skip,new_features,[quant] Add FixedQParamsFakeQuantize module (#45538)
42a70dc5a8,distributed,new_features,Implement all communication APIs in DistributedC10d new frontend (#46053)
cb3c1d17e4,skip,Untopiced,Promote -Wcast-function-type to an error in builds. (#46356)
3e041b503f,vulkan,new_features,Add Vulkan job dispatch and flush. (#46008)
6cd8b5e9a7,vulkan,new_features,Provide CMake option to enable Vulkan API. (#46503)
f47231bf0e,caffe2,Untopiced,[caffe2][dnnlowp] Remove openmp usage in quantize dnnlowp op
2181449068,skip,Untopiced,Revert D24004795: [quant] Add FixedQParamsFakeQuantize module
a651b876a7,memory_format_frontend,bc_breaking,preserve non-dense or overlapping tensor's layout in *_like functions (#46046)
e8fbe54cf5,skip,Untopiced,"[py][vulkan] Add is_vulkan to py api, add vulkan to device type parsing (#46511)"
8357e2edc3,fx,new_features,"Back out ""Revert D24269034: [fx] Refactor Tracer so that find_module and root args creation could be overridden by implementations"" (#46573)"
8328630315,mobile,performance,avoid inlining kernel lambdas on mobile (#46249)
cebe87fe3a,skip,Untopiced,"Revert D24379422: [py][vulkan] Add is_vulkan to py api, add vulkan to device type parsing"
62e714c9d9,cuda,improvements,Delete CUDAUnaryOps.cpp (#46280)
cf3d7a2660,dispatcher,new_features,first cut of adding a dangling impl test. fix #45165 (#46484)
611f028168,distributed,new_features,Add Batch-Updating Parameter Server Example to CI Tests (#46510)
6de619e4a4,complex_frontend,new_features,Allow converting parameters of nn.Module to complex dtypes (#44788)
96bc7faa50,onnx,new_features,"[ONNX] Export var, var_mean and std_mean ops (#45678)"
ac4ee0ef5d,python_frontend,docs,Fix typo in docs for interpolate (#46589)
65da50c099,build_frontend,improvements,Apply hip vs hipcc compilation flags correctly for building extensions (#46273)
09896eda14,package,bug_fixes,"Fix version comparisons for Python 3.6, 3.10 and 4 (#32389)"
c3c249aa0b,cuda,bug_fixes,Workaround to pay attention for CUDA version (#46535)
ce04e527b4,skip,Untopiced,Bump up windows cudnn version (#46436)
caed29a069,skip,Untopiced,fix-process-group-counter (#46563)
e3b2bfa2a3,performance_as_product,improvements,[pytorch] Early return in nn.EmbeddingBag when weight is empty (#46572)
475b4e30e6,jit,new_features,Allow for source code comments at any level of indentation (#46548)
ff0e20b384,skip,Untopiced,Config inheritance was added for pytorch project (#46584)
e02a3e190e,skip,Untopiced,DOC: Building libtorch using CMake (#44196)
6011b36080,build_frontend,improvements,Fix `type qualifiers ignored on return type` warning (#46668)
8908f6ad8e,benchmark,improvements,[op-bench] modify import path of configs (#46679)
746febdeac,quantization,improvements,[quant][graphmode][fx] Add additional_object_mapping argument to convert (#46338)
13decddae2,quantization,new_features,[reland][quant] Add FixedQParamsFakeQuantize module (#45538) (#46657)
33e82c0269,skip,Untopiced,Update error message to include link to readme. (#46613)
adbb50ea67,jit,new_features,Enabling alias annotation checks for all operations during autograd tests (#46601)
db83ddcb86,distributed,docs,small doc fix (#46599)
adffd8eb6b,distributed,improvements,Add const to the first arg 'grad' of Reducer::copy_grad_to_bucket (#46501)
fe4f90c40b,cuda,improvements,Cusolver inverse check info (#46625)
9b5197b763,caffe2,Untopiced,[mlf][efficiency] add tensor inference function to last-n collector op (#46693)
ab28bd528d,quantization,new_features,[quant][graphmode][fx] Support quantizing FloatFunctional (#46634)
98aad933b6,distributed,improvements,[pytorch][PR] Record FutureNCCL callback stream on CUDA caching allocator (#45318)
8e13fe6c44,python_frontend,new_features,[numpy] `torch.sin` : support and promote integer inputs to float (#45733)
905ed3c840,python_frontend,docs,Revised sparse tensor documentation. (#45400)
143d1fd9f5,skip,Untopiced,Namespace cleanup for 1.7 Part 2 (#46673)
e5a2ba2ea1,skip,Untopiced,Fix benchmark_caffe2
7245d2c939,distributed,improvements,Avoid scatter for single-device case in DDP (#46304)
aa9ca85bd0,skip,Untopiced,Fix interval midpoint calculation (#46666)
52a970bac9,cuda,devs,Minor cleaning of `test_cuda.py` (#46617)
3526b604b1,skip,Untopiced,Add comment about running C++ executable lint locally (#46698)
bc1ce58451,skip,Untopiced,Push rocm to slow path (#46216)
3112e23428,vulkan,new_features,"[py][vulkan][reland] Add is_vulkan to py api, add vulkan to device type parsing (#46655)"
25dc0056f2,distributed,new_features,[RPC] print exception message on workers that run python functions (#46372)
93719440b8,skip,Untopiced,Replace map(lambda constructs (#46462)
b63ddd6f57,mobile,new_features,[OSS][Metal] Support Resnet models
06d50b5eb0,distributed,new_features,Pull in fairscale.nn.Pipe into PyTorch. (#44090)
920ec6651f,benchmark,bug_fixes,[OpBench] fix jit mode run of operator benchmark for ops with parameters (#46694)
c44300884e,caffe2,Untopiced,Clarify timing of GetDeviceProperty() (#46715)
18d80501a6,vmap_frontend,new_features,"Batching rules for: new_zeros, new_empty (#46606)"
2700932ef2,fx,bug_fixes,[FX] Fix recursion depth issue on Graph deepcopy (#46669)
9ccf85b7b4,fx,new_features,[FX] Make wrapped functions traceable (#46692)
c57c560744,skip,Untopiced,"Revert ""Push rocm to slow path (#46216)"" (#46728)"
982fa07ccb,python_frontend,improvements,torch.nn.Unfold accepts 0-dim for batch size (#40689)
23fad9111e,fx,new_features,[quant][graphmode][fx] Add additional_qat_module_mapping (#46344)
51bf7bed84,caffe2,Untopiced,[caffe2] Allow memonger to optimize nets with inplace(enforced) ops (#46560)
53dff784e2,caffe2,Untopiced,[caffe2] Fix inplace ops in onnx::SsaRewrite (#46134)
f326f6a8a0,performance_as_product,new_features,Remove dilation restriction on cuDNN ConvTranspose2d (#46290)
d6519d4e9f,jit,new_features,[pt][static_runtime] Add option enable_out_variant (#46690)
bd90379df5,quantization,new_features,[quant][graphmode][fx] Add support for additional_fuse_method_mapping (#46345)
ce5bca5502,distributed,bug_fixes,ProcessGroupNCCL::alltoall_base needs to call recordStream (#46603)
344abd56f9,skip,Untopiced,[CI][IOS] Rename the IOS_VERSION (#46645)
bf1ea14fbc,mobile,new_features,[CI][IOS] Add a arm64 ios job for Metal (#46646)
fe6fb7753e,python_frontend,devs,Clean up use of Flake8 in GitHub CI (#46740)
e34c825b77,fx,new_features,[quant][fx] Embedding quantization support (#46677)
842494af77,fx,new_features,[quant][fx] EmbeddingBag quantization support (#46678)
870a5a0d6d,distributed,bug_fixes,Enable DataParallel to run zero input Module (#46565)
6ae0a7c919,benchmark,improvements,Add ReplaceNaN benchmark as baseline (#46685)
88e94da580,skip,Untopiced,Enable softmax and tiny norm FP16 tests on ROCm (#46363)
511f89eaa9,cuda,new_features,Add nvtx.range() context manager (#42925)
8558c0e612,skip,Untopiced,Eliminate narrowing conversion (#46730)
129279a374,quantization,new_features,"[FBGEMM][Transposed Conv] add transposed conv support for fbgemm backend for 1d, 2d, 3d (#46607)"
4fd2cce9fa,python_frontend,bug_fixes,Check support_as_strided before using empty_strided. (#46746)
6c5f634657,jit,Untopiced,Fix grammar and spelling errors (#46713)
e0fd590ec9,skip,Untopiced,Fix incorrect usage of CUDACachingAllocator (#46605)
f230245c06,skip,Untopiced,Revert D24422354: [pytorch][PR] fix-process-group-counter
52f8d320b3,onnx,docs,[ONNX] Update ONNX doc for indexing export (#46349)
c31ced4246,autograd_frontend,new_features,make `torch.lu` differentiable. (#46284)
3ea26b1424,foreach_frontend,new_features,[WIP] Push rocm to slow path for foreach APIs (#46733)
e519fcd1aa,caffe2,Untopiced,Remap net name inside arg.n for AsyncIf operator
ccb79f3ac7,distributed,new_features,Add option to log subprocess output to files in DDP launcher. (#33193)
822efb7275,skip,Untopiced,add workflow ID to report tags (#46725)
999f7ed3a1,foreach_frontend,improvements,Refactored ForeachFunctors.cuh (#46660)
89f368bef8,skip,Untopiced,Enable XNNPACK on Windows & Update XNNPACK (#45830)
85954164a4,skip,Untopiced,"fix minor bug, message variable does not exist (#46777)"
aa828bf084,vmap_frontend,new_features,Support undefined grads in vmap fallback (#46671)
74d81080a0,vmap_frontend,new_features,Use new_zeros in evenly_distribute_backward (#46674)
343260a1cc,quantization,new_features,[quant][graphmode][fx] Add support for additional_{fusion/quant}_pattern (#46346)
c4892c8efe,jit,improvements,[pytorch][tensorexpr] Promote integer arguments to sin/cos/tan to float (#46776)
789e935304,python_frontend,improvements,Annotate torch.nn.cpp (#46490)
13b7855f33,jit,new_features,Support hashing of various data types by implementing generic hashing for IValues (#46441)
37dbc6117f,quantization,new_features,[quant][eagermode] Add additional_fuser_method_mapping to config (#46355)
7d4c1a5ab0,skip,Untopiced,Fix type warning (#46770)
f9b9430152,jit,new_features,Support doc_string for TorchBind custom classes (#46576)
9cbdd84e15,skip,Untopiced,Fix compiler warning
fa8cd06a5c,skip,Untopiced,Perform explicit cast (#46771)
edbc84aa4a,skip,Untopiced,Fix hash type (#46769)
d94bd998ec,complex_frontend,new_features,Update backward formulas (Re #44444) (#46275)
b61671ccd2,python_frontend,bug_fixes,Enable dtype arg for torch.linalg.norm with order 'fro' and 'nuc' (#46637)
3e606da0af,skip,Untopiced,Upgrading lcov install to install v1.15 to be compatible with GCC9 (#46847)
5a2b537b54,jit,improvements,Add error messages and workaround for RET failure of containers with a torch class type (#46543)
b5662ba0f0,caffe2,Untopiced,[uhm][0/n] add cuda Mod Op (#46732)
e927b62e73,skip,Untopiced,[quant][graphmode][fx] Support sigmoid/hardsigmoid/tanh in qat (#46738)
56a3831bc6,benchmark,improvements,[NVFuser]Benchmark minor update (#46778)
0c74b43a3f,skip,Untopiced,Update TensorPipe submodule (#46842)
25db74bf5e,skip,Untopiced,Revert D24486972: [quant][graphmode][fx] Support sigmoid/hardsigmoid/tanh in qat
58ed60c259,distributed,new_features,Added context manager enabling all futures returned by rpc_async and custom build rpc functions to be automatically waited on (#41807)
57bf0b596a,quantization,docs,[docs] Changing the wording on quantization versioning and support (#46858)
02dc52f25b,vmap_frontend,improvements,vmap fallback: gracefully error out when vmap over dim of size 0 (#46846)
13a5be571b,complex_frontend,new_features,Enable complex backward for torch.take() and tensor.fill_() (#46860)
99cf3b1ce4,cuda,improvements,CUDA BFloat16 signal windows (#45155)
7731370e71,cuda,new_features,"CUDA BFloat16 gelu, hardswish, hardsigmoid (#44997)"
adafd3d4b2,distributed,new_features,Support RRef.backward() for local RRefs. (#46568)
a6cd294c9b,distributed,improvements,[Gradient Compression] Refactor CommHookInterface and PythonCommHook. (#46512)
a4adc1b6d7,skip,Untopiced,Fix unused variable warning (#46838)
a602811da7,amd,bug_fixes,[ROCm] fix bug in miopen findAlgorithm. (#46852)
2397c8d1f7,performance_as_product,new_features,[pytorch] Improve/fix heuristics for using mkldnn vs native conv (#46675)
c9bf03a6c4,skip,Untopiced,Add Vulkan Tensor. (#44015)
af27da93de,vulkan,new_features,Add Vulkan Tensor factory. (#44016)
b3e64c86e0,caffe2,Untopiced,Remove loop_test mode (#46618)
4a35280ec2,skip,Untopiced,[c10] fix weak_intrusive_ptr lock() (#46007)
9858b012ec,python_frontend,docs,Fix TripletMarginWithDistanceLoss example code (#46853)
37da6d26ff,jit,docs,add fburl link to error message (#46795)
bcbb6baccf,complex_frontend,improvements,Add a warning message that torch.sign would not support complex numbers (#43280)
60eded6c0f,jit,improvements,Add single element tuple output from to_backend/to_glow (#5029)
6b50ccc41c,quantization,new_features,[quant][graphmode][fx] Support sigmoid/hardsigmoid/tanh in qat (#46738) (#46871)
4b6e307191,jit,new_features,Replace flatten tensors with flatten loops. (#46737)
8640905088,fx,new_features,add sparse_nn_partition (#46390)
d5cd781cd3,benchmark,improvements,Update dper3 to use torch.nan_to_num and nan_to_num_ (#46873)
daf2a6a29d,skip,Untopiced,Increase no-output-timeout for OSX builds (#46891)
bbe5bfaa4f,performance_as_product,improvements,Add GradMode::enabled check to max_pool1d (#46767)
21e60643c0,python_frontend,improvements,"[numpy] `torch.log{2,10}` : promote integer inputs to float (#46810)"
151f31ba27,skip,Untopiced,remove event not ready assertion from TestCuda.test_copy_non_blocking (#46857)
717e6d8081,python_frontend,improvements,add type annotations to comm.py (#46736)
79a1d2bd78,skip,Untopiced,[iOS] Bump up the cocoapods version (#46935)
dc53eefd25,build_frontend,devs,Conditional requirement for py3.6 only (#46932)
64d4b24a12,skip,Untopiced,Adding link to gcov depending on GCC_VERSION (#46928)
c20c840c1b,skip,Untopiced,Install sccache from source (#46672)
1479ed91be,skip,Untopiced,Add CUDA 11.1 CI (#46616)
8066e89f64,quantization,bug_fixes,quant: fix bug with copy.deepcopy of FX prepared quantization models (#46895)
115bbf9945,caffe2,Untopiced,[caffe2] Disable running full grad check in tests by default
53839ac9d7,python_frontend,bug_fixes,Fix internal assert for torch.heaviside with cuda tensor and cpu scalar tensor (#46831)
67c1dc65a3,fx,bug_fixes,[FX] Fix handling of `inf` and `nan` literals (#46894)
8e37dcb1f3,foreach_frontend,new_features,Added foreach_zero_ API (#46215)
810c68fb1d,benchmark,bug_fixes,[OpBench] fix jit tracing with quantized op/tensor by enabling `_compare_tensors_internal` to compare quantized tensors (#46772)
5a8198eb3c,quantization,bug_fixes,[quant][graphmode][fx][fix] scalar as first input for add/mul (#46751)
998b9b9e68,quantization,new_features,[quant][graphmode][fx] custom_module support static/dynamic/weight_only quant (#46786)
e077a2a238,distributed,new_features,[Gradient Compression] Add CppCommHook subclass for supporting the C++ API of communication hook. (#46566)
e299393fd5,distributed,new_features,[Gradient Compression] Provide 2 default C++ comm hooks (#46701)
d92bf921db,fx,bc_breaking,[quant][graphmode][fx] Remove `inplace` option for fuse_fx (#46953)
ddbdbce623,jit,bug_fixes,[jit] Prevent caching of `graph` attribute. (#46960)
46b252b83a,skip,Untopiced,Revert D24262885: [pytorch][PR] Added foreach_zero_ API
cd8ed93287,fx,bc_breaking,[quant][graphmode][fx][api] Remove `inplace` option from prepare_fx (#46954)
c886c7f6dd,python_frontend,improvements,fix: Fixed typing of bool in _ConvNd (#46828)
50c9581de1,skip,Untopiced,AT_ERROR if mmap allocation has failed (#46934)
353e7f940f,cuda,bug_fixes,Ensure kernel launches are checked (#46474)
b75b961934,autograd_frontend,bug_fixes,"Fix `requires_grad` arg for `new_full`, `new_empty`, `new_zeros` (#46486)"
c6858fd71a,caffe2,Untopiced,Set up benchmarks for ClipRanges operator for Caffe2 and PyTorch
c9222b7471,caffe2,Untopiced,Implement clip_ranges operator for PyTorch
c3fc17b48e,cuda,bug_fixes,Fix bit math (#46837)
cbf90dafe1,mobile,bug_fixes,Fix CPUCaching allocator guard bug (#46922)
069232a574,fx,bug_fixes,[FX] Fix corner case in name sanitization (#46958)
61ee0242c0,skip,Untopiced,Fix backcompat in master following revert (#46984)
98b3da8b13,skip,Untopiced,Revert D24452660: [pytorch][PR] Add CUDA 11.1 CI
179d2b288c,vulkan,bug_fixes,Fix interval midpoint calculation in vulkan (#46839)
23bce17baa,jit,new_features,"Add inputsSize to Python IR, like outputsSize (#46779)"
bf08814b73,fx,Untopiced,[FX] Kill functional transforms name (#47004)
ec600bc391,vulkan,new_features,Add Vulkan tensor copy. (#46481)
14d87ec5a3,vulkan,new_features,Add Vulkan op Add. (#44017)
cd26d027b3,python_frontend,docs,[doc] Fix info on the shape of pivots in `torch.lu` + more info on what and how they encode permutations. (#46844)
fc2bd991cc,quantization,improvements,[quant] Fix flaky test test_histogram_observer_against_reference (#46957)
dc8176356e,jit,bug_fixes,Various cleanups to ir_emitter and friends (#46686)
c7183c9878,distributed,improvements,Fix object-based collectives API to use torch.cuda.current_device instead of (#46897)
9fefb40628,skip,Untopiced,Fix signed-to-unsigned conversion warning (#46834)
ad260ae7fd,skip,Untopiced,Disable test_joing_running_workers for TSAN. (#46966)
c2a3951352,quantization,bc_breaking,[quant][graphmode][fx] Remove inplace option for convert_fx (#46955)
a86b3438eb,fx,new_features,add support for different memory sizes on size_based_partition (#46919)
79474a1928,dispatcher,devs,[pytorch] simplify tensor options logic in pybinding codegen (#46976)
9d23fd5c00,skip,Untopiced,[pytorch] get rid of cpp_type_str from pybind codegen (#46977)
42a51148c1,skip,Untopiced,Use f-strings in torch.utils.cpp_extension (#47025)
5c8aad1141,python_frontend,improvements,"[numpy] `torch.cos`, `torch.tan` : promote integer inputs to float (#46706)"
604e1b301a,python_frontend,bug_fixes,Fix negative column numbers for the torch.eye (#46841)
9c1a41b724,dispatcher,new_features,[RFC] Add OperatorHandle overload to the RecordFunction::before() method (#46401)
b553c06abb,Uncategorized,Untopiced,Throw an exception in the constructor of torchscript serialization to avoid double-exception (#44266)
cab32d9cdf,Uncategorized,Untopiced,"[RPC Framework] Support remote device format ""<workername>/<device>"" (#46773)"
d0df29ac22,Uncategorized,Untopiced,[FX] Put inf and nan in globals instead of with an import string (#47035)
18d273dc0e,Uncategorized,Untopiced,[RFC][LocalSession] Fix workspace type
4a581ba6c2,Uncategorized,Untopiced,Implement LengthsToOffsets operator in Caffe2 (#46590)
dfdc1dbee4,Uncategorized,Untopiced,Disable softmax tests on ROCm (#46793)
262bd6437a,Uncategorized,Untopiced,Show old kernel location when there are mismatches (#46850)
ecdbea77bc,Uncategorized,Untopiced,Fix DDP documentation (#46861)
13b4127c95,Uncategorized,Untopiced,Fix implicit conversion (#46833)
f629fbe235,Uncategorized,Untopiced,Added torch.linalg.tensorsolve (#46142)
2249a293b7,Uncategorized,Untopiced,Fix segfault with torch.orgqr. (#46700)
2b6a720eb1,Uncategorized,Untopiced,Update pybind to 2.6.0 (#46415)
38265acfbe,Uncategorized,Untopiced,Add Mul op for Vulkan (#47021)
dd95bf65b6,Uncategorized,Untopiced,[caffe2/FC DNNLOWP] Shrink Y_int32_ vector capacity when appropriate
6eaa324c9f,Uncategorized,Untopiced,Implement torch.igamma (#46183)
1e275bc1a6,Uncategorized,Untopiced,Show Flake8 errors in GitHub CI again (#46990)
fee585b5a3,Uncategorized,Untopiced,Correctly mark unannotated NamedTuple field to be inferred TensorType (#46969)
74d730c0b5,Uncategorized,Untopiced,"implement NumPy-like functionality column_stack, row_stack (#46313)"
680571533b,Uncategorized,Untopiced,[RFC] Decouple fast pass functions (#46469)
d850b5c98c,Uncategorized,Untopiced,Fix DDP issue where parameters share same grad_accumulator (#46755)
3e499e490a,Uncategorized,Untopiced,Bump up NCCL to v2.8 (#46742)
1d233d7d1f,Uncategorized,Untopiced,[fix] torch.nn.functional.embedding -> padding_idx behavior (#46714)
129b41226e,Uncategorized,Untopiced,[ONNX] Support nd mask index in opset >= 11 (#45252)
c556d4550c,Uncategorized,Untopiced,fix_combine_two_partition_size (#47053)
1ea14e30f5,Uncategorized,Untopiced,[ONNX] Enable NoneType inputs to export API (#45792)
377a09c8e8,Uncategorized,Untopiced,reland fast TypeMeta/ScalarType conversion (#45544)
71c0133e23,Uncategorized,Untopiced,enable PE everywhere but mobile (#47001)
156c08b0d9,Uncategorized,Untopiced,view_as_real doesn't work for all backends since it relies on strides. (#47018)
dc6f723cb4,Uncategorized,Untopiced,Delete Vulkan from code generator. (#46938)
87e86fa84c,Uncategorized,Untopiced,Some miscellaneous cleanup in codegen (#46940)
54d83296a9,Uncategorized,Untopiced,Desugar missing dispatch field into singleton Math entry (#46970)
41f8641f1e,Uncategorized,Untopiced,"Delete SchemaRegister.cpp, make flag operate on TypeDefault.cpp (#46991)"
c689b4d491,Uncategorized,Untopiced,Delete TypeDefault call code generation logic in VariableType (#47000)
843cab3f2e,Uncategorized,Untopiced,Delete TypeDefault.h and TypeDerived.h codegen entirely. (#47002)
a4caa3f596,Uncategorized,Untopiced,[ONNX] bump CI ort to 1.5.2 rel for stability (#46595)
78de12f588,Uncategorized,Untopiced,Replace -f with -x for pytest tests. (#46967)
e17b8dea1d,Uncategorized,Untopiced,fix calculation of number of elements to not overflow (#46997)
3c643d112e,Uncategorized,Untopiced,"Pin destination memory for cuda_tensor.to(""cpu"", non_blocking=True) (#46878)"
7190155408,Uncategorized,Untopiced,[Transposed Conv]add ConvTranspose3d with FBGEMM as backend (#46608)
9bc8f071a3,Uncategorized,Untopiced,[WIP] Move torch.fx into its own target (#46658)
ddeacf1565,Uncategorized,Untopiced,Fix median bug on discontigous tensors (#46917)
f5477e3703,Uncategorized,Untopiced,Enable python code coverage on windows (#44548)
2e2dc5874b,Uncategorized,Untopiced,Fix lint (#47095)
e3b55a8a65,Uncategorized,Untopiced,[pytorch/ops] Concat fast path w/ zero tensor (#46805)
366888a5e2,Uncategorized,Untopiced,[quant][graphmode][fx] Remove logging for standalone module api calls (#47032)
707d271493,Uncategorized,Untopiced,Fix links in tools/build_variables.bzl (#47066)
d95e1afad3,Uncategorized,Untopiced,[pytorch] add script to run all codegen (#46243)
0dbd72935a,Uncategorized,Untopiced,Split comm hooks into python-dependent hooks and others (#47019)
f9d32c4fa8,Uncategorized,Untopiced,[JIT] Add selective backend lowering API (#43613)
6c34aa720c,Uncategorized,Untopiced,add add_node function for partition to fix partition mem size calculation (#47083)
eec201c138,Uncategorized,Untopiced,Add last_n_window_collector
67b7e751e6,Uncategorized,Untopiced,add warning if DataLoader is going to create excessive number of thread (#46867)
7df0224cba,skip,Untopiced,Automated submodule update: FBGEMM (#47071)
2643800881,Uncategorized,Untopiced,Fix max_pool2d with ceil_mode bug (#46558)
f05b66b70d,Uncategorized,Untopiced,pass TypeMeta by value (#45026)
c7fc8cab3b,Uncategorized,Untopiced,track Half/ComplexHalf default dtype (#45043)
99fed7bd87,Uncategorized,Untopiced,faster TensorOptions merging (#45046)
69fe10c127,Uncategorized,Untopiced,use bitfield to shrink TensorImpl (#45263)
1dd220bd84,Uncategorized,Untopiced,Add C++ coverage for Ubuntu cpu tests (#46656)
085193c291,Uncategorized,Untopiced,[quant][graphmode][fx][fusion] Add test for fuse_fx (#47085)
c86af4aa55,Uncategorized,Untopiced,Disable NEON acceleration on older compilers (#47099)
a81572cdc5,Uncategorized,Untopiced,Add anomaly mode for C++ (#46981)
d1d6dc2e3c,Uncategorized,Untopiced,Add more specific error message (#46905)
7eb427e931,Uncategorized,Untopiced,Providing more information while crashing process in async error handling (#46274)
cb4b6336ba,Uncategorized,Untopiced,[FX] Fix handling of attributes (#47030)
1aa57bb761,Uncategorized,Untopiced,"Moving coverage, xunit, pytest installation to Docker (#47082)"
7f056e99dd,Uncategorized,Untopiced,[fbcode] Make model reader utilities.
e3f912e8b7,Uncategorized,Untopiced,Revert D24655999: [fbcode] Make model reader utilities.
ee0033af9b,Uncategorized,Untopiced,[Gradient Compression] Surface C++ comm hooks to Python API as built-in comm hooks (#46959)
54feb00bbd,Uncategorized,Untopiced,Create prototype for AST rewriter (#46410)
317b78d56e,Uncategorized,Untopiced,Revert D24665950: Create prototype for AST rewriter
19ede75eb9,Uncategorized,Untopiced,[JIT] Enable ModuleDict non-literal indexing (#45716)
1cc1da5411,Uncategorized,Untopiced,LayerNormInt8QuantizeFakeNNPI fix to match ICEREF. (#47140)
85e5b76f17,skip,Untopiced,Automated submodule update: FBGEMM (#47190)
c10aa44e33,Uncategorized,Untopiced,"Back out ""Providing more information while crashing process in async error handling"" (#47185)"
da26858c9c,Uncategorized,Untopiced,Add complex backward support for torch.exp (#47194)
0d6bf8864b,Uncategorized,Untopiced,add rocm 3.9 to nightly builds (#47121)
c2e123331a,Uncategorized,Untopiced,Check CUDA kernel launches (fbcode/caffe2/aten/src/ATen/native/cuda/) (#47207)
6906701bde,Uncategorized,Untopiced,[ROCm] enable stream priorities (#47136)
6e22b6008d,Uncategorized,Untopiced,[MLF] Allow for computing prune quantile thresholds on absolute value of indicators in distributed-inference-compatible embedding LUT pruning (#46789)
60fea510a1,Uncategorized,Untopiced,explicitly error out in comparison ops when the types don't match (#46399)
c5ae875179,Uncategorized,Untopiced,Add bfloat support for torch.randn and torch.norm (#47143)
6852cbb952,Uncategorized,Untopiced,[RFC] Better error message in case operator could not be run (#46885)
70d58031d7,Uncategorized,Untopiced,[c10] make intrusive_ptr available as a pybind holder type (#44492)
96b23f7db1,Uncategorized,Untopiced,add sandcastle device type test base discovery (#47119)
7178790381,Uncategorized,Untopiced,Add vulkan clamp op (#47196)
9b52654620,Uncategorized,Untopiced,annotate a few torch.nn.modules.* modules (#45772)
22b3d414de,Uncategorized,Untopiced,Enhance the torch.pow testcase for the complex scalar base (#47101)
e03820651a,Uncategorized,Untopiced,Make conversions explicit (#46835)
7f125bca1c,Uncategorized,Untopiced,[Metal] Add pin_memory check in empty_strided (#47228)
b3eb0c86cf,Uncategorized,Untopiced,Revert D24335982: explicitly error out in comparison ops when the types don't match
f5073b0c5a,Uncategorized,Untopiced,Add `inputs` argument to `autograd.backward()` (#46855)
42b6f96764,Uncategorized,Untopiced,"Make ""Run flake8"" step always succeed again (#47236)"
ebf36ad3da,Uncategorized,Untopiced,Remove travis-python references as well as some unnecessary dependencies (#47209)
b5a1be02a0,Uncategorized,Untopiced,Add RAII DetectAnomalyGuard (#47164)
f58842c214,Uncategorized,Untopiced,Enable inlining into reductions (#47020)
8054ae3e77,Uncategorized,Untopiced,Add test for trace (#47125)
86151da19e,Uncategorized,Untopiced,Port CPU Trace from TH to ATen (#47126)
cedeee2cd4,Uncategorized,Untopiced,Add scalar.conj() and update backward formulas for add and sub (#46596)
be2e3dd2a1,Uncategorized,Untopiced,[quant][graphmode][fx][fix] Linear work with float_qparam_dynamic_qconfig (#47068)
b6685d3863,Uncategorized,Untopiced,[PT] optional -> c10::optional (#47144)
82b74bd929,Uncategorized,Untopiced,For torch::jit::module's attr method to moble::module (#47059)
27f4a78bb8,Uncategorized,Untopiced,Add benchmark for per channel tensor quantization (#46017)
ecfa7a27b8,Uncategorized,Untopiced,[jit] fix traced training attribute (#47211)
b0e954fff5,Uncategorized,Untopiced,quantize_tensor_per_channel ARM implementation (#46018)
2cff3bba58,Uncategorized,Untopiced,"[vulkan_api][ops] Mm, Pool, Upsample (#47063)"
b1b77148ac,Uncategorized,Untopiced,"Back out ""[Gradient Compression] Surface C++ comm hooks to Python API as built-in comm hooks"" (#47234)"
084b71125f,Uncategorized,Untopiced,Fix bug in toComplexWithDefault (#43841)
1fe273d798,Uncategorized,Untopiced,add node by node cost function (#47009)
09a52676ad,Uncategorized,Untopiced,Add NestedTensor specific dispatch key to PyTorch (#44668)
ac8a8185eb,Uncategorized,Untopiced,expose Timer docs to PyTorch website. (#46880)
4df7eefa06,Uncategorized,Untopiced,[TensorExpr] Support LLVM versions 8 through 12 (#47033)
0ead9d545a,Uncategorized,Untopiced,[quant][graphmode][fx] Add test for non quantized embedding and embeddingbag (#47092)
ad3a3bd0d6,Uncategorized,Untopiced,[GPU] Add an attribute to the torchscript model exported by metal (#47174)
73e121de1c,Uncategorized,Untopiced,[GPU] Enable optimize_for_metal in fbcode (#47102)
a341a4329a,Uncategorized,Untopiced,Format error message for unmatched signature between _out and base functions (#47087)
c05ee86edd,Uncategorized,Untopiced,Fix return-type-is-always-copy warning (#47279)
5c8896f8ad,Uncategorized,Untopiced,Delete CUDA build rules from MacOS build (#47277)
579cfc6641,Uncategorized,Untopiced,Moving test order to rebalance test1 and test2 times (#47290)
9e58c85d08,Uncategorized,Untopiced,[ROCm] remove use of HIP_PLATFORM (#47241)
8c865493c6,skip,Untopiced,Automated submodule update: FBGEMM (#47263)
782f92b569,Uncategorized,Untopiced,fix windows CI passed incorrectly (#47105)
9c3a75527b,Uncategorized,Untopiced,Update doc to reflect current behavior (#46937)
4e6f2440d8,Uncategorized,Untopiced,Optimize backward for torch.repeat (#46726)
774b638eb6,Uncategorized,Untopiced,Change largeCUDATensorTest to largeTensorTest+onlyCUDA; add a buffer to large cuda tensor test (#45332)
32b66b0851,Uncategorized,Untopiced,reorganize sparse_nn_partition (#47283)
f276ab55cd,Uncategorized,Untopiced,Added Kronecker product of tensors (torch.kron) (#45358)
c68c3d0a02,Uncategorized,Untopiced,[fix] nn.Embedding.from_pretrained : honour `padding_idx` argument (#47184)
0d00724e36,Uncategorized,Untopiced,[numpy] `torch.{a}tanh` : promote integer inputs to float (#47064)
c424d9389e,Uncategorized,Untopiced,"[numpy] `torch.a{cos, tan}` : promote integer inputs to float (#47005)"
dc0d68a1ee,Uncategorized,Untopiced,[JIT] Print out interface mismatch for prim::ModuleDictIndex (#47300)
ea93bdc212,Uncategorized,Untopiced,Add comment explaining purpose of the accumulate_grad argument (#47266)
8b13ab9370,Uncategorized,Untopiced,Event Logging for NCCL Async Error Handling Process Crash (#47244)
f730f2597e,Uncategorized,Untopiced,[NNC] Implement Cond in LLVM codegen (#47256)
2b5433dee6,Uncategorized,Untopiced,[Pytorch][Annotation] Update inlined callstack with module instance info (#46729)
63978556fd,Uncategorized,Untopiced,"[numpy] `torch.a{cosh, sinh}` : promote integer inputs to float (#47152)"
f41f3e3cd1,Uncategorized,Untopiced,Implement bicubic grid sampler (#44780)
31ebac3eb7,Uncategorized,Untopiced,[quant] Quantized flip dispatch (#46235)
a8ef4d3f0b,Uncategorized,Untopiced,Provide 'out' parameter for 'tensordot' (#47278)
7a0f0d24d0,Uncategorized,Untopiced,Codegen - error when an argument that looks like an out argument isn't a kwarg (fix #43273) (#47284)
3161fe6d5a,Uncategorized,Untopiced,[JIT] SubgraphUtils: add a function for generating a string name for a given graph. (#47253)
a65e757057,Uncategorized,Untopiced,[TensorExpr] CudaCodegen: restart counter for function names unique ID inside each codegen instantiation. (#47254)
9b168a1fed,Uncategorized,Untopiced,[TensorExpr] Pick meaningful names for functions in TE codegen. (#47255)
464c569dbf,Uncategorized,Untopiced,[vulkan] Add mean.dim op for vulkan (#47312)
2caa3bd453,Uncategorized,Untopiced,"Inlining all non-output buffers, including intermediate buffers. (#47258)"
2652f2e334,Uncategorized,Untopiced,Optimize arguments checks (#46661)
f91fcefc81,Uncategorized,Untopiced,[Gradient Compression] Surface C++ comm hooks to Python API as built-in comm hooks (#47270)
dec1c36487,Uncategorized,Untopiced,Create prototype for AST rewriter (#47216)
c6fe65bf90,Uncategorized,Untopiced,[quant][graphmode][fx][fix] Fix error that DefaultQuantizer is not inserted after a module configured with None qconfig (#47316)
53a5f08e0c,Uncategorized,Untopiced,[quant][eagermode] Avoid inserting fakequant for sigmoid/hardsigmoid/tanh in eval mode (#47297)
3a0024574d,Uncategorized,Untopiced,Do not delete rpath from torch.dylib on Darwin (#47337)
0cba3e3704,Uncategorized,Untopiced,[quant][graphmode][fx] Add support for qat convbn{relu}1d (#47248)
a2f9c7d4e3,Uncategorized,Untopiced,Expose SparseLengthsSum8BitRowwiseSparse to C10 (#47306)
0ec717c830,Uncategorized,Untopiced,Support int32 indices and offsets in nn.EmbeddingBag (#46758)
5c4bd9a38f,Uncategorized,Untopiced,Move python-independent c10d implementations to torch/lib (#47309)
996f444c00,Uncategorized,Untopiced,[pt][static_runtime] Memory model (#46896)
f1ac63d324,Uncategorized,Untopiced,Implement copysign (#46396)
07e8f48e6b,Uncategorized,Untopiced,Removing caffe2 and third_party from our code coverage (#47310)
e4bc785dd5,Uncategorized,Untopiced,randperm: add torch check to ensure generator device = tensor device (#47022)
fe17269e75,Uncategorized,Untopiced,"Revert ""Revert D24335982: explicitly error out in comparison ops when the types don't match"" (#47288)"
01da0fe5ff,Uncategorized,Untopiced,Including generator param in randperm documentation (#47231)
4189c3ca76,Uncategorized,Untopiced,Fix onnx test-reports path in CI (#47315)
bba5a31176,Uncategorized,Untopiced,Revert D24481801: Optimize backward for torch.repeat
f588ad6a35,Uncategorized,Untopiced,[quant][graphmode][fx] Test to make sure dequantize node are placed properly (#47332)
2c55426610,Uncategorized,Untopiced,Renamed a TensorListMetaData property. Cleaned up a test (#46662)
6b3802a711,Uncategorized,Untopiced,"[Gradient Compression] Export sizes, along with length and offset of each variable to GradBucket for PowerSGD (#47203)"
5d82311f0d,Uncategorized,Untopiced,Add vulkan reshape op (hack) (#47252)
a11bc04997,Uncategorized,Untopiced,Expand GRADIENT_IMPLEMENTED_FOR_COMPLEX to allow named tensors (#47289)
7ab843e78b,Uncategorized,Untopiced,[JIT] add freeze to docs (#47120)
17be8ae11a,Uncategorized,Untopiced,[pytorch] Remove c10::nullopt_t::init (#47013)
ae7063788c,Uncategorized,Untopiced,[Pytorch] Add basic c10::optional tests (#47014)
6f6025183f,Uncategorized,Untopiced,Skip iomp5 emebedding if torch_cpu could not be found (#47390)
2e5bfa9824,Uncategorized,Untopiced,Add `input` argument to `autograd.backward()` cpp api (#47214)
31c9d2efcd,Uncategorized,Untopiced,Add tests for DDP control flow models. (#47206)
33cf7fddd2,Uncategorized,Untopiced,[NNC] Fix an issue in Cuda fusion with fp16 scalar vars coerced to float (#47229)
da491d7535,Uncategorized,Untopiced,Split up BinaryMiscOpKernels.cu because it's slow to compile. (#47362)
ff3e1de6d7,Uncategorized,Untopiced,Clean up some imports in cuda kernel code. (#47400)
b704cbeffe,Uncategorized,Untopiced,[FX] Speed up non-parameter tensor lookup (#47325)
735f8cc6c2,Uncategorized,Untopiced,[DI] Allow explicit taskLauncher for torchscript interpreter (#46865)
32c76dbecc,Uncategorized,Untopiced,Split IGamma cuda kernel into it's own file to speed up compilation times. (#47401)
030caa190f,Uncategorized,Untopiced,Expand the test of torch.bmm on CUDA (#47124)
8a3728c819,Uncategorized,Untopiced,Make `torch.det()` support complex input. (#45980)
c8872051e6,Uncategorized,Untopiced,Validate number of GPUs in distributed_test. (#47259)
192b2967a5,Uncategorized,Untopiced,[quant][graphmode][fx][test] Add test for nn.Sequential (#47411)
878032d387,Uncategorized,Untopiced,[ONNX] Add export of prim::data (#45747)
5107a411cd,Uncategorized,Untopiced,add partition_by_partition_cost (#47280)
ca293ec4e7,Uncategorized,Untopiced,[TensorExpr] Run constant pooling in fusion groups to dedupe constants. (#47402)
6c5a1c50bf,Uncategorized,Untopiced,Benchmark combining Distributed Data Parallel and Distributed RPC (#46993)
60ae84754e,Uncategorized,Untopiced,Add torch.overrides checks for submodules. (#47285)
c4209f1115,Uncategorized,Untopiced,Fix pickling for Tensor subclasses. (#47115)
0edc6a39c8,Uncategorized,Untopiced,[NNC] Read/Write Dependency analysis (#46952)
df5b4696cf,Uncategorized,Untopiced,[Pytorch] Specialize guts of c10::optional for 32-bit scalars (#47015)
f19637e6ee,Uncategorized,Untopiced,Expand the test of torch.addbmm and torch.baddbmm (#47079)
433b55bc7c,Uncategorized,Untopiced,[quant] Add testing coverage for 4-bit embedding_bag sparse lookup op (#47328)
d8c3b2b10c,Uncategorized,Untopiced,[quant][pyper] Add support for pruned weights in embedding_bag_byte lookup (#47329)
a4ba018e57,Uncategorized,Untopiced,Updated docs/test for dot and vdot (#47242)
68954fe897,Uncategorized,Untopiced,Add release note scripts (#47360)
220b3bd667,Uncategorized,Untopiced,Add op benchmark for batch box cox as baseline (#47275)
ae374dc690,Uncategorized,Untopiced,Move igamma cuda specific code to kernel file. (#47410)
9a9529aa84,Uncategorized,Untopiced,Batching rules for complex view functions (#47188)
e40a563050,Uncategorized,Untopiced,"Fix sum batching rule, add simple clone batching rule (#47189)"
1519c7145c,Uncategorized,Untopiced,__noinline__ the top level igamma cuda kernel. (#47414)
9c8078cdfb,Uncategorized,Untopiced,Revert D24659901: Add tests for DDP control flow models.
745899f926,Uncategorized,Untopiced,Revert D24706475: [pytorch][PR] [NNC] Fix an issue in Cuda fusion with fp16 scalar vars coerced to float
5977d1d864,Uncategorized,Untopiced,FixedQParamsFakeQuantize: adjust default quant_min and quant_max (#47423)
7a599870b0,Uncategorized,Untopiced,[ONNX] Update peephole pass for prim::ListUnpack (#46264)
35491412d1,Uncategorized,Untopiced,Revert D24649817: [pytorch][PR] Fix pickling for Tensor subclasses.
eed4a57d54,Uncategorized,Untopiced,Speedup copysign for half and bfloat16 types (#47413)
373246733d,Uncategorized,Untopiced,[FX] get the correct error message (#47108)
c2d4a5b137,Uncategorized,Untopiced,Disable unused docker-pytorch-linux-xenial-py3.6-gcc4.8 job (#47446)
33acbedace,Uncategorized,Untopiced,Added CUDA support for complex input for torch.inverse (#45034)
b4b0fa6371,Uncategorized,Untopiced,add get_device_to_partitions_mapping (#47361)
65241e3681,Uncategorized,Untopiced,add remove_node in Partition class (#47452)
9c8f40516f,Uncategorized,Untopiced,Batched grad for advanced indexing (index) (#47223)
e985503d80,Uncategorized,Untopiced,[NNC] Fix an issue with half-scalar vars coerced to float (Take 2) (#47448)
ceb16d8836,Uncategorized,Untopiced,[Bootcamp] add CUDA kernel checks to ATen/native/cuda (#47466)
a63f391c6f,Uncategorized,Untopiced,[JIT] fix documentation typo (#46926)
ad8c0e57ef,Uncategorized,Untopiced,Add a command-line flag for overriding pthreadpool size (#46781)
9a9383ef2e,Uncategorized,Untopiced,PyTorch NNAPI integration prototype (#46780)
fd72ec53d4,Uncategorized,Untopiced,[JIT] Optimize hot path in ProfilingGraphExecutorImpl::getPlanFor. (#47465)
873652d9ac,Uncategorized,Untopiced,[TensorExpr] Fix LLVM 12 build after LLVM API changes (#47480)
fccfe7bd1a,Uncategorized,Untopiced,[Gradient Compression] Add unit tests that test default Python comm hook implementations (#47158)
fe77ded48a,Uncategorized,Untopiced,Add Python declaration of torch._C and torch._C._autograd modules. (#46622)
73a3e70b24,Uncategorized,Untopiced,Add type annotations for torch._C._distributed_c10d module. (#46623)
eaa993a2e0,Uncategorized,Untopiced,Add type annotations to torch._C._distributed_rpc module. (#46624)
f3ad7b2919,Uncategorized,Untopiced,[JIT][Reland] add list() support (#42382)
1aeefcdaa6,Uncategorized,Untopiced,Revert D24730264: [pytorch][PR] Added CUDA support for complex input for torch.inverse
160db3db4f,Uncategorized,Untopiced,Adding profiling capability to c++ ddp collective functions (#46471)
611080a118,Uncategorized,Untopiced,[hot fix] cuda 11.0.x doesn't support sm86. (#47408)
5614f72534,Uncategorized,Untopiced,Suppres test issues in test_torch running in sandcastle (#47474)
d0d673b043,Uncategorized,Untopiced,Improve reciprocal() and rsqrt() accuracy on arm64 (#47478)
90a90ab1d6,Uncategorized,Untopiced,Add type informations to torch/storage.py (#46876)
47198e3208,Uncategorized,Untopiced,[caffe2] improve core.Net cloning/init performance (24x for large models!) (#47475)
c26c4690fe,Uncategorized,Untopiced,Add sub operator
24b549ba84,Uncategorized,Untopiced,[jit] better message for bad type annotation (#47464)
2572d7a671,Uncategorized,Untopiced,[quant][eagermode][qat][test] Add numerical test for qat convert (#47376)
582e852fba,Uncategorized,Untopiced,[caffe2] Add unittests for schema.Field init (#47512)
8eb228a7f3,Uncategorized,Untopiced,Add support for log_softmax (#47409)
31d041c946,Uncategorized,Untopiced,"Back out ""[c10] make intrusive_ptr available as a pybind holder type"""
637787797b,Uncategorized,Untopiced,[JIT] add support for torch.jit.Final in python 3.6 (#47393)
7af9752fdc,Uncategorized,Untopiced,Fix rounding error flakiness in quantized_test (#47468)
e09ec8eefa,Uncategorized,Untopiced,Update the error message for retain_grad (#47084)
25d1fb519d,Uncategorized,Untopiced,Build nightly binaries only for the latest ROCM (#47503)
3f9697b10e,Uncategorized,Untopiced,Correctly compare Stream IValues (#47303)
a1fef453b6,Uncategorized,Untopiced,Support extra files in _load_for_mobile (#47425)
3253ccbd9f,Uncategorized,Untopiced,Add bool tensor support for where (#47454)
451e7d3db4,Uncategorized,Untopiced,Enable diag for bool Tensors (#47455)
f90da88d8f,Uncategorized,Untopiced,Add complex support for torch.mean [CUDA] (#47048)
9d0c6e9469,Uncategorized,Untopiced,Implement Complex tensor support in all reduce and all gather (#47523)
c19eb4ad73,Uncategorized,Untopiced,BoxWithNMSLimit support int `batch_splits` input (#47504)
29184f86b0,Uncategorized,Untopiced,Correctly print out sign of near-zero double values (#47081)
f23a2a1115,Uncategorized,Untopiced,The dimension being reduced should not be coalesced by TensorIterator (#47237)
6e69a24a1d,Uncategorized,Untopiced,[ONNX] Reimplement _var_mean to ensure non-negative (#47240)
5a5258cb0d,Uncategorized,Untopiced,Support the strided tensor on input for torch.cat (#46859)
781e0ed835,Uncategorized,Untopiced,Support RRef.backward() for Owner RRefs. (#46641)
4a7de2746f,Uncategorized,Untopiced,Add docs on how to toggle TF32 flags on C++ (#47331)
16c72a5a6b,Uncategorized,Untopiced,[pytorch] continue to rewrite gen_python_functions.py with typed models (#46978)
8182558c22,Uncategorized,Untopiced,[PyTorch Mobile] Don't use __ROOT__ for inference only ops
9e0102c10f,Uncategorized,Untopiced,Add AcceleratedGraphModule and serialzie GraphModule to JSON (#47233)
6248e0621c,Uncategorized,Untopiced,Revert D24801481: [pytorch][PR] Add AcceleratedGraphModule and serialzie GraphModule to JSON
4a58f35bef,Uncategorized,Untopiced,[caffe2] Fix duplicate name bug in Net.AddExternalInput (#47530)
59aca02224,Uncategorized,Untopiced,"Implement Tensor.new_empty_strided(sizes, strides, *, dtype, device, requires_grad) (#47225)"
b80da89891,Uncategorized,Untopiced,Batching rule for Tensor.new_empty_strided (#47226)
3d962430a9,Uncategorized,Untopiced,Make gen_op_registration flake8 compliant (#47604)
8339f88353,Uncategorized,Untopiced,Add complex autograd support for torch.mean (#47566)
65e5bd23d8,Uncategorized,Untopiced,[quant] Add _FusedModule type to capture all fused modules for quantization (#47484)
4a2fb34042,Uncategorized,Untopiced,check sparse sizes (#47148)
fbffd959ca,Uncategorized,Untopiced,"Fix compiler warning variable ""num_ivalue_args"" was declared but never referenced detected during: (#47494)"
70d34718b8,Uncategorized,Untopiced,[fx] add missing modules for type annoations (#47537)
77c49e65d5,Uncategorized,Untopiced,[tensorexpr] Fix registration of intrinsics on llvm-fb (#47540)
7bc8fdb6d7,Uncategorized,Untopiced,as_strided batching rule (#47364)
ead86b2419,Uncategorized,Untopiced,"Add batching rule for torch.clone(tensor, torch.contiguous_format) (#47365)"
6214d0ad88,Uncategorized,Untopiced,Update nccl commit tag to head of v2.8 branch (#47603)
a08e8dd70c,Uncategorized,Untopiced,Fix python 3.9 builds on Windows (#47602)
e26c1726cf,Uncategorized,Untopiced,[ONNX] Fix scripting rand/randn/where (#45793)
8d1a6ae51d,Uncategorized,Untopiced,[pytorch] TraceType codegen tweak - newline before redispatch call (#47436)
499d2fad98,Uncategorized,Untopiced,[pytorch] factor out return_names api (#47437)
4159191f0e,Uncategorized,Untopiced,[pytorch] split out trace type generator and migrate to new codegen model (#47438)
a49367e9c9,Uncategorized,Untopiced,Update the docs of torch.eig about derivative (#47598)
5686d2428c,Uncategorized,Untopiced,[ONNX] Slightly improve indexing with ellipsis under scripting (#46571)
b6a2444eff,Uncategorized,Untopiced,[WIP] Adding bunch of unary foreach APIs (#47383)
4c52a56c40,Uncategorized,Untopiced,[caffe2] Properly call super init in schema.py (#47542)
86bb413600,Uncategorized,Untopiced,Optimize backward for torch.repeat (#46726)
2f617c5104,Uncategorized,Untopiced,skip GPU test on sandcastle if sanitizer is enabled (#47626)
8b3f1d1288,Uncategorized,Untopiced,[caffe2] Add __slots__ to all classes in schema.py (#47541)
3dd266304c,Uncategorized,Untopiced,Fix inaccurate note in DistributedDataParallel (#47156)
79f8582289,Uncategorized,Untopiced,[ONNX] Add export of aten::is_floating point (#46442)
8aca85dbcd,Uncategorized,Untopiced,Add diagflat complex support (#47564)
ce11dbbb48,Uncategorized,Untopiced,Vulkan tweaks (#47261)
4841e9ef33,Uncategorized,Untopiced,Add Vulkan op Conv2D. (#46900)
49d5b4d1e1,Uncategorized,Untopiced,move helper functions out of Partitioner class (#47515)
b631c872c9,Uncategorized,Untopiced,Utility that loads a DP/DDP model state dict into a non-DDP model with the same architecture. (#45643)
52fe73a39e,Uncategorized,Untopiced,Enable Python code coverage for onnx runs (#47387)
c8a42c32a1,Uncategorized,Untopiced,Allow large inputs to svd_lowrank. Fix inaccuracy in torch.svd docs. (#47440)
0b30a8d007,Uncategorized,Untopiced,[NNC] Simplify and fix some bugs in Bounds Inference (#47450)
f2eac5df18,Uncategorized,Untopiced,[NNC] Fix lowering of aten::remainder (#47611)
22d21414d7,Uncategorized,Untopiced,Revert D24574649: [pytorch][PR] Utility that loads a DP/DDP model state dict into a non-DDP model with the same architecture.
57dcb04239,Uncategorized,Untopiced,Batched gradient support for view+inplace operations (#47227)
65a72cae2c,Uncategorized,Untopiced,Fix type promotion for trace on CPU. (#47305)
abae12ba41,Uncategorized,Untopiced,only set ccbin flag if not provided by user (#47404)
6bb18b24fb,Uncategorized,Untopiced,[quant][qat] Ensure observer respects device affinity (#47514)
1bf3dc51ae,Uncategorized,Untopiced,[JIT] Add `__prepare_scriptable__` duck typing to allow replacing nn.modules with scriptable preparations (#45645)
5882f2e540,Uncategorized,Untopiced,[caffe2][memonger] Add support for distributed inference predict nets in DAG memonger
1c45631f10,Uncategorized,Untopiced,Revert D24737050: [WIP] Adding bunch of unary foreach APIs
780f854135,Uncategorized,Untopiced,Clear Shape info in frozen modules (#47511)
fa560ceb9c,Uncategorized,Untopiced,[reland] make intrusive_ptr as a pybind holder type (#47586)
22d56319ee,Uncategorized,Untopiced,Moving hypothesis and other installations to Docker (#47451)
cc337069e0,Uncategorized,Untopiced,.circleci: Add python 3.9 to linux binary build matrix (#47235)
ccc53901bd,Uncategorized,Untopiced,Update CONTRIBUTING and gitignore for docs build (#47539)
1a55f5b3ea,Uncategorized,Untopiced,[ONNX] Update batch_norm symbolic to handle track_running_stats=False (#47135)
5cba3cec5a,Uncategorized,Untopiced,fix extensions build flags on newer GPUs (#47585)
497cd2506f,Uncategorized,Untopiced,Add serialize GraphModule to JSON support (#47612)
163adb9fa7,Uncategorized,Untopiced,Add HalfToFloat + FloatToHalf operators to PyTorch (#45092)
17c58720fe,Uncategorized,Untopiced,Revert D24346771: [caffe2][memonger] Add support for distributed inference predict nets in DAG memonger
0a7ebf00f8,Uncategorized,Untopiced,[Reland] Add tests for DDP control flow models. (#47470)
6b94830cdc,Uncategorized,Untopiced,faithful signature support in BoxedKernelWrapper (#47267)
5ce9c70631,Uncategorized,Untopiced,Revert D24735802: [pytorch][PR] [ONNX] Update batch_norm symbolic to handle track_running_stats=False
0fb1356a98,Uncategorized,Untopiced,[ONNX] Fix eye export (#47016)
14f0675903,Uncategorized,Untopiced,[ONNX] Fix dtype for log_softmax export (#46627)
ef5f54b2c6,Uncategorized,Untopiced,added rocm 3.9 docker image (#47473)
7691cf175c,Uncategorized,Untopiced,[ROCm] set ROCM_ARCH to gfx900 and gfx906 for CI builds (#47683)
8e3af9faa8,Uncategorized,Untopiced,[pytorch] fix debug symbol flag for android clang (#46331)
febc76a5c6,Uncategorized,Untopiced,fix assert_allclose doesnt check shape (#47580)
a843d48ead,Uncategorized,Untopiced,Grammatically updated the tech docs (#47345)
f692af209d,Uncategorized,Untopiced,add unittest for operator benchmark (#47678)
c9d37675b2,Uncategorized,Untopiced,"Back out ""[pytorch][PR] The dimension being reduced should not be coalesced by TensorIterator"" (#47642)"
6575e674ce,Uncategorized,Untopiced,"[numpy] torch.{all, any} : Extend Dtype Support (#44790)"
bf6a156f64,Uncategorized,Untopiced,Fix kthvalue error for scalar input (#47600)
69532c4227,Uncategorized,Untopiced,Vulkan MobileNetv2 unit test. (#47616)
4de40dad5d,Uncategorized,Untopiced,[ONNX] Improve stability of gemm export (#46570)
1b954749d0,Uncategorized,Untopiced,Disable test_distributed_for for multigpu test env (#47703)
a5e9fa1b0d,Uncategorized,Untopiced,Add max_src_column_width to autograd profiler (#46257)
e914a1b976,Uncategorized,Untopiced,Support default args in symbolic tracing (#47615)
51a661c027,Uncategorized,Untopiced,"[vulkan] tentative fix for conv2d_pw, and fix checks for addmm (#47723)"
a5c65b86ce,Uncategorized,Untopiced,Fixed einsum compatibility/performance issues (#46398)
bfec376e9f,Uncategorized,Untopiced,[vulkan] Apply new changes to vulkan api v1 (#47721)
cbf439caf1,Uncategorized,Untopiced,Unbreak backward compatibility tests (#47726)
0650a6166f,Uncategorized,Untopiced,[c10d] switch ProcessGroup::Work to be managed by intrusive_ptr (#44046)
0cfe3451d4,Uncategorized,Untopiced,[c10d] switch Store to be managed by intrusive_ptr (#47074)
ae5c2febb9,Uncategorized,Untopiced,[c10d] switch ProcessGroupNCCL:Options to be managed by intrusive_ptr (#47075)
5647f0ca7c,Uncategorized,Untopiced,Revert D24859919: [pytorch][PR] Grammatically updated the tech docs
88ec72e1c2,Uncategorized,Untopiced,[fbcode][pytorch mobile] Create model reader utilities.
48ed577fbd,Uncategorized,Untopiced,Stop including TypeDefault.h from MPSCNNTests.mm (#46998)
4cb73f5a4c,Uncategorized,Untopiced,Allow for string literal return during symbolic tracing (#47618)
1239d067ae,Uncategorized,Untopiced,[quant][graphmode][fx] Support standalone_module_class (#47705)
d478605dec,Uncategorized,Untopiced,Fix classmethod override argument passing. (#47114)
0c64f9f526,Uncategorized,Untopiced,Convert from higher order functions to classes in tools.codegen.gen (#47008)
2204374fd4,Uncategorized,Untopiced,Revert D24667127: [c10d] switch ProcessGroupNCCL:Options to be managed by intrusive_ptr
1f946e942d,Uncategorized,Untopiced,Revert D24667128: [c10d] switch Store to be managed by intrusive_ptr
dac0192148,Uncategorized,Untopiced,Revert D23632280: [c10d] switch ProcessGroup::Work to be managed by intrusive_ptr
d1351c66a8,Uncategorized,Untopiced,[FX] Add a bunch of docstrings (#47719)
dbfee42a7d,Uncategorized,Untopiced,[FX] Fix uses not updating when erasing a node (#47720)
a1db5b0f2b,Uncategorized,Untopiced,Added CUDA support for complex input for torch.inverse #2 (#47595)
513f62b45b,Uncategorized,Untopiced,[hotfix] fix collect_env not working when torch compile/install fails (#47752)
4078f44668,Uncategorized,Untopiced,[TB][embedding supporting] Modify histogram to accept multipy types to skip Castop and avoid OOMing in Castop
da2e2336b6,Uncategorized,Untopiced,[ONNX] Export and shape inference for prim uninitialized in If subblock (#46094)
1abe6e5ad4,Uncategorized,Untopiced,[ONNX] Bool inputs to index_put updated symbolic (#46866)
6c815c71b3,Uncategorized,Untopiced,Revert to use NCCL 2.7.8-1 (#47638)
fc24d0656a,Uncategorized,Untopiced,"Tensor.contiguous, Tensor.is_contiguous batch rule (#47621)"
f6ff6478cf,Uncategorized,Untopiced,Make kwargs argument optional in _batched_grad_test (#47625)
df887936a4,Uncategorized,Untopiced,Fix transpose batching rule (#47628)
05a76ed705,Uncategorized,Untopiced,Batching rule for torch.squeeze(tensor) (#47632)
7864ae9f98,Uncategorized,Untopiced,Improve error messages for operator registration API (#47636)
fcd44ce698,Uncategorized,Untopiced,Add instruction on how to handle the potential linker error on Linux (#47593)
f2b7c38735,skip,Untopiced,Automated submodule update: FBGEMM (#47605)
0c54ea50bd,Uncategorized,Untopiced,[PyTorch] Avoid atomic refcounting in intrusive_ptr::make (#47100)
32b4b51254,Uncategorized,Untopiced,[Docs] Minor doc fixes for init_process_group (#47644)
d4fa84bf5f,Uncategorized,Untopiced,Properly serialize types that only appear at function input (#47775)
545f624a4a,Uncategorized,Untopiced,Mark overriden Tensor method `override` (#47198)
a0c4aae3d5,Uncategorized,Untopiced,Free original weight after prepacking in XNNPACK based op (#46541)
52ec8b9340,Uncategorized,Untopiced,Added CUDA support for complex input for torch.triangular_solve (#46916)
e8a73fbf34,Uncategorized,Untopiced,Workaround PyTorch debug build crash using old GCC (#47805)
c9f6e70c09,Uncategorized,Untopiced,Refactor DDP uneven inputs control flags (#47394)
c5834b6a23,Uncategorized,Untopiced,Look in named-buffers of module for tensors (#47641)
b46787d6d7,Uncategorized,Untopiced,add cost_aware_partition (#47673)
dd77d5a1d4,Uncategorized,Untopiced,[quant][refactor] factor out get_combined_dict function (#47781)
47386722da,Uncategorized,Untopiced,[quant][graphmode][fx][refactor] insert_observer (#47782)
89b371bc28,Uncategorized,Untopiced,[quant] Add support for 2D indices for quantized embedding operators (#47766)
70ae5685f9,Uncategorized,Untopiced,[reland][c10d] switch ProcessGroup::Work to be managed by intrusive_ptr (#47806)
665ac2f7b0,Uncategorized,Untopiced,[reland] [c10d] switch Store to be managed by intrusive_ptr (#47808)
a02baa0c7a,Uncategorized,Untopiced,[reland][c10d] switch ProcessGroupNCCL:Options to be managed by intrusive_ptr (#47807)
4b25d83e9b,Uncategorized,Untopiced,torch.dropout: fix non-contiguous layout input (#47552)
2907447c97,Uncategorized,Untopiced,Spurious numpy writable warning (#47271)
2df5600155,Uncategorized,Untopiced,[ROCm] add skipCUDAIfRocm to test_lingalg test_norm_fro_2_equivalence_old (#47809)
859e054314,Uncategorized,Untopiced,skip test_all_reduce_sum_cuda_async test case for ROCM (#47630)
553ccccc54,Uncategorized,Untopiced,[c10d] switch ProcessGroup to be managed by intrusive_ptr (#47343)
e1ee3bfc0e,Uncategorized,Untopiced,Port bmm and baddbmm from TH to ATen (#42553)
cfe3defd88,Uncategorized,Untopiced,[vulkan] Enable prepacked addmm/mm for linear layers (#47815)
b6cb2caa68,Uncategorized,Untopiced,"Revert ""Fixed einsum compatibility/performance issues (#46398)"" (#47821)"
00a3add425,Uncategorized,Untopiced,[TorchBind] Support using lambda function as TorchBind constructor (#47819)
809660ffa4,Uncategorized,Untopiced,"ATen DerivedType is dead, long live ATen RegisterDispatchKey (#47011)"
d7c8d3cccb,Uncategorized,Untopiced,Remove references to `typing` module from setup.py (#47677)
9ea7a6c7c5,Uncategorized,Untopiced,[ONNX] Update ONNX doc for writing pytorch model (#46961)
66f9b1de1b,Uncategorized,Untopiced,[NCCL] enable p2p tests (#47797)
1478e5ec2a,Uncategorized,Untopiced,[quant] Remove nn.quantized.ReLU module and nn.quantized.functional.relu (#47415)
f42cdc2e43,Uncategorized,Untopiced,[NNC] Fix printing of integral doubles (#47799)
f221a19a7f,Uncategorized,Untopiced,Force LLVM Compilation for CPU Tests (#46949)
ad5be26b2f,Uncategorized,Untopiced,Small changes/cleanup (#46950)
b8a1070ec0,Uncategorized,Untopiced,[TensorExpr][CPU] Fix bool -> int casting (#46951)
fe81faee5f,Uncategorized,Untopiced,Add more CPU tests (#47369)
e618bd858e,Uncategorized,Untopiced,[NNC] Fix llvm min lowering for int inputs (#47370)
450738441b,Uncategorized,Untopiced,[NNC] Add more CPU Tests (#47371)
346a71d29c,Uncategorized,Untopiced,[NNC] More cpu tests (#47372)
dcca712d3c,Uncategorized,Untopiced,[NNC] refactor cuda half support to more general file (#47373)
664d2f48cf,Uncategorized,Untopiced,[NNC] Enable unary op cpu testing (#47374)
76ff557de7,Uncategorized,Untopiced,[NNC] add hazard analysis to Bounds Inference (#47684)
f51be328ae,Uncategorized,Untopiced,[FX] Fix __tensor_constants not scriptable (#47817)
6aaf04616b,Uncategorized,Untopiced,[Metal] Remove undefined tests
275a89a7ee,Uncategorized,Untopiced,[Docs] Store Docs fixes about HashStore API (#47643)
149190c014,Uncategorized,Untopiced,Added CUDA support for complex input for torch.solve (#47045)
b1a4170ab3,Uncategorized,Untopiced,[NNC] Fix lowering of aten::pow (#47795)
8304c25c67,Uncategorized,Untopiced,Give hash in commit messages in doc push scripts (#47694)
65d5004b09,Uncategorized,Untopiced,"Update, appease, and enable fail-on for shellcheck (#47786)"
8da7576303,Uncategorized,Untopiced,Remove `balance` and `devices` parameter from Pipe. (#46804)
21f447ee2c,Uncategorized,Untopiced,Added serialization of parameters for leaf modules (#47729)
9734c042b8,Uncategorized,Untopiced,[FX] Fix submodule naming for subgraph split (#47869)
7391edb591,Uncategorized,Untopiced,[hotfix] fix misleadingly summary BLAS=MKL when there's no BLAS install (#47803)
3649a2c170,Uncategorized,Untopiced,[numpy] `torch.sqrt` : promote integer inputs to float (#47293)
edf751ca2f,Uncategorized,Untopiced,Make empty c10-full (#46092)
8ff0b6fef8,Uncategorized,Untopiced,[OpBenchMobile] Enable operator_benchmark to run the benchmark on mobile through AiBench (#47767)
a376d3dd5d,Uncategorized,Untopiced,[pytorch] strip out warning message ifdef STRIP_ERROR_MESSAGES (#47827)
4f538a2ba4,Uncategorized,Untopiced,[pytorch][bot] update mobile op deps (#47825)
eb8331e759,Uncategorized,Untopiced,Revert D24524219: Remove `balance` and `devices` parameter from Pipe.
eab809377d,Uncategorized,Untopiced,[NNC] Remove all deferred expansion from Reductions (#47709)
85c43c3da1,Uncategorized,Untopiced,[ONNX] Convert _len based on the first dimension length (#47538)
9fa681c5e0,Uncategorized,Untopiced,"[ONNX] Add export of prim::dtype, prim::tolist (#46019)"
c4ecbcdcb3,Uncategorized,Untopiced,[quant][graphmode][fx][refactor] insert_observer_for_special_module (#47783)
59e96c55f7,Uncategorized,Untopiced,Support MatMul in c2_pt_converter
1afdcbfbb3,Uncategorized,Untopiced,[quant][graphmode][fx][refactor] insert_observer_for_output_of_the_node (#47784)
a97c7e2ef0,Uncategorized,Untopiced,Profiler benchmark fix (#47713)
dfd946871a,Uncategorized,Untopiced,Move eq.device to lite interpreter
1589ede8dd,Uncategorized,Untopiced,[quant][graphmode][fx] insert_observer_for_input_arg_of_observed_node (#47785)
2712acbd53,Uncategorized,Untopiced,CUDA BFloat16 Dropout (#45005)
0652d755d3,Uncategorized,Untopiced,Fix some flaky tests in test_torch.py and test_nn.py (#46941)
9ee4f499f0,Uncategorized,Untopiced,[OpBench] add _consume_op.list for processing input with type of List[Tensor] (#47890)
ed20e327d7,Uncategorized,Untopiced,[quant] skip tests without fbgemm support (#47800)
16d6af74e6,Uncategorized,Untopiced,[PyTorch] Optimize ~intrusive_ptr for the case of zero weak references (#47834)
a8ca042ec0,Uncategorized,Untopiced,rename torch.Assert to torch._assert (#47763)
b787e748f0,Uncategorized,Untopiced,torch.Assert: make it torch.jit.script'able (#47399)
1aeac97712,Uncategorized,Untopiced,[PyTorch] Remove unnecessary shared_ptr copies in ThreadLocalDebugInfo::get (#47791)
692726812b,Uncategorized,Untopiced,[JIT] Fix function schema subtype checking (#47706)
2ed3430877,Uncategorized,Untopiced,[GPU] Make permuteWeights inline (#47634)
ffd0003022,Uncategorized,Untopiced,Added support for complex input for torch.lu_solve (#46862)
759a548d6e,Uncategorized,Untopiced,add dependency check in cost_aware_partition (#47856)
8855c4e12f,skip,Untopiced,[AutoAccept][Codemod][FBSourceClangFormatLinter] Daily `arc lint --take CLANGFORMAT`
1c7c612af0,Uncategorized,Untopiced,Revert D24543682: [pytorch][PR] Added support for complex input for torch.lu_solve
4cec19b56a,Uncategorized,Untopiced,Revert D24740727: torch.Assert: make it torch.jit.script'able
e5da3b6097,Uncategorized,Untopiced,Revert D24891767: rename torch.Assert to torch._assert
d4db4718fa,Uncategorized,Untopiced,Revert D24873991: Profiler benchmark fix
f1babb00f0,Uncategorized,Untopiced,[caffe2] Fix ListWithEvicted _pprint_impl wrongly printing _evicted_values (#47881)
d54497fca7,Uncategorized,Untopiced,Try again to give hash in doc push scripts (#47922)
1915ae9510,Uncategorized,Untopiced,[quant][graphmode][fx][refactor] is_output_quantized (#47879)
03d1978a1a,Uncategorized,Untopiced,[JIT] Resolve string literal type annotations using `Resolver::resolveType` (#47731)
eccbd4df1c,Uncategorized,Untopiced,Remove fbcode/caffe2/mode (#46454)
a3e08e5344,Uncategorized,Untopiced,Support ReduceSum in c2_pt_converter (#47889)
f743b5639a,Uncategorized,Untopiced,[caffe2][memonger] Add support for distributed inference predict nets in DAG memonger (#47718)
5d51b63984,Uncategorized,Untopiced,Use Blocking Wait if both Blocking Wait and Async Error Handling Are Set (#47926)
c0aa863c56,Uncategorized,Untopiced,[quant][graphmode][fx][refactor] insert_quantize_node (#47880)
6a4d55f23c,Uncategorized,Untopiced,[ONNX] Enable onnx shape inference in export by default (#46629)
7b8bd91632,Uncategorized,Untopiced,fp16 -> fp32 EmbeddingBag moved into CPU impl (#47076)
6e42b77be1,Uncategorized,Untopiced,Add '--allow-run-as-root' to mpiexec to allow running distributed test inside a container (#43794)
0125e14c9a,Uncategorized,Untopiced,[OpBench] change relu entry point after D24747035
0685773d8d,skip,Untopiced,Automated submodule update: FBGEMM (#47929)
e8fecd5caf,Uncategorized,Untopiced,Add constructor for ArgumentDef (#47492)
260daf088d,Uncategorized,Untopiced,Added linalg.cholesky (#46083)
ceeab70da1,Uncategorized,Untopiced,Reopen PR for 0 dim batch size for AvgPool2d. (#47426)
5c0dff836a,Uncategorized,Untopiced,Improve dimensionality mismatch warning (#47874)
4380934b9b,Uncategorized,Untopiced,[JIT] Dont use specialized tensor type (#46130)
f86ec08160,Uncategorized,Untopiced,[pytorch][quantization] adding jit state for QuantizedLeakyReLU (#47660)
a9b6fa9e46,Uncategorized,Untopiced,Fix multinomial when input has 0 prob (#47386)
f8c559db8e,Uncategorized,Untopiced,[resubmit] Providing more information while crashing process in async error handling (#47246)
11710598db,Uncategorized,Untopiced,Preserve module parameters in freezing (#47094)
1bdd3687b9,Uncategorized,Untopiced,"Back out ""[JIT] Fix function schema subtype checking"""
550973b675,Uncategorized,Untopiced,Missing curly bracket. (#47855)
2eb1e866e8,Uncategorized,Untopiced,Update links in DDP note (#47663)
4f9d0757f3,Uncategorized,Untopiced,Add type informations to torch.cuda (#47134)
17a6bc7c1b,Uncategorized,Untopiced,Cleanup unused code for Python < 3.6 (#47822)
fe7d1d7d0e,Uncategorized,Untopiced,Add LeakyReLU operator to static runtime (#47798)
c543b3b582,Uncategorized,Untopiced,Fix a downcast (#47919)
982ae987d3,Uncategorized,Untopiced,Revert D24941350: [pytorch][PR] Reopen PR for 0 dim batch size for AvgPool2d.
1606899dbe,Uncategorized,Untopiced,distributed_test: Map rank to GPU accordingly (#47898)
0dbff184e9,Uncategorized,Untopiced,change file name to snake style (#47914)
d91cefb0d8,Uncategorized,Untopiced,[pytorch][codegen] migrate gen_annotated_fn_args.py to new codegen model (#47745)
4ff8cd8f3a,Uncategorized,Untopiced,[pytorch][codegen] gen_python_functions.py loading native_functions.yaml / deprecated.yaml directly (#47746)
c936b43f14,Uncategorized,Untopiced,[pytorch][codegen] add fully migrated scripts to mypy strict config (#47747)
4779553921,Uncategorized,Untopiced,"Revert ""[quant] Remove nn.quantized.ReLU module and nn.quantized.functional.relu (#47415)"" (#47949)"
07e98d28cf,Uncategorized,Untopiced,[pytorch][codegen] migrate gen_variable_factories.py to the new data model (#47818)
f8248543a1,Uncategorized,Untopiced,Pass in smaller timeout into init_process_group for distributed_test (#47896)
0e98fdd389,Uncategorized,Untopiced,[ATen/CPU] Parallelize HalfToFloat + FloatToHalf operators in PT (#47777)
5adf840259,Uncategorized,Untopiced,[pytorch][te][easy] Remove KernelScope from fusion pass tests (#47952)
db1f217d8d,Uncategorized,Untopiced,Add complex support for torch.addcmul and torch.addcdiv (#46639)
d293413b3e,Uncategorized,Untopiced,Batched matmul dtypes (#47873)
8ef7ccd669,Uncategorized,Untopiced,Fix auto exponent issue for torch.pow (#47024)
013e6a3d9d,Uncategorized,Untopiced,Revert D24698027: Fix auto exponent issue for torch.pow
d032d22141,Uncategorized,Untopiced,Replacing CUDA11.0 config with CUDA11.1 in CI (#47942)
cd4aa9c95c,Uncategorized,Untopiced,Fix inplace check logic to be triggered when written to Tensor does not require gradients (#46296)
147a48fb27,Uncategorized,Untopiced,[cmake] clean up cmake/Utils.cmake (#47923)
f9552e6da4,Uncategorized,Untopiced,update windows build guide (#47840)
9aaf7fb398,Uncategorized,Untopiced,[CI] Fix additional CI jobs not launched when PR is created from fork repo (#47969)
957e45a97c,Uncategorized,Untopiced,[NNC] Support vectorization of reductions (#47924)
d20483a999,Uncategorized,Untopiced,Skip dummy node creation for autograd engine when there is a single input and place on correct queue (#47592)
ee995d33bd,Uncategorized,Untopiced,rename torch.Assert to torch._assert (#47763) (#47972)
dea2337825,Uncategorized,Untopiced,torch.Assert: make it torch.jit.script'able (#47399) (#47973)
95ea778ac6,Uncategorized,Untopiced,Set proper output differentiability for unique function (#47930)
550f26c6d5,Uncategorized,Untopiced,Port math kernel for layer_norm from pytorch/xla. (#47882)
825ee7e7f8,Uncategorized,Untopiced,[caffe2] plan_executor_test: add test case for should_stop loops (#47613)
1e0ace7fdc,Uncategorized,Untopiced,Fix docstring typo (#47545)
cf92b0f3a0,Uncategorized,Untopiced,add type annotations to multiprocessing module (#47756)
b12d645c2f,Uncategorized,Untopiced,Test TORCH_LIBRARY in CUDA extension (#47524)
6ec2a89e01,Uncategorized,Untopiced,remove ops in the __caffe2 namespace (#47318)
95b9c2061b,Uncategorized,Untopiced,update legacy dispatcher registration API tests to avoid duplicate def() calls (#47319)
93d9837375,Uncategorized,Untopiced,rename macro. TORCH_LIBRARY_FRAGMENT_THIS_API_IS_FOR_PER_OP_REGISTRATION_ONLY to TORCH_LIBRARY_FRAGMENT (#47320)
cba26e40cf,Uncategorized,Untopiced,migrate export_caffe2_op_to_c10.h macros to the new dispatcher registration API (#47321)
824f710694,Uncategorized,Untopiced,make duplicate def() calls an error in the dispatcher. Updating all fb operators to use the new dispatcher registration API (#47322)
fa0acb73bd,Uncategorized,Untopiced,fix node manipulation in partition class (#48016)
549ef1d668,Uncategorized,Untopiced,[caffe][memonger] Extend operator schema check to dag memonger (#48021)
7b2c78f120,Uncategorized,Untopiced,Revert D24714803: make duplicate def() calls an error in the dispatcher. Updating all fb operators to use the new dispatcher registration API
3611d26a25,Uncategorized,Untopiced,[JIT] Optimize FunctionSchema::checkArg for the Tensor case. (#48034)
43a9d6fb6e,Uncategorized,Untopiced,[TorchScript] Support user defined classes as constants (#5062)
49eb82a7b2,Uncategorized,Untopiced,Fix type annotation errors in torch.distributed.* directory (#47531)
915050ed66,Uncategorized,Untopiced,Fix typing errors in torch.distributed.distributed_c10d.* (#47532)
7f66fa62ca,Uncategorized,Untopiced,Fix typing errors in torch.distributed.nn.* directory. (#47533)
49f0e5dfeb,Uncategorized,Untopiced,"Fix typing errors in torch.distributed.*, close issue #42967. (#47534)"
a03f05f2a2,Uncategorized,Untopiced,"Fix ""pointless comparison"" warning (#47876)"
8aaca4b46a,Uncategorized,Untopiced,[reland][quant] Remove nn.quantized.ReLU module and nn.quantized.functional.relu (#47415) (#48038)
9443150549,Uncategorized,Untopiced,Update Graph docstring to match `__init__.py` (#48100)
315122ce15,Uncategorized,Untopiced,Bump up the CUDA OOM test memory size (#48029)
0d6c900bdb,Uncategorized,Untopiced,docker: Fix PYTHON_VERSION not propagating (#47877)
aabc87cd04,Uncategorized,Untopiced,[NNC] Fix HalfChecker when half present but unused (#48068)
b10d6c6089,Uncategorized,Untopiced,[caffe2] cache NextName indexes for faster name generation (#47768)
d522cd15a3,Uncategorized,Untopiced,"fix BC test, after removing __caffe2 ops (#48099)"
b1c5f06f9e,Uncategorized,Untopiced,"Revert D24925955: Fix ""pointless comparison"" warning"
06707a7ef8,Uncategorized,Untopiced,Fix flake8 failure (#48124)
cb046f7bd2,Uncategorized,Untopiced,[static runtime] Initial memonger (#47759)
e1a101676b,Uncategorized,Untopiced,[quant] ReflectionPad2d (#48036)
04545f4b46,Uncategorized,Untopiced,[quant] out-variant for the reflection pad (#48037)
05dc9821be,Uncategorized,Untopiced,.circleci: Add python 3.9 builds for macOS (#47689)
3846e35a55,Uncategorized,Untopiced,[GPU] Enable Metal on macosx (#47635)
d7e838467a,Uncategorized,Untopiced,[qunat][graphmode][fx] Embedding/EmbeddingBag works in static quant qconfig (#48062)
cdc2d2843b,Uncategorized,Untopiced,Structured kernel definitions (#45277)
568a72bacc,Uncategorized,Untopiced,Fix Vulkan empty (and family) breakage as a result of API update. (#47937)
194ea076b2,Uncategorized,Untopiced,Update VMA. (#47727)
9392137dbe,Uncategorized,Untopiced,"[PyTorch Mobile] Fix for messenger: avoid error with [-Werror,-Wglobal-constructors]"
0adace3706,Uncategorized,Untopiced,fix calculate_extra_mem_bytes_needed_for (#48102)
134bce7cd0,Uncategorized,Untopiced,Adding bunch of unary foreach APIs (#47875)
94cd048bda,Uncategorized,Untopiced,Added foreach_frac API (#47384)
c6c6a53ba0,Uncategorized,Untopiced,[JIT] Fix function schema subtype checking (#47965)
4883d39c6f,Uncategorized,Untopiced,Avoid direct reference to at::native::tensor from TensorDataContainer (#47567)
cc611280d3,Uncategorized,Untopiced,"Revert D24862372: [PyTorch Mobile] Fix for messenger: avoid error with [-Werror,-Wglobal-constructors]"
bc484cfed1,Uncategorized,Untopiced,[c10d][jit] initial torchbind bindings for ProcessGroupNCCL (#42944)
a1f494cb8b,Uncategorized,Untopiced,Fix test_inverse_singular for cublas path; fix cusolver inverse multi-stream issue (#47026)
6049653c20,Uncategorized,Untopiced,[quant][graphmode][fx] Keep linear op unchanged when qconfig is not supported (#48067)
df0ae244a9,Uncategorized,Untopiced,[static runtime] Add out_ variant for aten::stack and aten::nan_to_num (#48150)
2832e325dd,Uncategorized,Untopiced,[TensorPipe] Avoid using deprecated alias for error (#48168)
8c00221fe2,Uncategorized,Untopiced,Fix inconsistent environment variable naming for setting NVTOOLEXT_HOME in TorchConfig.cmake (#48012)
ca8b9437ab,Uncategorized,Untopiced,Add type annotations for a few torch.nn.modules (#46013)
2ff748a680,Uncategorized,Untopiced,Move kthvalue scalar test to separate method for XLA (#48042)
98722ab8a7,Uncategorized,Untopiced,There should be a newline between BUILD WITH CUDA and NVTX (#48048)
21c823970e,Uncategorized,Untopiced,[ROCm] remove sccache wrappers post build (#47947)
e2b4c63dd9,Uncategorized,Untopiced,Enable the faster combined weight branch in MHA when query/key/value is same object with nan (#48126)
1454cbf087,Uncategorized,Untopiced,Make numpy optional dependency for torch.cuda.amp (#48154)
10b490a3e0,Uncategorized,Untopiced,Hipify revamp (#45451)
3ca4c656de,Uncategorized,Untopiced,Install magma on CUDA 11.1 (#48164)
81b1673a21,Uncategorized,Untopiced,Enable complex tests that depend on batched matmul on CUDA (#47910)
a6898cb5f4,Uncategorized,Untopiced,Small documentation changes for RRef and Dist Autograd (#48123)
140e946fec,Uncategorized,Untopiced,Disable distributed collectives profiling tests (#48129)
0387f2a6fa,Uncategorized,Untopiced,Fix default value of `num_replicas` in DistributedSampler docstring (#48135)
df88cc3f7f,Uncategorized,Untopiced,Document that `remainder` does not support complex inputs (#48024)
d256e38823,Uncategorized,Untopiced,[JIT] Pass TypePtr by reference in Argument::type() and Type::isSubtypeOfExt(). (#48061)
68a3a3f3b5,Uncategorized,Untopiced,Add `torch.swapdims` and `torch.swapaxes` (#46041)
8af9f2cc23,Uncategorized,Untopiced,Revert D24924736: [pytorch][PR] Hipify revamp
866f8591be,Uncategorized,Untopiced,Migrate `eig` from the TH to Aten (CUDA) (#44105)
8a996dd139,Uncategorized,Untopiced,[te] Make BUILD_TENSOREXPR_BENCHMARK a real CMake option (#48158)
464d23e6b4,Uncategorized,Untopiced,[te][benchmark] Add more optimized versions of gemm (#48159)
07657b6001,Uncategorized,Untopiced,[tensorexpr] Switch cpp tests to pure gtest (#48160)
5243456728,Uncategorized,Untopiced,[pytorch][codegen] remove dead code in gen_variable_type.py (#47975)
5eaf8562cd,Uncategorized,Untopiced,[pytorch][codegen] simplify dunder method check in gen_python_functions.py (#47976)
a36e646878,Uncategorized,Untopiced,[pytorch][codegen] simplify python signature creation logic (#47977)
ed4dd86567,Uncategorized,Untopiced,move aten::round to lite interpreter (#45931)
0639387ff1,Uncategorized,Untopiced,move Tensor comparisons back to C (#48018)
2fbd70d336,Uncategorized,Untopiced,fft: Generalize fill with conjugate symmetry and use complex dtypes (#46908)
ea1e78a0c5,Uncategorized,Untopiced,Revert D24853669: [pytorch][PR] Migrate `eig` from the TH to Aten (CUDA)
4360486346,Uncategorized,Untopiced,pass strict_fuser_check for recursive fusion (#47221)
0f89be616a,Uncategorized,Untopiced,Removing non-thread-safe log statement from ReinitializeTensor (#48185)
1bafff2366,Uncategorized,Untopiced,[PyTorch][JIT] Skip unnecessary refcounting in TensorType::merge (#47959)
383abf1f0c,Uncategorized,Untopiced,[PyTorch] Make RecordFunction::active private (#47549)
f0f8b97d19,Uncategorized,Untopiced,Introducing winograd transformed fp16 nnpack to PT for unet 106 (#47925)
576fa09157,Uncategorized,Untopiced,[quant][fix] Fix quant type classification for float_qparam qconfig (#48069)
efeb988518,Uncategorized,Untopiced,"Suppress ""ioctl points to uninitialised"" check (#48187)"
72918e475e,Uncategorized,Untopiced,[quant] FakeQuantize inherit from FakeQuantizeBase (#48072)
4c9eb57914,Uncategorized,Untopiced,[PyTorch] Narrow Device to 2 bytes by narrowing DeviceType and DeviceIndex (#47023)
a97d059614,Uncategorized,Untopiced,Get TestTorch.test_empty_meta working again (#48113)
773d1f3208,Uncategorized,Untopiced,[Person Seg] Compress the person seg model (#48008)
5883e0b0e0,Uncategorized,Untopiced,"[quant][fix][ez] Fix quant_type classification for fp16, fp16 (#48073)"
bef460a803,Uncategorized,Untopiced,[PyTorch] Return raw ptr from ThreadLocalDebugInfo::get() (#47796)
4316bf98f5,Uncategorized,Untopiced,[FX] Refactor unique name handling (#48205)
ed57f804fa,Uncategorized,Untopiced,[quant][refactor] Move some util functions from torch/quantization/fx/utils.py to torch/quantization/utils.py (#48107)
6da26fe79b,Uncategorized,Untopiced,[te] Fix pow (#48213)
c5dae335e4,Uncategorized,Untopiced,[PT][StaticRuntime] Move prim op impl to ops.cpp (#48210)
8819bad86c,Uncategorized,Untopiced,Implement igammac (3rd PR) (#48171)
46d846f5bb,Uncategorized,Untopiced,"T78750158 Support varying size input in numeric suite at 10/30/2020, 3:55:01 PM (#47391)"
0d8ddb5ec2,Uncategorized,Untopiced,"Make softmax and log_softmax handle negative dims, add tests (#48156)"
daff3a81a1,Uncategorized,Untopiced,[Gradient Compression] PowerSGD comm hook (#48060)
db767b7862,Uncategorized,Untopiced,Add c10d new frontend to build (#48146)
370310bedb,Uncategorized,Untopiced,"batched grad for binary_cross_entropy, symeig (#48057)"
c4a6df989c,Uncategorized,Untopiced,Pass any verbosity from test/run_test.py to pytest (#48204)
c542614e53,Uncategorized,Untopiced,Implement C++ ModuleDict (#47707)
975ff6624b,Uncategorized,Untopiced,"DOC: backport doc build fix from 1.7, tweak link (#47349)"
a7153a89a5,Uncategorized,Untopiced,Exclude docs/cpp/src from flake8 (#48201)
1dd4f4334c,Uncategorized,Untopiced,docker: Make CUDA_VERSION configurable (#48199)
fe6bb2d287,Uncategorized,Untopiced,[PyTorch] Declare the instantiation of PackedConvWeightsQnnp<2>::prepack (#48256)
008f840e7a,Uncategorized,Untopiced,Implement in-place method torch.cumsum_ and torch.cumprod_ (#47651)
678fe9f077,Uncategorized,Untopiced,Add blas compare example (#47058)
343b3e5cae,Uncategorized,Untopiced,Added linalg.tensorinv (#45969)
9b19880c43,Uncategorized,Untopiced,Fix collect_env.py with older version of PyTorch (#48076)
f98ab18445,Uncategorized,Untopiced,[pytorch][codegen] move is_abstract property to NativeFunction model (#48252)
2039ff3fbb,Uncategorized,Untopiced,[Caffe2] Optimize MishOp on CPU (#48212)
685cd9686f,Uncategorized,Untopiced,Refactor CuFFTConfig to not use tensor objects (#46909)
feb6487acf,Uncategorized,Untopiced,Dont skip NCCL backend when testing all_reduce_cuda (#48231)
c0723a0abf,Uncategorized,Untopiced,Add MessageTypeFlags enum for RPC Messages (#48143)
4b56aef05d,Uncategorized,Untopiced,add kl_based_partition (#48197)
0ea4982cf3,Uncategorized,Untopiced,migrate export_caffe2_op_to_c10.h macros to the new dispatcher registration API (#48097)
3c936ecd3c,Uncategorized,Untopiced,Revert D25056091: migrate export_caffe2_op_to_c10.h macros to the new dispatcher registration API
1a6666c967,Uncategorized,Untopiced,[Gradient Compression] Add a comment on _orthogonalize. (#48253)
84d4e9c4fa,Uncategorized,Untopiced,enable cuda11.1 and cudnn 8.0.5 in CI (#48242)
998c4cac9a,Uncategorized,Untopiced,[FX] Add Node.all_input_nodes (#48270)
7828a22094,Uncategorized,Untopiced,fix a bug in leakyReLU (#48265)
28580d3c0f,Uncategorized,Untopiced,Add TorchBind-based Python and TorchScript binding for ProcessGroup (#47907)
d6b374956f,Uncategorized,Untopiced,[JIT] Resolve `torch.device` in recursive compilation of classes (#47734)
fa41275899,Uncategorized,Untopiced,[Pytorch] Weaker memory ordering for c10::intrusive_ptr (#48221)
de284b6d35,Uncategorized,Untopiced,[pytorch][codegen] add autograd data model (#48249)
56129bdea2,Uncategorized,Untopiced,remove having no deadline for the test (#48226)
efd41db32c,Uncategorized,Untopiced,[TensorExpr] Add more operator tests. (#48282)
eb49dabe92,Uncategorized,Untopiced,[TensorExpr] Add even more operator tests. (#48292)
ec256ab2f2,Uncategorized,Untopiced,implement torch.addr using TensorIterator based kernels (#47664)
562d4c3bc5,Uncategorized,Untopiced,Add basic ldexp operator for numpy compatibility (#45370)
55d5b27343,Uncategorized,Untopiced,Refactor request_callback_no_python.cpp processRpc function (#47816)
68a50a7152,Uncategorized,Untopiced,Replace `GatherRangesToDense` operator in Dper from c2 to pt.
ca880d77b8,Uncategorized,Untopiced,Fix inf norm grad (#48122)
6eaf1e358c,Uncategorized,Untopiced,caffe2/core.Net: is_external_input rebuild lookup tables when necessary
d1b8da75e6,Uncategorized,Untopiced,[JIT] Metacompile boolean constants (#46721)
6d5d336a63,Uncategorized,Untopiced,Revert D25108971: [pytorch][PR] enable cuda11.1 and cudnn 8.0.5 in CI
8177f63c91,Uncategorized,Untopiced,Reorganize and refine the Windows.h import in C++ files (#48009)
7be30d1883,Uncategorized,Untopiced,Move CUDA kernel check to c10 (#48277)
dc843fe197,Uncategorized,Untopiced,Fix test_ldexp on Windows (#48335)
8f1af0947c,Uncategorized,Untopiced,[iOS] Fix the fbios armv7 pika build
87bfb2ff08,Uncategorized,Untopiced,Automatically infer the type of the iterator in a range-based for loop (#48232)
0984d3123a,Uncategorized,Untopiced,[static runtime] add more _out variants (#48260)
286cdf3cda,Uncategorized,Untopiced,[static runtime] add static registry (#48258)
fefd56c4db,Uncategorized,Untopiced,Remove an accidental copy in a range-based for loop (#48234)
f8722825b5,Uncategorized,Untopiced,Compare Weights FX Implementation (#48056)
6d0947c8cf,Uncategorized,Untopiced,Revert D25093315: [pytorch][PR] Fix inf norm grad
0a3db1d460,Uncategorized,Untopiced,[FX] Prototype Conv/BN fuser in FX (#47657)
50e42b9092,Uncategorized,Untopiced,Explicitly cast an implicit conversion from some macro defined type to a double (#48290)
44def9ad71,Uncategorized,Untopiced,[quant][fix] Fix quantization for qat.ConvBnReLU1d (#48059)
16d089733b,Uncategorized,Untopiced,Enable creation and transfer of ScriptModule over RPC (#48293)
6615edaf9a,Uncategorized,Untopiced,[Pytorch Mobile] Disable OutOfPlace calls for mobile (#48255)
fdc62c74a6,Uncategorized,Untopiced,Add Kineto submodule (separate PR) (#48332)
636fa8fda8,Uncategorized,Untopiced,[quant] Add backend_independent option for quantized linear module (#48192)
a00ba63023,Uncategorized,Untopiced,Disable old fuser internally (#48322)
f1d328633c,Uncategorized,Untopiced,Fix mypy error (#48359)
5e1faa1d41,Uncategorized,Untopiced,[TensorExpr] Fix aten::atan2 lowering and disable aten::pow lowering on CPU. (#48326)
b967119906,Uncategorized,Untopiced,[TensorExpr] Fix lowering for aten::div. (#48329)
6400d27bbb,Uncategorized,Untopiced,[Gradient Compression] Define a customized state for PowerSGD comm hook (#48348)
cac553cf34,Uncategorized,Untopiced,[Gradient Compression] clang-format test_c10d.py (#48349)
6b80b664bb,Uncategorized,Untopiced,quant: enable mypy on torch/quantization/fx (#48331)
c5e380bfcb,Uncategorized,Untopiced,quant: add type annotations on quantization.fx.Quantizer class vars (#48343)
f2da18af14,Uncategorized,Untopiced,Add USE_KINETO build option (#45888)
b6654906c7,Uncategorized,Untopiced,Fix assertEqual's handling of numpy array inputs (#48217)
4ed7f36ed1,Uncategorized,Untopiced,"Added linalg.eigh, linalg.eigvalsh (#45526)"
671ee71ad4,skip,Untopiced,[AutoAccept][Codemod][FBSourceClangFormatLinter] Daily `arc lint --take CLANGFORMAT`
2dff0b3e91,Uncategorized,Untopiced,Fix typos in comments (#48316)
2e0a8b75d8,Uncategorized,Untopiced,An implementation of torch.tile as requested in pytorch/pytorch#38349 (#47974)
e9efd8df1b,Uncategorized,Untopiced,[numpy] `torch.log1p` : promote integer inputs to float (#48002)
f7a8bf2855,Uncategorized,Untopiced,Use libkineto in profiler (#46470)
8581c02a3f,Uncategorized,Untopiced,quant: add type annotations on quantization.fx.Quantizer matches (#48350)
1d984410fb,Uncategorized,Untopiced,quant fx: fix typo (#48356)
bc2c1d7d59,Uncategorized,Untopiced,quant: make each line of fx/quantize.py <=80 chars (#48357)
33cc1d6a64,Uncategorized,Untopiced,[docs] fix torch.swap{dim/axes} to showup in docs (#48376)
9ecaeb0962,Uncategorized,Untopiced,[numpy] Add unary-ufunc tests for `erf` variants (#47155)
4ab2055857,Uncategorized,Untopiced,Re-enable only cuda tests wrongly disabled before (#48429)
3858aaab37,Uncategorized,Untopiced,Fix syntax issue in c++ cuda api note (#48434)
55e225a2dc,Uncategorized,Untopiced,Int8 FC fix to match NNPI ICE-REF step-C (#48459)
db1b0b06c4,Uncategorized,Untopiced,Flake8 fixes (#48453)
f1c985695c,Uncategorized,Untopiced,Enabled gloo backend in test_distributed unit tests for ROCm (#40395)
e56e21b775,Uncategorized,Untopiced,Grammatically update the readme docs (#48328)
6a37582162,Uncategorized,Untopiced,Fix misleading doc string in quint8.h (#48418)
18ae12a841,Uncategorized,Untopiced,Refactor mkl fft planning to not use Tensor objects (#46910)
e7ca62be08,Uncategorized,Untopiced,Fix PyTorch compilation on Apple M1 (#48275)
8b248af35d,Uncategorized,Untopiced,Alias _size_N_t to BroadcastingListN[int] (#48297)
c5ce995834,Uncategorized,Untopiced,reintroduce deadline removal (#48481)
84fafbe49c,Uncategorized,Untopiced,[docs] docstring for no type checked meshgrid (#48471)
5dfced3b0d,Uncategorized,Untopiced,work around #47028 until a proper fix is identified (#48405)
7df8445242,Uncategorized,Untopiced,torch.fft: Remove complex gradcheck workaround (#48425)
f95af7a79a,Uncategorized,Untopiced,[numpy] `torch.erf{c}` : promote integer inputs to float (#48472)
344918576c,Uncategorized,Untopiced,Migrate `eig` from the TH to Aten (CUDA) (#44105)
25ab39acd0,Uncategorized,Untopiced,[numpy] `torch.asin` : promote integer inputs to float (#48461)
272f4db043,Uncategorized,Untopiced,Implement NumPy-like function torch.float_power() (#44937)
36c87f1243,Uncategorized,Untopiced,Refactors test_torch.py to be fewer than 10k lines (#47356)
2fe382e931,Uncategorized,Untopiced,annotate torch._tensor_str (#48463)
0e5682d26b,Uncategorized,Untopiced,Pruning codeowners who don't actual do code review. (#48109)
755b8158e2,Uncategorized,Untopiced,Fix __config__ docs (#48557)
bdf360f9f2,Uncategorized,Untopiced,[ONNX] Update onnx submodule (#47366)
5cb688b714,Uncategorized,Untopiced,Merge all vec256 tests into one framework (#47294)
5bb2a87a94,Uncategorized,Untopiced,Update sleef to fix build issues (#48529)
3c9e71c9ad,Uncategorized,Untopiced,fix BUILD_MOBILE_BENCHMARK typo (#48515)
e41d8b3d3d,Uncategorized,Untopiced,[JIT] adding missing test cases for test_isinstance.py (#47396)
af520d9d04,Uncategorized,Untopiced,[cmake] clean up blas discovery (#47940)
0213a3858a,Uncategorized,Untopiced,.circleci: Add python 3.9 builds for windows (#48138)
42e7cdc50a,Uncategorized,Untopiced,Improve libuv detection on Windows (#48571)
4e15877d5c,Uncategorized,Untopiced,Add documentation for torch.overrides submodule. (#48170)
fe80638212,Uncategorized,Untopiced,added docs to nn.rst (#48374)
eba96b91cc,Uncategorized,Untopiced,"Back out ""[pytorch][PR] [JIT] Add `__prepare_scriptable__` duck typing to allow replacing nn.modules with scriptable preparations"""
b84d9b48d8,Uncategorized,Untopiced,Fix the typo errror in the line #953 of the docs of 'torch/nn/modules/activation.py' (#48577)
032e4f81a8,Uncategorized,Untopiced,Fix test comparison ops check for scalar overflow (#48597)
b5149513ec,Uncategorized,Untopiced,"migrate export_caffe2_op_to_c10.h macros to the new dispatcher registration API, update code_analyzer regex (#48308)"
8f8738ce5c,Uncategorized,Untopiced,"[vmap] implement batching rules for clamp, clamp_min and clamp_max (#48449)"
66440d1b29,Uncategorized,Untopiced,Tweak Vulkan memory use. (#47728)
d74f2d28a1,Uncategorized,Untopiced,Fix bazel build after sleef update (#48614)
d386d3323f,Uncategorized,Untopiced,[dper] supress excessive msg (#48404)
4976208e73,Uncategorized,Untopiced,[caffe2] Register BlackBoxPredictor AllocationArenaPool as CPUCachingAllocator (#48161)
2200e72293,Uncategorized,Untopiced,[CUDA graphs] Make CUDAGeneratorImpl capturable (#47989)
d6ddd78eb0,Uncategorized,Untopiced,Fix multiple spelling and grammar mistakes (#48592)
7f869dca70,Uncategorized,Untopiced,[ROCm] update debug flags (#46717)
5b6b1495b9,Uncategorized,Untopiced,"Update Windows CI to CUDA 11.1, cuDNN 8.0.5 (#48469)"
ea0ffbb6e6,Uncategorized,Untopiced,[vulkan] Fix Addmm prepacking to persist after GPU flush (#48313)
c3bb3827f9,Uncategorized,Untopiced,remove unused params in scalar_tensor_static (#48550)
29f0e1e2ce,Uncategorized,Untopiced,Fused8BitRowwiseQuantizedToFloat operator support (#48407)
671a959233,Uncategorized,Untopiced,Disable fast sigmoid since it causes divergence (#48623)
a6f0c3c4f0,Uncategorized,Untopiced,[TensorExpr] IREval: fix div for Half dtype. (#48354)
d9f5ac0805,Uncategorized,Untopiced,[TensorExpr] Add a envvar to disable LLVM backend and use IR Eval instead. (#48355)
adb4fd3f2f,Uncategorized,Untopiced,[te] Fix comparison ops on booleans (#48384)
dc7d8a889e,Uncategorized,Untopiced,caffe2: refactor context to allow being typed (#48340)
61936cb11e,Uncategorized,Untopiced,[PyTorch][JIT] Parameter passing & std::map API usage pass on ProfilingRecord::instrumentGraph (#47960)
ddb6594971,Uncategorized,Untopiced,[Gradient Compression] Add a random generator to PowerSGD state for initializing low-rank matrix Q (#48507)
7a59a1b574,Uncategorized,Untopiced,add aot_based_partition (#48336)
d2e429864c,Uncategorized,Untopiced,[quant][fix] Add bias once in conv_fused (#48593)
9500e8a081,Uncategorized,Untopiced,Testing: Improve interaction between dtypes and ops decorators (#48426)
acd4fca376,Uncategorized,Untopiced,[caffe2][torch] Clean up unused variable 'device' (#48600)
02e58aabe1,Uncategorized,Untopiced,"[ONNX] Support nonzero(*, as_tuple=True) export (#47421)"
55fc0e9e53,Uncategorized,Untopiced,[ONNX] Cast Gather index to Long if needed (#47653)
ccd20e995f,Uncategorized,Untopiced,[vulkan] convolution old prepacking via cpu-shader (#48330)
492683bd42,Uncategorized,Untopiced,Add LazyConvXd and LazyConvTransposeXd (#47350)
dc7ab46dcc,Uncategorized,Untopiced,Fix incorrect warnings in ParameterList/Dict (#48315)
c81f2d9a2f,Uncategorized,Untopiced,Revert D25222215: [quant][fix] Add bias once in conv_fused
736e8965e5,Uncategorized,Untopiced,"Change the type hints of ""pooling.py"". (#48412)"
0066b941f1,Uncategorized,Untopiced,Add CUDA kernel checks to fbcode/caffe2/caffe2/sgd (#48347)
98fddc1f06,Uncategorized,Untopiced,Revert D25172740: [pytorch][PR] [CUDA graphs] Make CUDAGeneratorImpl capturable
f80aaadbae,Uncategorized,Untopiced,fx quantization: add option to leave graph inputs and/or outputs quantized (#48624)
df6fc3d83a,Uncategorized,Untopiced,Fix complex tensors and missing data in benchmark utility (#47871)
74d6a6106c,Uncategorized,Untopiced,Fuzzing benchmark for FFT operators (#47872)
7c73fda501,Uncategorized,Untopiced,Remove `balance` and `devices` parameter from Pipe. (#48432)
aaf6582d02,Uncategorized,Untopiced,fix issue by which pytorch_jni is not bundled in libtorch (#46466)
c5f1117be2,Uncategorized,Untopiced,[ROCm] remove builds for versions less than 3.8 (#48118)
9342b97363,Uncategorized,Untopiced,change global_fp16_constants for test_fc_nnpi_fp16 (#48663)
d1df4038ff,Uncategorized,Untopiced,[PyTorch] Make RecordFunctionCallback::should_run_ a function pointer (#48274)
3ceec73db9,Uncategorized,Untopiced,[PyTorch] Lazily construct guts of RecordFunction (#47550)
5f181e2e6e,Uncategorized,Untopiced,centos now installs cmake from conda (#48035)
e3713ad706,Uncategorized,Untopiced,Let JIT unpickler to accept CUDA DataPtr from read_record_ (#46827)
d9c76360b2,Uncategorized,Untopiced,Add cuda_ipc channel to TensorPipe (#46791)
54022e4f9b,Uncategorized,Untopiced,add new build settings to torch.__config__ (#48380)
4fe583e248,Uncategorized,Untopiced,fix move default not compile correctly on cuda92 (#48257)
1c02be1b6a,Uncategorized,Untopiced,Fix AttributeError in _get_device_attr (#48406)
30324d1e71,Uncategorized,Untopiced,fix INTERNAL ASSERT FAILED for maximum (#48446)
75f38c2fa9,Uncategorized,Untopiced,"ret is never reassigned, return 0 directly (#48609)"
f5788898a9,Uncategorized,Untopiced,TensorIteratorConfig is not used by reorder_dimensions (#48613)
18f1cb14d5,Uncategorized,Untopiced,Avoid resizing ones array when bias is not used (#48540)
cff1ff7fb6,Uncategorized,Untopiced,Suppress unsigned warning (#48272)
f7986969af,Uncategorized,Untopiced,[FX] Delete values after their last use (#48631)
d0e9523c4f,Uncategorized,Untopiced,[TensorExpr] Add more operator tests. (#48677)
8b2ca28c1d,Uncategorized,Untopiced,Add an option to run RPC tests with TCP init (#48248)
25e367ec48,Uncategorized,Untopiced,Revert D25246563: [pytorch][PR] [ROCm] remove builds for versions less than 3.8
b824fc4de2,Uncategorized,Untopiced,[pytorch] [PR] Rename cuda kernel checks to C10 (#48615)
27905dfe9c,Uncategorized,Untopiced,Expose CXX_FLAGS through __config__ (#47861)
07f038aa9d,Uncategorized,Untopiced,Add option for cpp_extensions to compile standalone executable (#47862)
17ea11259a,Uncategorized,Untopiced,Rework compat bindings. (#47863)
0225d3dc9d,Uncategorized,Untopiced,Add support for timing C++ snippets. (#47864)
ff097299ae,Uncategorized,Untopiced,Enable callgrind collection for C++ snippets (#47865)
40a2dd7e1e,Uncategorized,Untopiced,Add type annotations to torch.onnx.* modules (#45258)
15abf18b67,Uncategorized,Untopiced,[MaskR-CNN] Add int8 aabb bbox_transform op
44016e66c4,Uncategorized,Untopiced,Revert D25097324: [pytorch][PR] [ONNX] Cast Gather index to Long if needed
bcc85a363e,Uncategorized,Untopiced,[numpy] `torch.sigmoid` : promote integer inputs to float (#47551)
6299c870ee,Uncategorized,Untopiced,Revert D25254920: [pytorch][PR] Add type annotations to torch.onnx.* modules
6646ff122d,Uncategorized,Untopiced,Revert D25199264: Enable callgrind collection for C++ snippets
74330e0497,Uncategorized,Untopiced,Added linalg.matrix_rank (#48206)
463e5d2f12,Uncategorized,Untopiced,Disable pruning on embedding look up operators when compressed_indices_mapping = {0} (#48672)
9c6979a266,Uncategorized,Untopiced,[Gradient Compression] Error feedback for PowerSGD (still need to fix the key in error_dict) (#48670)
47db191f0c,Uncategorized,Untopiced,Implement Kumaraswamy Distribution (#48285)
b4f5efa7b2,Uncategorized,Untopiced,Structured kernels generate Meta registrations (#48116)
ba5686f8c5,Uncategorized,Untopiced,Refactor argument fields in FunctionSchema to Arguments (#48182)
742903c0df,Uncategorized,Untopiced,Move argument grouping into FunctionSchema (#48195)
6ba7709415,Uncategorized,Untopiced,Refactor TensorIterator to do allocations via MetaBase::set_output (#48659)
e097f8898c,Uncategorized,Untopiced,Move var and std overloads to Functions.cpp and remove native:: reference (#48683)
6d6e9abe49,Uncategorized,Untopiced,Delete NativeFunctions.h include from Functions.h (#48687)
e41e780f7a,Uncategorized,Untopiced,Added support for complex input for torch.lu_solve #2 (#48028)
3b25af02a4,Uncategorized,Untopiced,matrix_exp + matrix_exp.backward complex support (#48363)
4abca9067b,Uncategorized,Untopiced,Fix dataloader hang with large sampler (#48669)
dc367e7903,Uncategorized,Untopiced,"Delete ""-b"" flag from pip install command (#48722)"
c98c98d77d,Uncategorized,Untopiced,Migrate `fmod` and `fmod_` from TH to ATen (CUDA) (#47323)
3c5db30eaa,Uncategorized,Untopiced,Update magma to 2.5.4 for Windows (#48656)
f61de25dfa,Uncategorized,Untopiced,Fix index_put doc. (#48673)
0db73460db,Uncategorized,Untopiced,[quantization] fix run_arg tiny bug (#48537)
52f0af03f8,Uncategorized,Untopiced,[reland][quant][fix] Add bias once in conv_fused (#48593) (#48661)
b2ec21a05a,Uncategorized,Untopiced,[ROCm] Enable deterministic rocBLAS mode (#48654)
022c929145,Uncategorized,Untopiced,"Revert ""Revert D25199264: Enable callgrind collection for C++ snippets"" (#48720)"
4fcdbb824b,Uncategorized,Untopiced,Updating all call-sites of the legacy dispatcher registration API in fbcode to the new API. (#48178)
4d26941a9b,Uncategorized,Untopiced,Fix lite interpreter record function issue. (#47457)
bdb68d9b0b,Uncategorized,Untopiced,[reland] [ROCm] remove versions less than 3.8 (#48723)
15fc66d6c8,Uncategorized,Untopiced,fix nvrtc PTX architecture cap for CUDA toolkit (#48455)
ce3484595e,Uncategorized,Untopiced,[packaging] missing quotation in graphviz printout (#48344)
88735f2cc9,Uncategorized,Untopiced,[package] move importer logic into import pickler (#48632)
83c76611d5,Uncategorized,Untopiced,[package] Support glob matching (#48633)
4aa5d68874,Uncategorized,Untopiced,[JIT] Fix clang-tidy warnings for jit/api (#47981)
3039d24f4a,Uncategorized,Untopiced,[JIT] Fix clang-tidy warnings for jit/frontend (#47982)
9b973eb275,Uncategorized,Untopiced,[JIT] Fix clang-tidy warnings jit/ir (#47983)
8746e1a1cc,Uncategorized,Untopiced,[JIT] Fix clang-tidy warnings in jit/passes (#47984)
18eccfbe42,Uncategorized,Untopiced,[JIT] Fix clang-tidy warnings in jit/python (#47985)
34b2304e34,Uncategorized,Untopiced,[JIT] Fix clang-tidy warnings in jit/testing (#47986)
a25d52f4e6,Uncategorized,Untopiced,[JIT] Fix clang-tidy warnings in jit/serialization (#47991)
fc1153a8be,Uncategorized,Untopiced,[JIT] Fix clang-tidy warnings in jit/runtime (#47992)
a49e2c5ce6,Uncategorized,Untopiced,"Remove ""-b"" option from `pip install` command (#48742)"
a4e13fcf3f,Uncategorized,Untopiced,add type annotations to common_nn.py (#48190)
de46369af7,Uncategorized,Untopiced,[vulkan] Distribute weight prepacking along y dimension for conv2d (#48266)
b006c7a132,Uncategorized,Untopiced,Add reparameterization support to `OneHotCategorical` (#46610)
90a3049a9a,Uncategorized,Untopiced,[fix] repr(torch.device) (#48655)
95311add49,Uncategorized,Untopiced,Vulkan linear memory allocator. (#48569)
5f62308739,Uncategorized,Untopiced,Hipify revamp [REDUX] (#48715)
a1daf1e678,Uncategorized,Untopiced,Use fastAtomicAdd in GPU upsampling trilinear (#48675)
0d39bd47cf,Uncategorized,Untopiced,only enable cudnn persistent RNN when batchsize % 8 == 0 (#48070)
1195403915,Uncategorized,Untopiced,[NNC] Add cpu fusion gflag (#48682)
c465602d78,Uncategorized,Untopiced,Refactor existing JIT testing utils to enable new OpInfo test suite to reuse existing logic (#47695)
9c35a68094,Uncategorized,Untopiced,Refactored assertAutodiff test to have better error message (#48567)
90faf43151,Uncategorized,Untopiced,Support for OpInfo-based testing for operators in JIT (#47696)
0e4f9a7872,Uncategorized,Untopiced,"Refactored OpInfo testing to support custom SampleInputs, added addmm to op_db to test (#48627)"
ea573ea944,Uncategorized,Untopiced,[qunat][graphmode][fx] Standalone module takes float as input and output (#48671)
5f105e2aa6,Uncategorized,Untopiced,Add test for empty tensors for batch matmuls (#47700)
85c1e8acdc,Uncategorized,Untopiced,Replace kernel resource strings with real .cu source files (#48283)
1112773cf5,Uncategorized,Untopiced,Fix unintended error when worker force kill happens #43455 (#43462)
79b9c03465,Uncategorized,Untopiced,Optimize torch zeros (#45636)
c7746adbc6,Uncategorized,Untopiced,Revert D24874754: [pytorch][PR] Add test for empty tensors for batch matmuls
313e77fc06,Uncategorized,Untopiced,Add broadcast_shapes() function and use it in MultivariateNormal (#43935)
5489a98cd3,Uncategorized,Untopiced,Add support for CorrCholeskyTransform (#48041)
0484b048d0,Uncategorized,Untopiced,Replace constexpr with CONSTEXPR_EXCEPT_WIN_CUDA (#48717)
ef50c94e7c,Uncategorized,Untopiced,reenabling MPI test (#48725)
c01e5b8827,Uncategorized,Untopiced,Simplify CachingAllocator. (#48752)
d6f9e8562b,Uncategorized,Untopiced,Generalize some TensorIterator consumers to take TensorIteratorBase (#48727)
f9a0abfc43,Uncategorized,Untopiced,Fix code review from #48659 and #48116 (#48731)
93973ee699,Uncategorized,Untopiced,Header cleanup (#48728)
92f376147c,Uncategorized,Untopiced,Enable TCPStore on Windows (#47749)
befab0d9d4,Uncategorized,Untopiced,[ONNX] Cast Gather index to Long if needed (#47653)
5c9cef9a6c,Uncategorized,Untopiced,[numpy] Add `torch.moveaxis` (#48581)
416dc68341,Uncategorized,Untopiced,[Pytorch][Annotation] Update inlined callstack with module instance info (#47416)
c2ad3c4e6a,Uncategorized,Untopiced,Add scary comment in cpp_custom_type_hack.h (#48737)
2cb9204159,Uncategorized,Untopiced,"Add nondeterministic alert to index_copy, median CUDA and kthvalue CUDA (#46942)"
dabc286ab3,Uncategorized,Untopiced,Remove output used only by sizes (#448) (#47665)
b726a1bbf8,Uncategorized,Untopiced,quantize bias of the quantization parameters (#48749)
c134f32835,Uncategorized,Untopiced,Implemented torch.inner (#46716)
47aa253632,Uncategorized,Untopiced,[Feature] Allow user to specify a fraction of the GPU memory. (#48172)
1eed54d17a,Uncategorized,Untopiced,Upgrade oneDNN (mkl-dnn) to v1.7 (#47853)
e7038a7725,Uncategorized,Untopiced,Improve an autograd warning (#48765)
b3ac628081,Uncategorized,Untopiced,[JIT] Fix bug in get_annotation_str for ast.Subscript (#48741)
cc1c3063c5,Uncategorized,Untopiced,Add test binary to compare torch model outputs (#47933)
cf1e5d7d2b,Uncategorized,Untopiced,Ignore MSVC's pdb file (#47963)
16fd1c32c5,Uncategorized,Untopiced,[ONNX] Update batch_norm symbolic to handle track_running_stats=False (#47903)
536352e86f,Uncategorized,Untopiced,fx quant: clean up functions in _generate_qconfig_map (#48772)
c98c617b44,Uncategorized,Untopiced,fx quant: clean up functions in _prepare (#48773)
f5bcf45e3b,Uncategorized,Untopiced,fx quant: add more typehints (#48774)
54da2dadd8,Uncategorized,Untopiced,"fx quant: more typehints, part 2 (#48792)"
f5d94244b2,Uncategorized,Untopiced,"fx quant: more typehints, part 3 (#48794)"
c55d45f04b,Uncategorized,Untopiced,[qnnpack] Fix unused var warning when building for different archs. (#48730)
86540dbf41,Uncategorized,Untopiced,Fix jit doc model loading example (#48104)
f065087567,Uncategorized,Untopiced,[ONNX] Handle dynamic input axes for prim_ConstantChunk (#48176)
15bc21c280,Uncategorized,Untopiced,[ONNX] Track and list model params for scripting (#47348)
5fd61de99e,Uncategorized,Untopiced,[ONNX] Added hardswish symbolic in opset 9 (#48423)
2181ff89bb,Uncategorized,Untopiced,[vulkan][test] Not use non 1 dilation for conv2d (#48800)
4cc163f8ec,Uncategorized,Untopiced,Add deadline to fakelowp tests (#48823)
cb285080b0,Uncategorized,Untopiced,Added computing matrix condition numbers (linalg.cond) (#45832)
6ab84ca0f3,Uncategorized,Untopiced,Implement NumPy-like function torch.msort() (#48440)
eb43e12ee4,Uncategorized,Untopiced,Revert D25277886: [pytorch][PR] Replace constexpr with CONSTEXPR_EXCEPT_WIN_CUDA
3a0d4240c3,Uncategorized,Untopiced,Fix broadcast_all crashing on Tensor-likes (#48169)
bc2352e8c3,Uncategorized,Untopiced,[NNC] Complete SimpleIREvaluator support for bitwise ops (#48053) (#48179)
07d185ef05,Uncategorized,Untopiced,[ROCm] add 3.10 docker image (#48791)
fadec77c30,Uncategorized,Untopiced,[quant][fx][graphmode] Renable torchvision test (#48602)
a5fb12d168,Uncategorized,Untopiced,RRef proxy support for ScriptModule methods (#48339)
9af627fda1,Uncategorized,Untopiced,fix some typos in the fx ir test_fx_experiemntal (#48847)
31808dcdd8,Uncategorized,Untopiced,[RELAND] [CUDA graphs] Make CUDAGeneratorImpl capturable (ci-all edition) (#48694)
0a42003f8f,Uncategorized,Untopiced,[TensorExpr Fuser] Handle fusing values with un-profiled uses (#48689)
ba3962f5f0,Uncategorized,Untopiced,[Onnxifi] Warmup cache of output shapes (#48346)
714c7020ee,Uncategorized,Untopiced,[Mask R-CNN]Add Int8 AABB Generate proposals Op
42e6951e62,Uncategorized,Untopiced,Remove save_state_warning in LambdaLR (#46813)
7c9ba62130,Uncategorized,Untopiced,Server connects to its listen socket addr (#46801)
e1f9542d00,Uncategorized,Untopiced,Revert D23898398: [Mask R-CNN]Add Int8 AABB Generate proposals Op
4eb4db7c30,Uncategorized,Untopiced,"Support torch.distributed.irecv(src=None, ...) (#47137)"
142b21fd44,Uncategorized,Untopiced,Add SparseLengthsSum4BitRowwiseSparse in c2_pt_converter (#48240)
0f9823d888,Uncategorized,Untopiced,[PyTorch] Save some space in ProcessedNode (#48861)
ca3ae7dc73,Uncategorized,Untopiced,[DI] create a new key for threadLocalDebugInfo (#48762)
b9cd774e29,Uncategorized,Untopiced,Get rid of printf in cuda fuser debugPrint() (#46994)
212ec07cb7,Uncategorized,Untopiced,Support torchbind as attribute in torch.fx symbolic tracing (#48732)
4b8d965f18,Uncategorized,Untopiced,"Revert D25292656: [pytorch][PR] Support torch.distributed.irecv(src=None, ...)"
5654fc8edd,Uncategorized,Untopiced,Revert D25293474: [pytorch][PR] Server connects to its listen socket addr
2d07d5b50a,Uncategorized,Untopiced,[te] Don't fuse integer fmod or remainder (#48700)
9bb87fa58b,Uncategorized,Untopiced,[te] Fix spacing in graph dump (#48829)
03abd81b8d,Uncategorized,Untopiced,[ROCm] Enable skipped distributed global tests (#48023)
092e52a4da,Uncategorized,Untopiced,[fx]added prototype of to_folder (#47544)
9e10e3b74f,Uncategorized,Untopiced,[PyTorch] Move TensorImpl::shallow_copy_and_detach to .cpp file (#48680)
3f10518def,Uncategorized,Untopiced,[PyTorch] Add VariableVersion&& overload for TensorImpl::shallow_copy_and_detach (#48681)
a3298c2f64,Uncategorized,Untopiced,Implement JIT serialization of ProcessGroup (#48544)
02d89f9f1d,Uncategorized,Untopiced,scatter_object_list API for c10d (#43930)
f0f315c33b,Uncategorized,Untopiced,[PyTorch] Inline RecordFunctionCallback::shouldRun (#48286)
af30a89068,Uncategorized,Untopiced,[caffe2][a10] Remove unreferenced local variable e (#48601)
55b93735ac,Uncategorized,Untopiced,[PyTorch] Save refcount decrements in StaticRuntime::deallocate_registers (#48859)
6317e0b2f1,Uncategorized,Untopiced,[BE] Fix signed-unsigned warnings (#48848)
7439bc4dd6,Uncategorized,Untopiced,[Gradient Compression] Add an index field to GradBucket for PowerSGD (#48757)
5180caeeb4,Uncategorized,Untopiced,Remove deprecated spectral ops from torch namespace (#48594)
799b700ada,Uncategorized,Untopiced,add a unit test for lack of devices (#48858)
63a71a82cf,Uncategorized,Untopiced,[ROCm] add 3.10 to nightly builds (#48866)
fa5f7d87bf,Uncategorized,Untopiced,fx quant: add typing for fuser (#48844)
0923d19601,Uncategorized,Untopiced,fx quant: add types to quantization_patterns (#48851)
251398acca,Uncategorized,Untopiced,Force a sync on non-CPU tensors for the benchmark to reflect the timing accurately. (#48856)
0fb58d76a1,Uncategorized,Untopiced,Support ArgMin in c2_pt_converter
ae9f39eb58,Uncategorized,Untopiced,[FX][1/2] Make docstrings pretty when rendered (#48738)
0185a05ceb,Uncategorized,Untopiced,Revert D25338250: [pytorch][PR] [BE] Fix signed-unsigned warnings
5de22d3f69,Uncategorized,Untopiced,Removes redundant method_test entries (#48828)
85121a7a0f,Uncategorized,Untopiced,Added CUDA support for complex input for torch.cholesky_solve (#47047)
195ab5e864,Uncategorized,Untopiced,remove non-default settings in fuser.py (#48862)
2e600feda9,Uncategorized,Untopiced,[numpy] `torch.sinh`: promote integer inputs to float (#48644)
17f53bffef,Uncategorized,Untopiced,[Gradient Compression] Replace the key of error_dict in PowerSGD state with bucket index (#48867)
ea2a568cca,Uncategorized,Untopiced,Fixed einsum compatibility/performance issues (#46398) (#47860)
e429d05015,Uncategorized,Untopiced,"Fixing error: ""member may not be initialized"" due to constexpr at Windows (#48836)"
19f4c5110e,Uncategorized,Untopiced,Add another torch::jit::load API to load PyTorch model with shared_ptr PyTorchStreamReader input (#48802)
a39398b9e5,Uncategorized,Untopiced,CUDA BF16 norm (#48806)
00f01791a3,Uncategorized,Untopiced,[Caffe2]Add more error message in ComputeBinaryBroadcastForwardDims
1febd2225b,Uncategorized,Untopiced,Add explicit cast to cuda_atomic_ops_test.cu (#48886)
8bc6023d7a,Uncategorized,Untopiced,Add type annotations to torch.onnx.* modules (#48782)
36df25334f,Uncategorized,Untopiced,Fix incorrect usage of CUDACachingAllocator [v2] (#48817)
21ba48fe49,Uncategorized,Untopiced,[vulkan] test_app for mobilenetV2 on vulkan api (#48924)
f2c3efd51f,Uncategorized,Untopiced,Fix generator exhaustion in SparseAdam (#47724)
ba6511b304,Uncategorized,Untopiced,pyi codegen update - remove Declarations.yaml (#48754)
dad74e58fc,Uncategorized,Untopiced,"[WIP] Added foreach_trunc, foreahc_reciprocal, foreach_sigmoid APIs (#47385)"
924b001b71,Uncategorized,Untopiced,#48733 added logging statements to LLVM codegen using JIT logging (#48758)
d307601365,Uncategorized,Untopiced,Revert D24923679: Fixed einsum compatibility/performance issues (#46398)
88ebf6f894,Uncategorized,Untopiced,Revert D25304229: [pytorch][PR] Add type annotations to torch.onnx.* modules
d6b5f3ad98,Uncategorized,Untopiced,Add object-based collective APIs to public docs (#48909)
b77ca9e829,Uncategorized,Untopiced,[Docs] Add examples for new object-based c10d APIs (#43932)
f67259fe89,Uncategorized,Untopiced,Fix CI by removing gen_pyi from mypy-stirct.ini (#48961)
7629612f9f,Uncategorized,Untopiced,Update torch.randint documentation to include missing note (#48787)
e3893b867f,Uncategorized,Untopiced,Reenable some BF16 tests on CUDA (#48805)
adbb74ded9,Uncategorized,Untopiced,[package] pre-emptively install submodules (#48799)
533c837833,Uncategorized,Untopiced,Register OpInfos for torch.fft transforms (#48427)
c876d4f477,Uncategorized,Untopiced,[Gradient Compression] Let the dtype of created low-rank tensors P and Q be the same type as the input tensor (#48902)
bea88ee1d0,Uncategorized,Untopiced,Added entry for torch.linalg.cond to linalg.rst (#48941)
3aeb9cc85d,Uncategorized,Untopiced,[DOCS]Correct docs for torch.lu_solve (#47762)
5533be5170,Uncategorized,Untopiced,CUDA BF16 backwards (#48809)
881e9583b2,Uncategorized,Untopiced,docker: Add make variable to add docker build args (#48942)
c3a90bedd4,Uncategorized,Untopiced,Move aten::__contains__.int_list for lite jit (#48950)
cb6233aa53,Uncategorized,Untopiced,Fix some convoluted(?) code (#48893)
32b098baf9,Uncategorized,Untopiced,Add and adjust kernel launch checks (#46727)
046ea6696d,Uncategorized,Untopiced,Enable faithful API for all ops (#47711)
3ef36dca8e,Uncategorized,Untopiced,Faithful out arguments (#47712)
b643dbb8a4,Uncategorized,Untopiced,VariableType calls faithful C++ API for c10-full out ops (#47792)
07978bd62e,Uncategorized,Untopiced,[static runtime] fuse inference ops (1) (#48948)
39445f718c,Uncategorized,Untopiced,Revert D25375885: [pytorch][PR] Reenable some BF16 tests on CUDA
e2befb84bc,Uncategorized,Untopiced,minor README change to fix #25464 (#48970)
58c13cf685,Uncategorized,Untopiced,"Back out ""Revert D25375885: [pytorch][PR] Reenable some BF16 tests on CUDA"""
c29f51642e,Uncategorized,Untopiced,Modify NEON check for ARM64 on OS X (#48982)
ad3fed8b90,Uncategorized,Untopiced,[BE] Fix signed-unsigned warnings (#48848)
274ce26fd8,Uncategorized,Untopiced,[static runtime] Add Internal Ops to the registry (#48616)
b0e919cf60,Uncategorized,Untopiced,Avoid initializing gradInput twice in the backward phase of replication (#48890)
b89c328493,Uncategorized,Untopiced,Add fftw3 cmake as alternative for FFT/DFT (#48808)
c92c8598a3,Uncategorized,Untopiced,[FX][2/2] Make docstrings pretty when rendered (#48871)
dee82ef3ea,Uncategorized,Untopiced,Add LKJCholesky distribution (#48798)
0fb9d36660,Uncategorized,Untopiced,Delete ATen mirror stuff (#49028)
2b70bcd014,Uncategorized,Untopiced,[TensorExpr] Enable inlining for output tensors too. (#48967)
d1fb4b4ffc,Uncategorized,Untopiced,Put Flake8 requirements into their own file (#49032)
e8ec84864f,Uncategorized,Untopiced,[StaticRuntime] Add aten::narrow (#48991)
5960581148,Uncategorized,Untopiced,CUDA BFloat16 batchnorm (non-cuDNN) (#44994)
6000481473,Uncategorized,Untopiced,add a unit test for large node error (#48938)
02b63858f2,Uncategorized,Untopiced,[CUDAExtension] support all visible cards when building a cudaextension (#48891)
e538bd6695,Uncategorized,Untopiced,[collect_env] Add candidate paths for nvidia-smi on Windows (#49021)
17e71509a6,Uncategorized,Untopiced,fx quant: quick cleanup for model_device (#48906)
2668ea8087,Uncategorized,Untopiced,fx quant: move qconfig utils to utils file (#48907)
d033e185ed,Uncategorized,Untopiced,fx quant: move more functions to utils (#48908)
3f9ff48ebb,Uncategorized,Untopiced,[JIT] Allow del statements with multiple targets (#48876)
107c31f2f5,Uncategorized,Untopiced,Add a pass to fetch attributes of nn.Module to fx.node (#47935)
993ce4b206,Uncategorized,Untopiced,[quant][graphmode][fx] Add MatchAllNode in pattern matching (#48979)
4434c07a2c,Uncategorized,Untopiced,[quant][fix] Support quantization of ops where input is quantizable (#49027)
5450614cf6,Uncategorized,Untopiced,Correctly apply WIN32_LEAN_AND_MEAN to the whole repo (#49025)
34cc77a811,Uncategorized,Untopiced,Torch onnx (#48980)
7c0a3e3a06,Uncategorized,Untopiced,Annotate torch._tensor_str (#48584)
59a3e76641,Uncategorized,Untopiced,[pt][quant] Remove contiguous calls in qembeddingbag (#48993)
2d9585a6a1,Uncategorized,Untopiced,[quant][graphmode][fx] Add test for ResnetBase (#48939)
1c31f76297,Uncategorized,Untopiced,Add high level profiling trace for dataloading and optimizer (#47655)
e8b00023b2,Uncategorized,Untopiced,[ROCm] restore autograd tests (#48431)
a849f38222,Uncategorized,Untopiced,skip cuda test_cholesky_solve_batched_many_batches due to illegal memory access (#48999)
a20d4511e4,Uncategorized,Untopiced,[PyTorch] TensorImpl::is_non_overlapping_and_dense_ should default to true (#48625)
09b974c2d5,Uncategorized,Untopiced,Extra sampling of record function events (#48289)
71cfb73755,Uncategorized,Untopiced,Add complex support to broadcast_coalesced (#48686)
4b26cafb8f,Uncategorized,Untopiced,make validate debug-only in Device copy ctr (#47854)
73f7178445,Uncategorized,Untopiced,remove redundant sccache wrappers from build.sh scripts (#47944)
9f7fb54693,Uncategorized,Untopiced,Revert D25111515: Extra sampling of record function events
492580b855,Uncategorized,Untopiced,[te] Remove vestigial __init__.py from test/cpp/tensorexpr (#49061)
b3ab25aefa,Uncategorized,Untopiced,[numpy] `torch.cosh`: promote integer inputs to float (#48923)
41fd51d7d8,Uncategorized,Untopiced,[PyTorch] Reference to c10::GetCPUAllocator() directly (#49068)
e5a98c5ab0,Uncategorized,Untopiced,[ONNX] Remove usage of isCompleteTensor() in symbolic functions (#48162)
44f33596d3,Uncategorized,Untopiced,"[pe] Add gflags for num_profiled_runs and bailout_depth, laint (#49059)"
b98e62f8eb,Uncategorized,Untopiced,[te] Add gflag for fast intrinsic expansion (#49060)
c62f3fc40b,Uncategorized,Untopiced,fix clang-tidy warning - make global TorchLibraryInit objects const (#48956)
7584161dfa,Uncategorized,Untopiced,Enhance `new_group` doc to mention using NCCL concurrently. (#48872)
f5e9ffbc27,Uncategorized,Untopiced,Check CUDA kernel launches (/fbcode/caffe2/) (#49105)
fc0a3a1787,Uncategorized,Untopiced,Improve torch.fft n-dimensional transforms (#46911)
7a4a2df225,Uncategorized,Untopiced,Revert D25003113: make validate debug-only in Device copy ctr
bfa95f90a0,Uncategorized,Untopiced,Revert D25325039: Check CUDA kernel launches (/fbcode/caffe2/)
67d12c9582,Uncategorized,Untopiced,Pass shape hints for AOT case (#48989)
c7cc8a48c0,Uncategorized,Untopiced,migrating some straggler pytorch ops in fbcode to the new registration API (#48954)
dfa3808704,Uncategorized,Untopiced,[PyTorch] Remove aten::native::empty usage in TensorIndexing (#49074)
5765bbd78c,Uncategorized,Untopiced,Review memory overlap checks for advanced indexing operations (#48651)
f431e47a2e,Uncategorized,Untopiced,[collect_env] Acquire windows encoding using OEMCP (#49020)
a6fa3b2682,Uncategorized,Untopiced,adding profile_ivalue (#47666)
16b8e6ab01,Uncategorized,Untopiced,"Class-based structured kernels, with migration of add to framework (#48718)"
e9ef1fe309,Uncategorized,Untopiced,[PyTorch Mobile] Add continuous build config for xplat/caffe2
5375a479aa,Uncategorized,Untopiced,Add type annotations to conv-relu (#47680)
e69c2f85f6,Uncategorized,Untopiced,Add version_info tuple (#48414)
3123f878dd,Uncategorized,Untopiced,[PyTorch] Avoid storage refcount bump in copy_tensor_metadata (#48877)
7a2abbd8fd,Uncategorized,Untopiced,Revert D25416620: [pytorch][PR] Add version_info tuple
c5bc6b40ab,Uncategorized,Untopiced,[NNC] Dead Store Elimination (#49030)
9417e92722,Uncategorized,Untopiced,op to gen quant params from min-max thresholds
95233870f2,Uncategorized,Untopiced,[PyTorch Mobile] Preserve bundled input related methods when calling optimize_for_mobile
27f7d1c286,Uncategorized,Untopiced,Port `eig` CPU from TH to ATen (#43215)
eb9516eaa4,Uncategorized,Untopiced,"[numpy] `torch.exp{2, m1}`: promote integer inputs to float (#48926)"
7f7f0fa335,Uncategorized,Untopiced,Avoid using FutureNCCL before it's ready (#48561)
b7f5aa9890,Uncategorized,Untopiced,Remove NCCL dependency from PythonFutureWrapper (#48495)
868a1a48c6,Uncategorized,Untopiced,Add some safeguards to FutureNCCL (#48562)
e4267eb424,Uncategorized,Untopiced,Have FutureNCCL record streams w/ allocator in addCallback (#48496)
8fb52e7fa2,Uncategorized,Untopiced,Make FutureNCCL record events in current stream (#48497)
6157f8aeb5,Uncategorized,Untopiced,Use fresh stream from pool for each FutureNCCL callback (#48498)
b91b0872a1,Uncategorized,Untopiced,"Record CUDA events for ""follow-up"" FutureNCCL inside markCompleted (#48499)"
003c30ba82,Uncategorized,Untopiced,Fix FutureNCCL's completed() disagreeing with wait() (#48503)
91ad3ed831,Uncategorized,Untopiced,Fix FutureNCCL not recording dataptrs with caching alloc in wait() (#48563)
e294c2d841,Uncategorized,Untopiced,Add multi-GPU support to FutureNCCL (#48500)
9fe3ac3650,Uncategorized,Untopiced,Don't store device indices separately on FutureNCCL (#48501)
a6778989d1,Uncategorized,Untopiced,Support wider range of types in FutureNCCL (#48502)
9078088edb,Uncategorized,Untopiced,Split FutureNCCL's CUDA-specific parts from generic future logic (#48504)
4c425e8da0,Uncategorized,Untopiced,Merge common parts of FutureNCCL into at::ivalue::Future (#48505)
030fa6cfba,Uncategorized,Untopiced,Split out reusable CUDAFuture from FutureNCCL (#48506)
b5a7e25059,Uncategorized,Untopiced,Cache the DataPtrs in CUDAFuture (#48788)
2255e68da8,Uncategorized,Untopiced,Revert D25433268: [PyTorch Mobile] Preserve bundled input related methods when calling optimize_for_mobile
c7b8f3e2cd,Uncategorized,Untopiced,Decouple direct access to native::scalar_tensor from TensorIndexing.h (#48761)
33bc7918e8,Uncategorized,Untopiced,fix some comments in accelerator_partitioner.py (#49104)
21c04b4438,Uncategorized,Untopiced,make AT_FFTW_ENABLED available to fb internal
3384145418,Uncategorized,Untopiced,[te] Add BitCast to the IR
195b92bfa6,Uncategorized,Untopiced,Revert D25441716: [te] Add BitCast to the IR
d5c4a80cfd,Uncategorized,Untopiced,Allow ROCm CI to use non-default stream. (#48424)
45473ffe23,Uncategorized,Untopiced,Refactor cudnn convolution (#49109)
25a8397bf3,Uncategorized,Untopiced,add additional interpolation modes for torch.quantile (#48711)
54f0556ee4,Uncategorized,Untopiced,Add missing complex support for torch.norm and torch.linalg.norm (#48284)
524adfbffd,Uncategorized,Untopiced,Use new FFT operators in stft (#47601)
840e71f4e6,Uncategorized,Untopiced,Check CUDA kernel launches (/fbcode/caffe2/) (#49145)
909a9060e9,Uncategorized,Untopiced,[vmap] implement batching rule for fill_ and zero_ (#48516)
edbf9263ad,Uncategorized,Untopiced,[iOS] Bump up the cocoapods version (#49176)
2519348f60,Uncategorized,Untopiced,"[Binary Push] Update the awscli installation, use conda install rather than brew install (#49175)"
18c03b9f00,Uncategorized,Untopiced,make duplicate def() calls an error in the dispatcher (#48098)
70853c5021,Uncategorized,Untopiced,Dont use symbolic shapes check (#47810)
0e666a9f5a,Uncategorized,Untopiced,[TensorExpr] Cache use of fallback in kernel invocation (#47812)
413caa7fd2,Uncategorized,Untopiced,[NNC] Compute Tensor Output Properties in ininitialization (#47813)
71ddc0ba19,Uncategorized,Untopiced,[TensorExpr Fuser] Add support for nodes which have tensor constant inputs (#47814)
0b9d5e65e4,Uncategorized,Untopiced,Remove inferred from tensor type ctors (#48263)
3b57be176e,Uncategorized,Untopiced,[NNC] Preserve strided output (#48264)
0c70585505,Uncategorized,Untopiced,fix #49064 (invalid escape) by using raw strings (#49065)
e1c1a7e964,Uncategorized,Untopiced,[ONNX] Changes to export API to better handle named arguments (#47367)
21dba8c1ad,Uncategorized,Untopiced,Make aten::div.out c10-full (#47793)
c892c3ac9a,Uncategorized,Untopiced,remove hacky_wrapper from BackendSelect (#49079)
a480ca5302,Uncategorized,Untopiced,[JIT] Use `is_buffer` in `BufferPolicy::valid` (#49053)
a3e1bd1fb9,Uncategorized,Untopiced,Preserve submodule with __set_state__ in freezing (#47308)
95a1725a4a,Uncategorized,Untopiced,Vsx initial support issue27678 (#41541)
f4226b5c90,Uncategorized,Untopiced,[static runtime] add static subgraph fusion pass (#49185)
84fce6d29a,Uncategorized,Untopiced,[AARCH64] Fix HAS_VST1 check if compiled by clang (#49182)
69522410fa,Uncategorized,Untopiced,add user vs internal msg support in common_utils.TestCase (#48935)
80f7510d92,Uncategorized,Untopiced,[FX] Fix create_arg for NamedTuple (#48986)
57145c910f,Uncategorized,Untopiced,Revert D24711613: [pytorch][PR] Preserve submodule with __set_state__ in freezing
5e8cfec332,Uncategorized,Untopiced,Add a newline before dependency graph output (#49127)
7feec06dfe,Uncategorized,Untopiced,Only 1 TensorImpl allocation in differentiable views. (#48896)
a47a087a43,Uncategorized,Untopiced,[NNC] Add missing data type support for abs and frac (#48679)
882eb0f646,Uncategorized,Untopiced,[quant][graphmode][fx] Add support for dynamic quant for RNN and RNNCell (#49126)
0dea76ecda,Uncategorized,Untopiced,Delete some dead functions from tools.codegen.api.meta (#49041)
267641a245,Uncategorized,Untopiced,Rename positional and kwarg_only to have flat prefix (#49042)
9b0ffb9fb3,Uncategorized,Untopiced,Delete cpp.group_arguments (#49043)
5469aa5e7f,Uncategorized,Untopiced,[NNC] Add a non functional Tensor kind (#48750)
159f258415,Uncategorized,Untopiced,Update Kineto revision (#49200)
cc3b59f6df,Uncategorized,Untopiced,[package] use bazel-style glob matching for mock/extern (#49066)
696e30af6e,Uncategorized,Untopiced,Fix ProcessGroupNCCL profiling when profiler is not run with use_cuda (#48946)
743a4ef0ae,Uncategorized,Untopiced,[PyTorch] Enable AutoNonVariableTypeMode in static runtime (#49199)
59e822026c,Uncategorized,Untopiced,Add manual_cpp_binding to native_functions.yaml (#49092)
da6f249a10,Uncategorized,Untopiced,[caffe2] DeserializeToNDArray (#49135)
56a157fc79,Uncategorized,Untopiced,hacky_wrapper_for_legacy_signatures reorders out arguments (#48911)
fce059d4ff,Uncategorized,Untopiced,[te] Don't throw when re-registering a CodeGen factory (#49174)
8669f02573,Uncategorized,Untopiced,Saves a copy of vector<Tensor> in view ops returning TensorList. (#49149)
2b1057b0cf,Uncategorized,Untopiced,[RPC Framework] Support retrieving the RRef to the remote module (#48983)
5ab90b2fda,Uncategorized,Untopiced,Make CUDAFuture remember and restore current device in callback (#48789)
2f1d1eb7df,Uncategorized,Untopiced,Revert D25428587: [pytorch][PR] add additional interpolation modes for torch.quantile
88b3d3371b,Uncategorized,Untopiced,add additional arm64 checker in cmake files (#48952)
2bb2f641c4,Uncategorized,Untopiced,Bring fast_nvcc.py to PyTorch OSS (#48934)
dcd1e3d78d,skip,Untopiced,[AutoAccept][Codemod][FBSourceClangFormatLinter] Daily `arc lint --take CLANGFORMAT`
f204f77e6d,Uncategorized,Untopiced,Drop FutureNCCL in favor of vanilla CUDAFuture (#49014)
f10b53d9ea,Uncategorized,Untopiced,[PyTorch Mobile] Record dtypes for tensors used in kernel function implementations (#48826)
c0a0845019,Uncategorized,Untopiced,Improve new_group example in the context of SyncBatchNorm (#48897)
42c78ed745,Uncategorized,Untopiced,Tuple Slice with both negative and positive stepped size (#48660)
f965b0fcfb,Uncategorized,Untopiced,Expose run_async function on torch::jit::Method (#48607)
796b267763,Uncategorized,Untopiced,fix backwards compatibility for #48711 and its revert (#49240)
2a3bb1cea0,Uncategorized,Untopiced,[quant][graphmode][fx][fix] Fix typo in fusion (#49183)
1cb5aa6c60,Uncategorized,Untopiced,Fix structured kernel codegen (#49244)
db5e5b439c,Uncategorized,Untopiced,Extra sampling of record function events [resend] (#49114)
9920adebfd,Uncategorized,Untopiced,pyi cleanup (#49054)
b94ec8c9f7,Uncategorized,Untopiced,pyi codegen - removing byte-for-byte compatibility hacks (#49055)
33a9b14da0,Uncategorized,Untopiced,pyi codegen - removing byte-for-byte-compatibility hacks (sorting overloads) (#49056)
218eaf4bba,Uncategorized,Untopiced,pyi codegen refactor - no need to group python signatures by overload name (#49057)
15200e385a,Uncategorized,Untopiced,Enable torch.where() to support Float16 & BFloat16 type inputs (#49004)
4bc4ec2686,Uncategorized,Untopiced,Reduce kineto logging (#49216)
e3542d2c12,Uncategorized,Untopiced,[PyTorch] avoid unnecessary call to empty_tensor_restride in empty() (#48211)
6c1b405a3b,Uncategorized,Untopiced,Updated derivative rules for complex QR decomposition (#48489)
c6147ae4c9,Uncategorized,Untopiced,[PyTorch] Fix getCustomClassType() perf (#48981)
df027bfd2c,Uncategorized,Untopiced,Modify Pipe to return an RRef. (#47829)
2f359e7d55,Uncategorized,Untopiced,Add tensorpipe agent tests to multigpu tests. (#49210)
53aa9b8c82,Uncategorized,Untopiced,[FX] Move none assignments to same line (#49209)
bfce69d620,Uncategorized,Untopiced,inline `has` function for DispatchKeySet (#49191)
5716b7db72,Uncategorized,Untopiced,Enabled Scalar lists (#48222)
6b78644623,Uncategorized,Untopiced,[te] Add BitCast to the IR (#49184)
21c38e1799,Uncategorized,Untopiced,Additional validation for DistributedSampler. (#48865)
29f0fa36b1,Uncategorized,Untopiced,[Gradient Compression] Minor update of the comments on PowerSGD. (#49246)
76d41c801e,Uncategorized,Untopiced,[JIT] Fix toIValue handling of AttributeError when casting ClassType (#49188)
635f1cd1a5,Uncategorized,Untopiced,Enable LayerNorm test cases
8d58362f59,Uncategorized,Untopiced,[PyTorch] Remove native::zeros reference in TensorIndexing (#49117)
693e908656,Uncategorized,Untopiced,[shape inference] fix ConstantFill
b5b8fe9876,Uncategorized,Untopiced,Revert D25434956: [JIT] Use `is_buffer` in `BufferPolicy::valid`
8999915a86,Uncategorized,Untopiced,"Fix ""Missing return statement"" mypy error (#49276)"
ae88d25c23,Uncategorized,Untopiced,[te] Fix clamp with uint8 args (#49143)
eaac28192c,Uncategorized,Untopiced,[te] Use Dtype::is_signed instead of an ad hoc local predicate. (#49147)
dc92f25b38,Uncategorized,Untopiced,[te] Use c10::ScalarType utility functions in te::Dtype (#49148)
717f31d984,Uncategorized,Untopiced,Remove unused reconstruct_scopes function (#48822)
cd927875e0,Uncategorized,Untopiced,[pt] Replace size(dim) with sizes()[dim] (#49255)
33b7970d9e,Uncategorized,Untopiced,fix slow windows test (#49258)
dc4db95540,Uncategorized,Untopiced,Update pipeline API to accept arbitrary sequence of Tensors and not just Tuple (#48467)
f2ba3c1621,Uncategorized,Untopiced,Use group.WORLD appropriately in process group initialization. (#48767)
38ed398580,Uncategorized,Untopiced,[fx] Add constant folding pass (#48443)
fdadfb6e5d,Uncategorized,Untopiced,Fix formatting error in `set_deterministic` documentation (#49136)
94a3d4b083,Uncategorized,Untopiced,Remove unused operator at::_fft_with_size (#48905)
f54ab8fbfe,Uncategorized,Untopiced,"Revert ""Revert D25003113: make validate debug-only in Device copy ctr"" (#49123)"
eb051afa78,Uncategorized,Untopiced,[PyTorch] native_cpp_binding for size() and stride() (#49262)
7d406b4a07,Uncategorized,Untopiced,[PyTorch] Make TORCH_CHECK less likely to interfere with inlining (#49263)
bd322c8967,Uncategorized,Untopiced,Update docstrings of torch.nn.modules.activation.MultiheadAttention (#48775)
8397a62a64,Uncategorized,Untopiced,Fix cvtfp32_bf16 (#41280)
690eaf9c43,Uncategorized,Untopiced,add channels last for AdaptiveAvgPool2d (#48916)
87636c07bb,Uncategorized,Untopiced,CUDA BF16 sparse (#48807)
a0432a7020,Uncategorized,Untopiced,[AARCH64] Fix vst1q_f32_x2 implementation (#49273)
25833e5d1c,Uncategorized,Untopiced,[CrashFix] Make the dst tensor contiguous when copying from metal
c068180a17,Uncategorized,Untopiced,[CUDA graphs] Cuda RNG-safe graph capture and replay bindings (#48875)
be849ed1fd,Uncategorized,Untopiced,[PyTorch] Make tls_local_dispatch_key_set inlineable (#49264)
9e3c25ff1d,Uncategorized,Untopiced,sls + layernorm test (#43799)
6cfd7c3811,Uncategorized,Untopiced,Remove type annotations from signatures in html docs (#49294)
4188c374ce,Uncategorized,Untopiced,Refactor: use version instead of major version in windows build (#49156)
6820745e28,Uncategorized,Untopiced,Revert D25489030: [PyTorch] Make tls_local_dispatch_key_set inlineable
86cf1e1358,Uncategorized,Untopiced,Add another way to verify ccache in CONTRIBUTING.md (#49337)
d5a971e193,Uncategorized,Untopiced,Add kernel launch checks in caffe2/aten/src/ATen/native/cuda/ (#49269)
1e2d1d7242,Uncategorized,Untopiced,Fixed cat transform to work with event_dim > 0 (#49111)
3a943e9f82,Uncategorized,Untopiced,Use Unicode friendly API on Win32 in THAllocator (#47905)
220b91660f,Uncategorized,Untopiced,[pytorch] Expand PixelShuffle to support any number of batch dims (#49187)
cb3169d7a8,Uncategorized,Untopiced,[aten] index_select dim 1 (#47077)
e2510a0b60,Uncategorized,Untopiced,Add Kernel Launch Checks to files under caffe2/aten/THC (#49358)
23e98e73f6,Uncategorized,Untopiced,Fix Windows CUDA-11.1 test jobs (#49376)
50b361a821,Uncategorized,Untopiced,Enable BF16 for indexing on CUDA (#48801)
626b8c0cf2,Uncategorized,Untopiced,[te] Ban uint8 tensors from fusion groups (#49247)
bbeee481c3,Uncategorized,Untopiced,Fix typo in torch.load docstring for the `f` parameter (#49350)
900aa4ee97,Uncategorized,Untopiced,[PyTorch] remove convenience RecordFunctionCallback interface (#48620)
7e23ee1598,Uncategorized,Untopiced,[PyTorch] Use plain old function pointer for RecordFunctionCallback (#48629)
a419a3e25d,Uncategorized,Untopiced,Add assertion on any NaN error on the error feedback (#49374)
25bc906281,Uncategorized,Untopiced,Revert D25135415: [PyTorch] Use plain old function pointer for RecordFunctionCallback
39a10fb652,Uncategorized,Untopiced,Fix check_kernel_launches.py for macros and provide extended context (#49365)
98726119d9,Uncategorized,Untopiced,Do not return unitialized qschame from getQSchemeAndQParamVector (#49391)
5a5e576ab9,Uncategorized,Untopiced,Update TensorPipe submodule (#49232)
9234f5026d,Uncategorized,Untopiced,Make WorkNCCL use CUDAEvent::query() rather than re-implement it (#49343)
8ae9b46e20,Uncategorized,Untopiced,Revert D25494735: Update TensorPipe submodule
9908b93dcf,Uncategorized,Untopiced,fix test_dispatch tests to error on duplicate def (#49254)
778006918c,Uncategorized,Untopiced,[WIP][FX] Add FX page to docs (#48814)
11334280bf,Uncategorized,Untopiced,Suppress `warning: calling a constexpr __host__ function from a __host__ __device__ function is not allowed` warning (#49197)
40a02e2ded,Uncategorized,Untopiced,Make out ops c10-full (with hacky-wrapper) (#48912)
e391dbc1b5,Uncategorized,Untopiced,Making ops c10 full: ops returning multiple out arguments (#49006)
c5f90a25c0,Uncategorized,Untopiced,Making ops c10-full: ops blocked by manual registrations (#49007)
b47fa5e88b,Uncategorized,Untopiced,Making ops c10-full: Dimname arguments (#49008)
a6274c1278,Uncategorized,Untopiced,Making ops c10 full: out overloads with default arguments (#49012)
5912316cf7,Uncategorized,Untopiced,Making ops c10-full: Generator arguments (#49013)
f4e15c4a23,Uncategorized,Untopiced,[te] Fix bugs with shift operators (#49396)
3ffe9e0f43,Uncategorized,Untopiced,[static runtime] refine fusion group (#49340)
38a59a67f3,Uncategorized,Untopiced,[JIT] Support multiple outputs in subgraph matcher. (#48992)
c508e5b1bf,Uncategorized,Untopiced,[numpy] torch.{all/any} : output dtype is always bool (#47878)
16f4b0ed6b,Uncategorized,Untopiced,Replace THError() check in THCTensorMathReduce.cu with C10_CUDA_KERNEL_LAUNCH_CHECK() (#49424)
aff0b68a58,Uncategorized,Untopiced,Fix include files for out-of-tree compilation (#48827)
7518f54611,Uncategorized,Untopiced,Add flag torch_jit_disable_warning_prints to allow disabling all warnings.warn (#49313)
46debe7f23,Uncategorized,Untopiced,[DPER] Introduce barrier operation to force synchronization of threads in async execution (#49322)
e9d7d37ad0,Uncategorized,Untopiced,[FX] Rename Node._uses and refactor Node.all_input_nodes (#49415)
22c6dafd33,Uncategorized,Untopiced,[PyTorch] Use plain old function pointer for RecordFunctionCallback (reapply) (#49408)
58551e52f0,Uncategorized,Untopiced,[CMake] Use libtorch_cuda list defined in bzl file (#49429)
acd72e79a3,Uncategorized,Untopiced,update breathe (#49407)
cbeb4c25e5,Uncategorized,Untopiced,[StaticRuntime] Permute_out (#49447)
94e328c038,Uncategorized,Untopiced,fix optimizer.pyi typo 'statue'->'state' (#49388)
8954eb3f72,Uncategorized,Untopiced,[StaticRuntime] Fusion pass for ClipRanges/GatherRanges/LengthsToOffsets (#49113)
a9137aeb06,Uncategorized,Untopiced,"quantized tensor: add preliminary support for advanced indexing, try 2 (#49346)"
40d7c1091f,Uncategorized,Untopiced,Unescape string in RPC error message (#49373)
ed04b71651,Uncategorized,Untopiced,[StaticRuntime][ATen] Add out variant for narrow_copy (#49449)
306bab220e,Uncategorized,Untopiced,Revert D25554109: [StaticRuntime][ATen] Add out variant for narrow_copy
d69d42db78,Uncategorized,Untopiced,Making ops c10 full: optional out arguments (#49083)
ec8e9d31cf,Uncategorized,Untopiced,Making ops c10-full: optional lists (#49088)
76d09ec33e,Uncategorized,Untopiced,[PyTorch] Avoid move-constructing a List in listConstruct (#49355)
efc090652e,Uncategorized,Untopiced,Enhanced generators with grad-mode decorators (#49017)
6786b2b966,Uncategorized,Untopiced,webdataset prototype - ListDirFilesIterableDataset (#48944)
001ff3acf6,Uncategorized,Untopiced,webdataset prototype - LoadFilesFromDiskIterableDataset (#48955)
86902f84bf,Uncategorized,Untopiced,CUDA BFloat embedding (#44848)
f2ee8c6241,Uncategorized,Untopiced,Instantiate PackedConvWeight to avoid linking error (#49442)
c52f1dc365,Uncategorized,Untopiced,.circleci: downgrade conda-package-handling to 1.6.0 (#49434)
4b3f05a471,Uncategorized,Untopiced,[Docs] Updating init_process_group docs to indicate correct rank range (#49131)
09c741868c,Uncategorized,Untopiced,[c10d Store] Store Python Docs Fixes (#49130)
bbc71435b7,Uncategorized,Untopiced,Add sinc operator (#48740)
45b33c83f1,Uncategorized,Untopiced,"Revert ""Revert D24923679: Fixed einsum compatibility/performance issues (#46398)"" (#49189)"
d7659be58d,Uncategorized,Untopiced,[caffe2][autograd] Avoid extensive -Wunused-variable warnings on _any_requires_grad (#49167)
afce5890ff,Uncategorized,Untopiced,Revert D25421263: [pytorch][PR] [numpy] torch.{all/any} : output dtype is always bool
48d1ad1ada,Uncategorized,Untopiced,"Reland ""Add test for empty tensors for batch matmuls"" (#48797)"
1b6d18aa7c,Uncategorized,Untopiced,Adding support for CuDNN-based LSTM with projections (#47725)
f98d8c6237,Uncategorized,Untopiced,Move inplace_is_vmap_compatible to BatchedTensorImpl.h (#49118)
2ec3e803eb,Uncategorized,Untopiced,Update accumulate_grad to support vmap (#49119)
6f814d45aa,Uncategorized,Untopiced,Update TensorPipe submodule (#49467)
39a23c797b,Uncategorized,Untopiced,Add docs/README.md to make existing doc build info more discoverable (#49286)
9955355853,Uncategorized,Untopiced,Updated derivative rules for complex svd and pinverse (#47761)
7729581414,Uncategorized,Untopiced,[quant][docs] Add fx graph mode quantization to quantization docs (#49211)
5874925b46,Uncategorized,Untopiced,stft: Change require_complex warning to an error (#49022)
7767dcfc8d,Uncategorized,Untopiced,Revert D25564477: [pytorch][PR] Add sinc operator
4431731c68,Uncategorized,Untopiced,Making ops c10-full: Storage arguments (#49146)
09173ae65e,Uncategorized,Untopiced,Allow zero annealing epochs (#47579)
676bfa6dbd,Uncategorized,Untopiced,Revert D25507480: [quant][docs] Add fx graph mode quantization to quantization docs
f0217e2f52,Uncategorized,Untopiced,Fix link in distributed contributing doc and add link (#49141)
399b07a8f9,Uncategorized,Untopiced,Add note to torch docs for sinh/cosh (#49413)
d0fb55454b,Uncategorized,Untopiced,Refine `ConvParams::use_nnpack()` (#49464)
6bde0ca6d3,Uncategorized,Untopiced,T66557700 Support default argument values of a method (#48863)
9ce1df079f,Uncategorized,Untopiced,[PyTorch] Merge CoinflipTLS into RecordFunctionTLS (#49359)
1a0510463a,Uncategorized,Untopiced,[PyTorch] Avoid extra Tensor refcounting in _cat_out_cpu (#49364)
c1879b573e,Uncategorized,Untopiced,[PyTorch] Use .sizes() instead of .size() in _cat_out_cpu (#49368)
953f9922ec,Uncategorized,Untopiced,[PyTorch] Use .sizes() isntead of .size() in cat_serial_kernel_impl (#49371)
6f928a4a53,Uncategorized,Untopiced,[PyTorch] Make tls_local_dispatch_key_set inlineable (reapply) (#49412)
f66147ebca,Uncategorized,Untopiced,BFloat16: add explicit dtype support for to_mkldnn and to_dense (#48881)
3efd5d8f01,Uncategorized,Untopiced,Introduce tools.codegen.api.translate (#49122)
47c65f8223,Uncategorized,Untopiced,Revert D25569586: stft: Change require_complex warning to an error
9056173acc,Uncategorized,Untopiced,[NNC] Dont inline outputs buffers on cpu (#49488)
872f6486b1,Uncategorized,Untopiced,Prevent accidentally writing old style ops (#49510)
a5cc0a6f4c,Uncategorized,Untopiced,.circleci: Only downgrade if we have conda (#49519)
c675727adf,Uncategorized,Untopiced,Fix bad error message when int overflow (#48250)
1c6e179b38,Uncategorized,Untopiced,Relax the atol/rtol of layernorm math kernel test. (#49507)
d409da0677,Uncategorized,Untopiced,Fix CUDA extension ninja build (#49344)
60b4c40101,Uncategorized,Untopiced,[extensions] fix `is_ninja_available` during cuda extension building (#49443)
50386b9988,Uncategorized,Untopiced,[NNC] Add Support For is_nan (#48973)
80b508f207,Uncategorized,Untopiced,[NNC] add support for masked_fill (#48974)
904586271b,Uncategorized,Untopiced,Add fusion support of aten::to (#48976)
36b20923ba,Uncategorized,Untopiced,eager quant: remove fake_quant after add/mul nodes during QAT (#49213)
92df8706a0,Uncategorized,Untopiced,fx quant: move {input|output}_quantized_idxs cfg from convert to prepare (#49238)
7542076097,Uncategorized,Untopiced,fx quant: do not insert observers at quantized inputs (#49239)
84506e0316,Uncategorized,Untopiced,fx quant: fix fq when input is quantized and node does not need fq (#49382)
82ac6c75af,Uncategorized,Untopiced,fx quant: make sure observer is inserted before a quantized output (#49420)
df2337097d,Uncategorized,Untopiced,add files to SLOW_TESTS for target determinator (#49500)
db2ecefc01,Uncategorized,Untopiced,"[reland] Support torch.distributed.irecv(src=None, ...) (#49383)"
4ce2b0b0ac,Uncategorized,Untopiced,Set caffe2::pthreadpool() size in ParallelOpenMP (#45566)
6230e337d5,Uncategorized,Untopiced,Add torch._foreach_zero_ API (#47286)
4edaf4d759,Uncategorized,Untopiced,Bring back math_silu_backward which works for all backends. (#49439)
ede0b169ea,Uncategorized,Untopiced,[quant][be] Add typing for quantization_mappings.py (#49179)
2ea1d97e3b,Uncategorized,Untopiced,Add BFloat16 support for isinf and isfinite (#49356)
65876d3f51,Uncategorized,Untopiced,Change aten::native_layer_norm signature to match torch.layer_norm definition (#48971)
26e076d19e,Uncategorized,Untopiced,Adding fix for invalid annotation types for dictionary (#49425)
c18af03a41,Uncategorized,Untopiced,[pt] fuse ClipRangesGatherSigridHash (#49181)
f5b68e74d7,Uncategorized,Untopiced,Revert D25574962: [pytorch][PR] Updated derivative rules for complex svd and pinverse
26974e6b28,Uncategorized,Untopiced,Remove set_quantizer_ from native_functions.yaml (#49463)
f5a26a554b,Uncategorized,Untopiced,[C2] Revive unsafe CoalesceOp (#49402)
c20b916cbd,skip,Untopiced,[AutoAccept][Codemod][FBSourceClangFormatLinter] Daily `arc lint --take CLANGFORMAT`
815d38395a,Uncategorized,Untopiced,PyLong_{As/From}{Long/UnsignedLong} lint checks (#49280)
b8d98f05e7,Uncategorized,Untopiced,[reland][quant][docs] Add fx graph mode quantization to quantization docs (#49211) (#49515)
a727bf2851,Uncategorized,Untopiced,Refactor RPC matchBuiltInOp to get rid of exception swallowing (#49009)
eb131cf484,Uncategorized,Untopiced,Revert D25105217: [pytorch][PR] Fix bad error message when int overflow
20b90f3909,Uncategorized,Untopiced,Set is_non_overlapping_and_dense_ flag in OpaqueTensorImpl constructor (#49470)
0d411c4216,Uncategorized,Untopiced,Test distributed collectives profiling with Gloo on GPU (#49072)
2b61e4d84c,Uncategorized,Untopiced,Revert D25152559: T66557700 Support default argument values of a method
1329066b69,Uncategorized,Untopiced,[te] Add fast log approximation based on sleef
4b85239532,Uncategorized,Untopiced,[quant][eagermode][fix] Fix quantization for DeQuantStub (#49428)
ad4467b93c,Uncategorized,Untopiced,.github: Add action workflow to update S3 HTMLS (#49509)
31fcbbdf35,Uncategorized,Untopiced,[FileStore] Implemented numKeys and Added Tests (#49556)
6db5e85726,Uncategorized,Untopiced,[FileStore] Updating Docs to Reflect FileStore changes (#49557)
ea4ccc730e,Uncategorized,Untopiced,Revert D25445815: [te] Add fast log approximation based on sleef
d17dc37112,Uncategorized,Untopiced,Add dict comprehension (#47774)
19dc5e94a6,Uncategorized,Untopiced,Revert D25547962: [PyTorch] Make tls_local_dispatch_key_set inlineable (reapply)
52b3775914,Uncategorized,Untopiced,Revert D25546409: [PyTorch] Use .sizes() isntead of .size() in cat_serial_kernel_impl
385f6b4807,Uncategorized,Untopiced,Revert D25545777: [PyTorch] Use .sizes() instead of .size() in _cat_out_cpu
625bc40def,Uncategorized,Untopiced,Revert D25544731: [PyTorch] Avoid extra Tensor refcounting in _cat_out_cpu
c78fd76f18,Uncategorized,Untopiced,Revert D25542799: [PyTorch] Merge CoinflipTLS into RecordFunctionTLS
1047957831,Uncategorized,Untopiced,[te][reapply] Add fast log approximation based on sleef (#49575)
39d3578e91,Uncategorized,Untopiced,[ddp launch] solve zombie problem (#49305)
9058040527,Uncategorized,Untopiced,Add more list peephole idioms (#48268)
ed0489c11a,Uncategorized,Untopiced,disable concat nested namespace check (#49571)
5db12b6811,Uncategorized,Untopiced,Add type inference for dequantization.tensors (#49517)
573f4aa352,Uncategorized,Untopiced,FLOPS Roofline Analysis Feature for PyTorch Profiler. (#46506)
5fcfebd84a,Uncategorized,Untopiced,Disables method variant grad and grad grad checks (#49576)
43f6da787e,Uncategorized,Untopiced,Use store based barrier in init_process_group. (#49419)
020c443fd1,Uncategorized,Untopiced,Fix CustomAutogradTest.ReentrantPriority rerun failures (#49581)
1a92802bde,Uncategorized,Untopiced,Set USE_KINETO=1 (#49201)
72b00a8a52,Uncategorized,Untopiced,Revert D25480770: Set USE_KINETO=1
6568572712,Uncategorized,Untopiced,Support integral types for kAbs in SimpleIREvaluator (#49357)
2de345d44d,Uncategorized,Untopiced,Add op bench for caffe2 quantile op (#49598)
f975f99d1d,Uncategorized,Untopiced,add checkout PR tip step for quick checks (#49590)
7545ff6619,Uncategorized,Untopiced,Refactor VmapPhysicalView::newLogicalToPhysical (#49482)
0b27d57062,Uncategorized,Untopiced,fixed the first line of torch.rst to match the __init__.py file's first line (#49584)
ccd646696b,Uncategorized,Untopiced,Fix Module backward hooks for all Tensor inputs/outputs (#46163)
faf6032945,Uncategorized,Untopiced,Remove deadlines for Caffe2 hypothesis_test when running on GPU. (#49591)
c9e052130a,Uncategorized,Untopiced,[FX] Enforce args is tuple and kwargs is dict (#49526)
71ca600af9,Uncategorized,Untopiced,Renaming CAFFE2_API to TORCH_API (#49496)
4a870f6518,Uncategorized,Untopiced,[PyTorch Mobile] Export Operator List from Mobile CompilationUnit instead of from TorchScript Model (#49385)
daaf932a99,Uncategorized,Untopiced,New profiler API (#48280)
e17f0fd676,Uncategorized,Untopiced,Adding support for bitwise augassignment operators (#44621)
27f355f87e,Uncategorized,Untopiced,Test pipeline parallelism works with DDP. (#48470)
fb755ad33e,Uncategorized,Untopiced,[FX] Emit named tuple construction node when NamedTuple appears as an arg (#49553)
b361e33a66,Uncategorized,Untopiced,[package] implicitly extern stdlib before mocking (#49306)
39d89e06e0,Uncategorized,Untopiced,Upload test times to S3 (#49190)
9d91360b5d,Uncategorized,Untopiced,Cleanup APIs for pipeline parallelism. (#48630)
d088359e5a,Uncategorized,Untopiced,[torchscript] Fix constant propagation schemas (#49605)
d0a12c5a47,Uncategorized,Untopiced,Add sinc operator (#48740)
485aee7a22,Uncategorized,Untopiced,Output stacks (support for SVG visualization) (#48438)
5ab9593098,Uncategorized,Untopiced,`torch.reciprocal`: promote integer inputs to float (#49102)
3659560fba,Uncategorized,Untopiced,[NNC] Disable masked fill (#49622)
e2e44bb10a,Uncategorized,Untopiced,[Issue #46210] added torch.fx.len() to provide support for len(); added a test case for torch.fx.len() (#49532)
6f381de006,Uncategorized,Untopiced,Inline coverage report combining/reporting (#49615)
71f3399e19,Uncategorized,Untopiced,[Gradient Compression] Implement the original layerwise PowerSGD (#49417)
8c52fdf522,Uncategorized,Untopiced,Improve documentation for pipeline parallelism. (#48638)
159de1f1d6,Uncategorized,Untopiced,Add benchmark for torch.distributed.pipeline.sync.Pipe (#49577)
7278e3bd29,Uncategorized,Untopiced,Bump tensorpipe version (#49599)
e4eaa6de5f,Uncategorized,Untopiced,Fix lint (#49629)
5cde23fdd4,Uncategorized,Untopiced,[quant][graphmode][fx] Allow user to specify qconfig for call_method (#49621)
ad9923e5d5,Uncategorized,Untopiced,Revert D25511543: [Gradient Compression] Implement the original layerwise PowerSGD
e2d2d9bb0c,Uncategorized,Untopiced,[PyTorch Mobile] Preserve bundled input related methods when calling optimize_for_mobile (#49170)
e0f60c9720,Uncategorized,Untopiced,Disable test on windows (#49636)
1ac05cfe01,Uncategorized,Untopiced,Remove DataPtr extractor from CUDAFuture (#48840)
c0deb231db,Uncategorized,Untopiced,disable kthvalue overlap (#48254)
8b61fbdac9,Uncategorized,Untopiced,Resubmit: [Gradient Compression] Implement the original layerwise PowerSGD (#49639)
f5ee619d2a,Uncategorized,Untopiced,Updated derivative rules for complex svd and pinverse (#47761)
5c25f8faf3,Uncategorized,Untopiced,stft: Change require_complex warning to an error (#49022)
342bfd892f,Uncategorized,Untopiced,[Gradient Compression] Add error feedback to layerwise PowerSGD (#49418)
96aed203bf,Uncategorized,Untopiced,[Gradient Compression] Replace the assertions in PowerSGD comm hook by stream syncrhonization (#49435)
5c3788d5d7,Uncategorized,Untopiced,Add support for torch.tensor_split to accept a tensor for `indices` argument (#49169)
bab732a3a3,skip,Untopiced,[AutoAccept][Codemod][FBSourceClangFormatLinter] Daily `arc lint --take CLANGFORMAT`
1b6fc1fd42,Uncategorized,Untopiced,[WIP][DataLoader] CollateIterableDataset prototype (#48933)
554f79acb9,Uncategorized,Untopiced,[WIP][DataLoader] Prototype of BatchIterableDataset (#49186)
7ed140a1a0,Uncategorized,Untopiced,[WIP][DataLoader] Prototype of SamplerIterableDataset (#49363)
ef172e138c,Uncategorized,Untopiced,[Mask R-CNN]Add Int8 AABB Generate proposals Op (#49574)
5ce94991eb,Uncategorized,Untopiced,Fix sinc docs typo (#49667)
8be205ae13,Uncategorized,Untopiced,Added linalg.solve (#48456)
b80a36614f,Uncategorized,Untopiced,Fix return type Any for Ternary ops (#49165)
b1a1271f68,Uncategorized,Untopiced,Fix typo in add_pr_curve docstrings. (#49648)
a3aafea076,Uncategorized,Untopiced,Fixed a typo in dataloader.py. (#49437)
db2e9c1e7f,Uncategorized,Untopiced,[NNC] Intermediate allocs flattened and dependency support (#49554)
3779bdec56,Uncategorized,Untopiced,Implementing NumPy-like function torch.broadcast_to (#48997)
44ce0b8883,Uncategorized,Untopiced,Sparse-sparse matrix multiplication (CPU/CUDA) (#39526)
12942ea52b,Uncategorized,Untopiced,[BE] Introduce `set_cwd` context manager (#49657)
a84b93a6f8,Uncategorized,Untopiced,add close() method to tqdm mock (#46040)
f7a085af98,Uncategorized,Untopiced,Dynamic GRU quantization support (#49448)
aebb7d1836,Uncategorized,Untopiced,converted current debugging statements in LLVM codegen to jit-logging statements #48771 (#49040)
476cabdfff,Uncategorized,Untopiced,added macros in jit logging to check whether loggings are enabled; replaced similar checks in LLVM codegen with such macros (#49121)
92f37ae263,Uncategorized,Untopiced,change block codegen to handle new inlining in NNC (#47687)
49c9994fb7,Uncategorized,Untopiced,Clean up backward compatibility skip list (#49691)
983bfc79ed,Uncategorized,Untopiced,Enable product for bool tensor (#48637)
befe337072,Uncategorized,Untopiced,Fix test_cuda_init_race skip rules (#49693)
fdf02eff3d,Uncategorized,Untopiced,Add base forward grad logic (#49097)
46c9a0e679,Uncategorized,Untopiced,Do not use negative values in GCD computation. (#49379)
5b163e230a,Uncategorized,Untopiced,[jit][tracer] allow traced modules to return dicts with tuple values when strict=False (#49568)
7e1356db7b,Uncategorized,Untopiced,Move device guard from MultiTensorApply.cuh (#46664)
1043ecf68d,Uncategorized,Untopiced,Use store based barrier only for certain store types. (#49694)
7eb392d73f,Uncategorized,Untopiced,Fix TCPStore type coercion (#49685)
aa2782b9ec,Uncategorized,Untopiced,replacing THC_CLASS and THC_API with TORCH_CUDA_API (#49690)
f5178bf151,Uncategorized,Untopiced,Revert D25607503: Add base forward grad logic
e1f73ced1e,Uncategorized,Untopiced,[TensorExpr] Change `LoopNest::vectorize` to accept `For*` instead of `Stmt*`. (#49696)
a5b27d7a31,Uncategorized,Untopiced,[TensorExpr] Move `SimpleIREval` implementation from .h to .cpp. (#49697)
ab2194f912,Uncategorized,Untopiced,unbreak mypy torch/quantization (#49549)
9d5d193704,Uncategorized,Untopiced,fx quant: types for fusion_patterns.py (#49606)
7c90b20f38,Uncategorized,Untopiced,fx quant: add types to observed_module.py (#49607)
edce6b138d,Uncategorized,Untopiced,fx quant: fix types on _find_quants (#49616)
11598da229,Uncategorized,Untopiced,[FX] Fix python code having spurious newlines from placeholders (#49720)
d54cf2aa27,Uncategorized,Untopiced,[pt][ATen] Optimize bmm (#49506)
590e7168ed,Uncategorized,Untopiced,[PyTorch] Remove direct reference to native symbols in sparse related non-native codes (#49721)
c348faedc4,Uncategorized,Untopiced,[Gradient Compression] Warm-start of PowerSGD (#49451)
dfb7520c47,Uncategorized,Untopiced,NewModuleTest: Don't call both check_jacobian and gradcheck (#49566)
2df249f0ab,Uncategorized,Untopiced,[fix] inplace remainder/% (#49390)
4d9d03fe47,Uncategorized,Untopiced,Complex backward for torch.sqrt (#49461)
42b5601f30,Uncategorized,Untopiced,[ROCm] add 4.0 to nightly builds (#49632)
7b4a7661d6,Uncategorized,Untopiced,Make PyTorch partially cross-compilable for Apple M1 (#49701)
eabe05ab72,Uncategorized,Untopiced,[onnxifi] Get rid of class member (#49380)
c23808d8e8,Uncategorized,Untopiced,Reland: Add base forward grad logic (#49734)
21398fb6cb,Uncategorized,Untopiced,Fix get_overlap_status for tensors without storage (#49638)
1451d84766,Uncategorized,Untopiced,Minor doc fix: change truncating to rounding in TF32 docs (#49625)
04e04abd06,Uncategorized,Untopiced,remove unused THCBlas (#49725)
6f9532dd53,Uncategorized,Untopiced,"only upload s3 stats on master, nightly, and release branch (#49645)"
9b6fb856e8,Uncategorized,Untopiced,Update NNPACK (#49749)
be091600ed,Uncategorized,Untopiced,early terminate when CUDA assert were thrown (#49527)
2780400904,Uncategorized,Untopiced,[numpy] Add `torch.xlogy` (#48777)
67d0c18241,Uncategorized,Untopiced,[FX] Try to make it more clear that _update_args_kwargs should not be called (#49745)
b414123264,Uncategorized,Untopiced,Update `is_floating_point()` docs to mention bfloat16 (#49611)
c3a7591cef,Uncategorized,Untopiced,fx quant: do not observe bias on F.conv (#49623)
19f972b696,Uncategorized,Untopiced,fx quant: do not observe bias on F.linear (#49628)
de07d07600,Uncategorized,Untopiced,fx quant: improve types on convert (#49688)
27f0dd36d9,Uncategorized,Untopiced,add type annotations to torch.nn.parallel._functions (#49687)
62f9b03b7c,Uncategorized,Untopiced,[lint] Apply whitespace linter to all gradle files
010b9c52f4,Uncategorized,Untopiced,Skip None submodule during JIT-tracing (#49765)
abacf27038,Uncategorized,Untopiced,Revert D25623219: [pytorch][PR] early terminate when CUDA assert were thrown
46b83212d1,Uncategorized,Untopiced,Remove unused six code for Python 2/3 compatibility (#48077)
461aafe389,Uncategorized,Untopiced,[numpy] `torch.angle`: promote integer inputs to float (#49163)
68d438c9da,Uncategorized,Untopiced,Add PixelUnshuffle (#49334)
af1b636b89,Uncategorized,Untopiced,[Gradient Compression] Change wait() to value() in some callbacks of PowerSGD communication hook (#49709)
f474ffa1a9,Uncategorized,Untopiced,[quant][graphmode][fx] Change standalone module api (#49719)
ee271047b5,Uncategorized,Untopiced,torch.utils.checkpoint.checkpoint + torch.cuda.amp (#49757)
88c33ff8ab,Uncategorized,Untopiced,[Gradient Compression] Explicitly restrict the scope of torch.cuda.synchronize to the current device (#49711)
55b431b17a,Uncategorized,Untopiced,[Gradient Compression] Directly let world_size = group_to_use.size() (#49715)
5171bd94d7,Uncategorized,Untopiced,[lint doc] how to fix flake errors if pre-commit hook wasn't there (#49345)
370350c749,Uncategorized,Untopiced,Preserve memory format in qconv op (#49533)
8554b58fbd,Uncategorized,Untopiced,Added linalg.inv (#48261)
b3387139b4,Uncategorized,Untopiced,Mod lists to neutral+descriptive terms in caffe2/docs (#49803)
d99a0c3b3e,Uncategorized,Untopiced,Improve docs for scatter and gather functions (#49679)
e163172904,Uncategorized,Untopiced,removes more unused THC functions (#49788)
4d6110939a,Uncategorized,Untopiced,[pt][quant] Make the CUDA fake quantize logic consistent with CPU fake quantize logic (#49808)
3f4b98d568,Uncategorized,Untopiced,[numpy] `torch.erfinv`: promote integer inputs to float (#49155)
e6a215592e,Uncategorized,Untopiced,[reland] Early terminate when CUDA assert were thrown (#49799)
1833009202,Uncategorized,Untopiced,Fix typo in complex autograd docs (#49755)
5acc27c00a,Uncategorized,Untopiced,Revert D25690129: [pytorch][PR] Added linalg.inv
9552cc65d4,Uncategorized,Untopiced,Creation of test framework for Sparse Operators (#48488)
69b1373587,Uncategorized,Untopiced,Revert D25692616: [pytorch][PR] [reland] Early terminate when CUDA assert were thrown
89b4899ea5,Uncategorized,Untopiced,[quant][graphmode][fx] Standalone module support {input/output}_quantized_idxs (#49754)
ec6de6a697,Uncategorized,Untopiced,Clip small scales to fp16 min
46cf6d332f,Uncategorized,Untopiced,Revert D25684692: [quant][graphmode][fx] Standalone module support {input/output}_quantized_idxs
963f7629b5,Uncategorized,Untopiced,[numpy] `torch.digamma` : promote integer inputs to float (#48302)
9c64b9ffba,Uncategorized,Untopiced,early termination of CUDA tests (#49869)
e6779d4357,Uncategorized,Untopiced,"[*.py] Rename ""Arguments:"" to ""Args:"" (#49736)"
58fe67967c,Uncategorized,Untopiced,Support the `in` operator with str (#47057)
268441c7d8,Uncategorized,Untopiced,[NNC] masked fill (#49627)
fc559bd6dc,Uncategorized,Untopiced,[JIT] Constant prop getattr (#49806)
ea558b2135,Uncategorized,Untopiced,fx quant: hook up ConvTranspose{n}d (#49717)
bc4ff7ba05,Uncategorized,Untopiced,fx quant: split linear test cases (#49740)
361f5ed91d,Uncategorized,Untopiced,Implement torch.linalg.qr (#47764)
c619892482,Uncategorized,Untopiced,Fix errata (#49903)
d434ac35e4,Uncategorized,Untopiced,Update gather documentation to allow index.shape[k] <= input.shape[k] rather than ==. (#41887)
8d7338e820,Uncategorized,Untopiced,Enable tests using named temp files on Windows (#49640)
a111a9291c,Uncategorized,Untopiced,added fuse_op and list_construct - list_unpack pass
891759f860,Uncategorized,Untopiced,Clean up type annotations in caffe2/torch/nn/modules (#49938)
4c5a4dbb8c,Uncategorized,Untopiced,[Tensorexpr]Copying header files in tensorexpr dir (#49933)
14edc726d9,Uncategorized,Untopiced,Clean up some type annotations in caffe2/torch/quantization (#49942)
01b57e1810,Uncategorized,Untopiced,Revert D25718705: Clean up type annotations in caffe2/torch/nn/modules
e482c70a3d,Uncategorized,Untopiced,added List as an option to the unflattened_size (#49838)
97c17b4772,Uncategorized,Untopiced,Fix auto exponent issue for torch.pow (#49809)
12b73fdbbf,Uncategorized,Untopiced,Adding JIT support for cuda streams and events (#48020)
cfc3db0ca9,Uncategorized,Untopiced,Remove THPWrapper (#49871)
b54ad08978,Uncategorized,Untopiced,Enable test_fusions TanhQuantize (#49970)
42d2e31cd6,Uncategorized,Untopiced,[numpy] `torch.rsqrt` : promote integer inputs to float (#47909)
6b56b71e61,Uncategorized,Untopiced,Accept input tensor with 0-dim batch size for MultiLabelMarginLoss (#46975)
6a951a6f4c,Uncategorized,Untopiced,Fix a KaTeX crash and many docstring issues (#49684)
a7e1f4f37a,Uncategorized,Untopiced,"Remove incorrect usage of layout(std430) on uniform buffers, correctly now treated as error in the latest release of Vulkan SDK. (#49572)"
ffbb68af8a,Uncategorized,Untopiced,quant docs: add common errors section (#49902)
04a8412b86,Uncategorized,Untopiced,[quant] Quantizable LSTM (#49671)
46afd7fc9f,Uncategorized,Untopiced,[PyTorch] Decouple version numbers from c10 and caffe2 targets (#49905)
cd608fe59b,Uncategorized,Untopiced,Revert D25719980: [pytorch][PR] Accept input tensor with 0-dim batch size for MultiLabelMarginLoss
730965c246,Uncategorized,Untopiced,Improve `torch.flatten` docs and add tests to test_view_ops (#49501)
4677fc69a2,Uncategorized,Untopiced,Fix inf norm grad (reland) (#48611)
de3d8f8c35,Uncategorized,Untopiced,Revert D25734450: [pytorch][PR] Improve `torch.flatten` docs and add tests to test_view_ops
749f8b7850,Uncategorized,Untopiced,Remove flops warnings from the default profiler use case (#49896)
8aad66a7bd,Uncategorized,Untopiced,[c10/**] Fix typos (#49815)
e44b2b72bd,Uncategorized,Untopiced,"Back out ""[pytorch][PR] Preserve memory format in qconv op"" (#49994)"
c7e9abb66a,Uncategorized,Untopiced,Making ops c10-full: list of optional tensors (#49138)
211f35631f,Uncategorized,Untopiced,Add type annotations to _tensorboard_vis.py and hipify_python.py (#49834)
22bd277891,Uncategorized,Untopiced,Run test_type_hints first (#49748)
b76822eb49,Uncategorized,Untopiced,Update update_s3_htmls.yml (#49934)
fdb81c538a,Uncategorized,Untopiced,Improve `torch.flatten` docs and add tests to test_view_ops (#49501)
6e84a018be,Uncategorized,Untopiced,move to non-legacy magma v2 headers (#49978)
69ca5e1397,Uncategorized,Untopiced,Enforce c10-fullness for all ops (#49619)
f0945537af,Uncategorized,Untopiced,.circleci: Ignore unbound variables for conda (#50053)
8e20594b38,Uncategorized,Untopiced,Construct CppSignatureGroup from NativeFunction (#49245)
7202c0ec50,Uncategorized,Untopiced,Tighten up error checking on manual_kernel_registration (#49341)
8eee8460f8,Uncategorized,Untopiced,codegen: Resolve overload ambiguities created by defaulted arguments (#49348)
6c833efd65,Uncategorized,Untopiced,Move default or no default logic into native.argument (#49489)
0216366f0d,Uncategorized,Untopiced,Make use_c10_dispatcher: full mandatory for structured kernels (#49490)
da790eca69,Uncategorized,Untopiced,Add trace batching forward/backward rule (#49979)
483670ff0f,Uncategorized,Untopiced,[pytorch] add threshold_backward batching for vmap (#49881)
74dcb6d363,Uncategorized,Untopiced,torch.xlogy: Use wrapped_scalar_tensor / gpu_with_scalars to speed up GPU kernel. (#49926)
71766d89ea,Uncategorized,Untopiced,[BE] unified run_process_no_exception code (#49774)
f96ce3305c,Uncategorized,Untopiced,prohibit assignment to a sparse tensor (#50040)
240c0b318a,Uncategorized,Untopiced,"Suppress ""statement is unreachable"" warning (#49495)"
c439a6534d,Uncategorized,Untopiced,[ONNX] Handle Sub-block index_put in _jit_pass_onnx_remove_inplace_ops_for_onnx (#48734)
efe1fc21fc,Uncategorized,Untopiced,Dont inlinine intermediates on cpu (#49565)
5acb1cc1df,Uncategorized,Untopiced,Drop unused imports from scripts (#49956)
a5339b9d7c,Uncategorized,Untopiced,Drop unused imports from leftovers (#49953)
d0369aabe1,Uncategorized,Untopiced,Clean up some type annotations in caffe2/contrib/aten/gen_op (#49945)
65122173ab,Uncategorized,Untopiced,[ONNX] Modified var_mean symbolic to support more combinations of dims (#48949)
9e0b4a96e4,Uncategorized,Untopiced,introduce a flag to disable aten::cat in TE (#49579)
8fb5f16931,Uncategorized,Untopiced,"Complex backward for indexing, slicing, joining, and mutating ops (#49552)"
c51455a7bb,Uncategorized,Untopiced,[FX] fix Graph python_code return type annotation (#49931)
ee80b45843,Uncategorized,Untopiced,[TensorExpr] Fix LLVM 10 build after LLVM API changes
6e6231f9cd,Uncategorized,Untopiced,unit test for fc parallelization aot (#50056)
e4d596c575,Uncategorized,Untopiced,Fix return value of _vmap_internals._get_name (#49951)
8c66aec435,Uncategorized,Untopiced,Fix grammar typo in readme.md (#50000)
3845770349,Uncategorized,Untopiced,Fixing error in Readme.md. (#50033)
ace78ddb6a,Uncategorized,Untopiced,Revert D25763758: [pytorch][PR] introduce a flag to disable aten::cat in TE
52933b9923,Uncategorized,Untopiced,Patch death tests/fork use after D25292667 (part 3)
e35b822d7d,Uncategorized,Untopiced,fixes indices computation for trilinear interpolate backwards (#50084)
b7bfc723d3,Uncategorized,Untopiced,Run mypy on more test files (#49658)
c86cfcd81d,Uncategorized,Untopiced,Run mypy over test/test_utils.py (#49654)
72306378b4,Uncategorized,Untopiced,quant: ensure observers do not crash for empty Tensors (#49800)
44c17b28c6,Uncategorized,Untopiced,quant: nice error message on convtranspose with per-channel weight (#49899)
113b7623d6,Uncategorized,Untopiced,quant: throw a nice error message for allclose with quantized inputs (#49802)
04e86be1a2,Uncategorized,Untopiced,eager quant: fix error with removing forward hooks (#49813)
bbae6774c1,Uncategorized,Untopiced,[JIT] Remove buffer metadata serialization forward-compat gate (#49990)
3cd2f1f3a7,Uncategorized,Untopiced,Add an option to disable aten::cat in TE (re-revert) (#50101)
c115957df0,Uncategorized,Untopiced,[distributed] Provide parameter to pass GPU ID in barrier function (#49069)
e868825eb6,Uncategorized,Untopiced,[RPC] Relax some profiling tests (#49983)
12ee7b61e7,Uncategorized,Untopiced,support building with conda installed libraries (#50080)
16e5af41da,Uncategorized,Untopiced,Fix store based barrier to only use 'add'. (#49930)
eee849be8c,Uncategorized,Untopiced,[caffe2][a10] Move down pragma pop to properly suppress warning 4522 (#49233)
9945fd7253,Uncategorized,Untopiced,Drop unused imports from caffe2/python (#49980)
e442ac1e3f,Uncategorized,Untopiced,Update MultiHeadAttention docstring (#49950)
e3c56ddde6,Uncategorized,Untopiced,Revert D25757691: [pytorch][PR] Run mypy over test/test_utils.py
093aca082e,Uncategorized,Untopiced,Enable distribution validation if __debug__ (#48743)
a272a7eeab,Uncategorized,Untopiced,[PyTorch] Avoid heap allocations in inferUnsqueezeGeometry (#49497)
e71a13e8a3,Uncategorized,Untopiced,[pytorch][codegen] migrate gen_variable_type to new data model (#49735)
abe1fa49e9,Uncategorized,Untopiced,[JIT] Add `__prepare_scriptable__` duck typing to allow replacing nn.modules with scriptable preparations (#45645) (#49242)
d1a56fcd9d,Uncategorized,Untopiced,[docs] add docstring in torch.cuda.get_device_properties (#49792)
9529ae3776,Uncategorized,Untopiced,Revert D25757721: [pytorch][PR] Run mypy on more test files
4a6c178f73,Uncategorized,Untopiced,Improve documentation and warning message for creation of a tensor with from_numpy() (#49516)
5e1c8f24d4,Uncategorized,Untopiced,Make stft (temporarily) warn (#50102)
dcc83868c5,Uncategorized,Untopiced,[PyTorch Mobile] Mark xnnpack operators selective
7fe25af59d,Uncategorized,Untopiced,Revert D25746115: [pytorch][PR] Improve documentation and warning message for creation of a tensor with from_numpy()
d1c375f071,Uncategorized,Untopiced,fix fork formatting (#49436)
5d93e2b818,Uncategorized,Untopiced,"torch.flip and torch.flip{lr, ud}: Half support for CPU and BFloat16 support for CPU & CUDA (#49895)"
26391143b6,Uncategorized,Untopiced,Support out argument in torch.fft ops (#49335)
70734f1260,Uncategorized,Untopiced,Kill AT_SKIP_BFLOAT16_IF_NOT_ROCM (#48810)
5f875965c6,Uncategorized,Untopiced,Fix doc for vmap levels (#50099)
574a15b6cc,Uncategorized,Untopiced,[PyTorch] Reapply D25544731: Avoid extra Tensor refcounting in _cat_out_cpu (#49760)
75028f28e1,Uncategorized,Untopiced,[PyTorch] Reapply D25545777: Use .sizes() instead of .size() in _cat_out_cpu (#49761)
d80d38cf87,Uncategorized,Untopiced,Clean up type annotations in caffe2/torch/nn/modules (#49957)
9b7f3fa146,Uncategorized,Untopiced,[fx] Add matrix multiplication fusion pass (#50120)
def8aa5499,Uncategorized,Untopiced,Remove cpu half and dead code from multinomial (#50063)
05358332b3,Uncategorized,Untopiced,Fix mypy typing check for test_dataset (#50108)
f6f0fde841,Uncategorized,Untopiced,[reland][quant][graphmode][fx] Standalone module support {input/output}_quantized_idxs (#49754) (#50058)
57d489e43a,Uncategorized,Untopiced,Fix for possible RNG offset calculation bug in cuda vectorized dropout with VEC=2 (#50110)
282552dde2,Uncategorized,Untopiced,[PyTorch] Reapply D25546409: Use .sizes() isntead of .size() in cat_serial_kernel_impl (#49762)
ad7d208ba5,Uncategorized,Untopiced,Revert D25239967: [fx] Add matrix multiplication fusion pass
0ad6f06684,Uncategorized,Untopiced,drop a unneeded comma from cmakelist.txt (#50091)
45ec35827e,Uncategorized,Untopiced,Set USE_RCCL cmake option (dependent on USE_NCCL) [REDUX] (#34683)
2ac180a5dd,Uncategorized,Untopiced,Fix cl.exe detection in cpu/fused_kernel.cpp (#50085)
c517e15d79,Uncategorized,Untopiced,Add support for converting sparse bool tensors to dense (#50019)
5f2ec6293d,Uncategorized,Untopiced,Unused variables in neural net classes and functions (#50100)
688992c775,Uncategorized,Untopiced,[PyTorch] Additional IValue tests (#49718)
1b31e13539,Uncategorized,Untopiced,[PyTorch] Store Tensor explicitly in IValue (#48824)
480a756194,Uncategorized,Untopiced,[PyTorch] IValue::toTensor can now return const Tensor& (#48868)
68a6e46379,Uncategorized,Untopiced,"Push anonymous namespace into codegen, not template (#49498)"
74c055b240,Uncategorized,Untopiced,"Fix mypy type hint for AdaptiveAvgPool2,3d, AdaptiveMaxPool2,3d (#49963)"
efe0533a24,Uncategorized,Untopiced,Clean up some type annotations in torch/testing/_internal (#50078)
e606e60331,Uncategorized,Untopiced,[Needs Review] Convert some files to Python3 (#49351)
7d9eb6c680,Uncategorized,Untopiced,Implementation of torch::cuda::synchronize (#50072)
638086950d,Uncategorized,Untopiced,Clean up type annotations in torch/nn/quantized/modules (#49941)
3ce539881a,Uncategorized,Untopiced,"Back out ""Revert D25757721: [pytorch][PR] Run mypy on more test files"" (#50142)"
6eee2a0a9f,Uncategorized,Untopiced,[JIT] disable masked fill (#50147)
ba691e1a42,Uncategorized,Untopiced,Remove incorrect links to zdevito/ATen (#50065)
9b519b4a3f,Uncategorized,Untopiced,[PyTorch Mobile] Generate Kernel dtype selection code in selected_mobile_ops.h during the build (#49279)
09eb468398,Uncategorized,Untopiced,[vulkan] 2D prepacking for conv2d (#48816)
473e78c0fa,Uncategorized,Untopiced,Remove redundant code for unsupported Python versions (#49486)
fcb69d2eba,Uncategorized,Untopiced,Add android.permission.INTERNET permission to Android test_app. (#49996)
e4c41b6936,Uncategorized,Untopiced,Remove codegen logic to support non-c10-full ops (#49164)
4a14020c0d,Uncategorized,Untopiced,Remove .impl_UNBOXED() and functionalities associated with it (#49220)
249261ada7,Uncategorized,Untopiced,Remove generated_unboxing_wrappers and setManuallyBoxedKernel (#49251)
6643e9fbb3,Uncategorized,Untopiced,Remove `use_c10_dispatcher: full` lines (#49259)
eef5eb05bf,Uncategorized,Untopiced,Remove backward and requires_grad from Autograd backend key (#49613)
dde5b6e177,Uncategorized,Untopiced,[PyTorch] Reapply D25547962: Make tls_local_dispatch_key_set inlineable (reapply) (#49763)
3270e661c3,Uncategorized,Untopiced,[PyTorch Mobile] Skip signature check when converting to typed operator handle (#49469)
dc41d17655,Uncategorized,Untopiced,.circleci: Add option to not run build workflow (#50162)
eb8003d8e9,Uncategorized,Untopiced,[FX] Remove extraneous newlines at end of code (#50117)
e49372d460,Uncategorized,Untopiced,Bugfix nightly checkout tool to work on Windows (#49274)
6838ecefb6,Uncategorized,Untopiced,Clean up some type annotations in torch/jit (#49939)
fa160d18e7,Uncategorized,Untopiced,"[PyTorch][jit] Add Type::{castRaw,expectRef} (#50061)"
ef1fa547ba,Uncategorized,Untopiced,[PyTorch] Use expectRef() when calling listConstruct (#50062)
b6b76a1055,Uncategorized,Untopiced,Mod lists to neutral+descriptive terms in caffe2/caffe2/opt (#49801)
4e2ab2cd73,Uncategorized,Untopiced,Move generator state APIs to ATen (#49589)
838e73de20,Uncategorized,Untopiced,enable alltoall_single torchscript support (#48345)
11cdb910b4,Uncategorized,Untopiced,[fx] Add matrix multiplication fusion pass (#50151)
968ad47b41,Uncategorized,Untopiced,Fix error messages thrown when the padding size is not valid (#50135)
321b98830e,Uncategorized,Untopiced,[script] Validator for unsupported ops on accelerator
ace1680b68,Uncategorized,Untopiced,[static runtime] Remove register concept by giving ownership to the nodes (#50050)
45c0d64b33,Uncategorized,Untopiced,Skip test_functional_autograd_benchmark during code coverage (#50183)
8706187523,Uncategorized,Untopiced,Fix #42271 (#50141)
fbdb7822c6,Uncategorized,Untopiced,minor improvement: extract major version (#49393)
ec6d29d6fa,Uncategorized,Untopiced,Drop unused imports from test (#49973)
e096449360,Uncategorized,Untopiced,Adding MyPy daemon status file to gitignore (#50132)
7377bfb1bd,Uncategorized,Untopiced,Fix compiler warnings pertaining to uniform_int() (#49914)
0495180f6e,Uncategorized,Untopiced,Fix deprecation warning in scalar_type_analysis (#50218)
160b4be60a,Uncategorized,Untopiced,[PyTorch] typeid: ensmallen scalarTypeItemSizes (#50165)
e12008d110,Uncategorized,Untopiced,[quant] Mapping for the `_LinearWithBias` (#49964)
0c3bae6a89,Uncategorized,Untopiced,docker: add environment variable PYTORCH_VERSION (#50154)
7ce8f7e488,Uncategorized,Untopiced,[quant] Backend string for the quantized types (#49965)
23cadb5d7b,Uncategorized,Untopiced,[PyTorch] Specialize `list_element_from` for `IValue` to avoid extra move/copy (#50124)
3b56e9d0ef,Uncategorized,Untopiced,[pytorch] prune based on custom importance scores (#48378)
2bceee785f,Uncategorized,Untopiced,Clean up simple type annotations in nn/functional.py (#50106)
f83d57f99e,Uncategorized,Untopiced,[Don't review] Clean up type annotations in caffe2/torch/nn (#50079)
09eefec627,Uncategorized,Untopiced,Clean up some type annotations in android (#49944)
ce370398cc,Uncategorized,Untopiced,"[Gradient Compression] Remove the extra comma after ""bucket"" in PowerSGD hook signatures (#50197)"
870ab04b64,Uncategorized,Untopiced,add type annotations to torch._utils (#49705)
bf4fcab681,Uncategorized,Untopiced,Fix SyncBatchNorm usage without stats tracking (#50126)
2e7c6cc9df,Uncategorized,Untopiced,[PyTorch] Devirtualize TensorImpl::numel() with macro (#49766)
1a1b665827,Uncategorized,Untopiced,[PyTorch] validate that SparseTensorImpl::dim needn't be overridden (#49767)
4de6b279c8,Uncategorized,Untopiced,[PyTorch] Devirtualize TensorImpl::dim() with macro (#49770)
84e3237a53,Uncategorized,Untopiced,Let RpcAgent::send() return JitFuture (#49906)
25ef605132,Uncategorized,Untopiced,Replace FutureMessage with ivalue::Future in distributed/autograd/utils.* (#49927)
008206decc,Uncategorized,Untopiced,Replace FutureMessage with ivalue::Future in RRefContext (#49960)
d730c7e261,Uncategorized,Untopiced,Replace FutureMessage with ivalue::Future in RpcAgent retry logic (#49995)
2d5f57cf3b,Uncategorized,Untopiced,Completely remove FutureMessage from RRef Implementations (#50004)
b2da0b5afe,Uncategorized,Untopiced,Completely remove FutureMessage from RPC TorchScript implementations (#50005)
0c943931aa,Uncategorized,Untopiced,Completely remove FutureMessage from distributed autograd (#50020)
1deb895074,Uncategorized,Untopiced,Remove FutureMessage from sender ProcessGroupAgent (#50023)
0684d07425,Uncategorized,Untopiced,Remove FutureMessage from sender TensorPipeAgent (#50024)
2831af9837,Uncategorized,Untopiced,Completely remove FutureMessage from FaultyProcessGroupAgent (#50025)
1f795e1a9b,Uncategorized,Untopiced,Remove FutureMessage from RPC request callback logic (#50026)
098751016e,Uncategorized,Untopiced,Completely Remove FutureMessage from RPC cpp tests (#50027)
171648edaa,Uncategorized,Untopiced,Completely Remove FutureMessage from RPC agents (#50028)
c480eebf95,Uncategorized,Untopiced,Completely remove FutureMessage type (#50029)
882ddb2f2d,Uncategorized,Untopiced,[PyTorch] Introduce packed SizesAndStrides abstraction (#47507)
b73c018598,Uncategorized,Untopiced,[PyTorch] Change representation of SizesAndStrides (#47508)
5a63c452e6,Uncategorized,Untopiced,Disable cuDNN persistent RNN on sm_86 devices (#49534)
294b7867eb,Uncategorized,Untopiced,Address clang-tidy warnings in ProcessGroupNCCL (#50131)
c215ffb6a2,Uncategorized,Untopiced,Revert D25687465: [PyTorch] Devirtualize TensorImpl::dim() with macro
fc2ead0944,Uncategorized,Untopiced,"Autograd engine, only enqueue task when it is fully initialized (#50164)"
9f832c8d3e,Uncategorized,Untopiced,[numpy] torch.exp: promote integer inputs to float (#50093)
006cfebf3d,Uncategorized,Untopiced,Update autograd related comments (#50166)
5c5abd591d,Uncategorized,Untopiced,Implement torch.linalg.svd (#45562)
d00acebd14,Uncategorized,Untopiced,Add tensor.view(dtype) (#47951)
54ce171f16,Uncategorized,Untopiced,Fix persistent_workers + pin_memory (#48543)
55919a4758,Uncategorized,Untopiced,add type annotations to torch.nn.quantized.modules.conv (#49702)
88bd69b488,Uncategorized,Untopiced,Stop using c10::scalar_to_tensor in float_power. (#50105)
b5ab0a7f78,Uncategorized,Untopiced,Improve torch.linalg.qr (#50046)
81778e2811,Uncategorized,Untopiced,[onnx] Do not deref nullptr in scalar type analysis (#50237)
a4f30d48d8,Uncategorized,Untopiced,Clean up some type annotations in test/jit (#50158)
5d45140d68,Uncategorized,Untopiced,[numpy] torch.{all/any} : output dtype is always bool (#47878)
d78b638a31,Uncategorized,Untopiced,Convert string => raw strings so char classes can be represented in Python regex (#50239)
0bb341daaa,Uncategorized,Untopiced,Dump state when hitting ambiguous_autogradother_kernel. (#50246)
f9f758e349,Uncategorized,Untopiced,Apply clang-format to rpc cpp files (#50236)
1bb7d8ff93,Uncategorized,Untopiced,Revert D25717504: Clean up some type annotations in test/jit
8f31621f78,Uncategorized,Untopiced,Fix MKL builds on Ubuntu (#50212)
2c4b6ec457,Uncategorized,Untopiced,Unused exception variables (#50181)
aa18d17455,Uncategorized,Untopiced,add type annotations to torch.nn.modules.fold (#49479)
1c12cbea90,Uncategorized,Untopiced,Optimize Vulkan command buffer submission rate. (#49112)
49bb0a30e8,Uncategorized,Untopiced,Support scripting classmethod called with object instances (#49967)
c2d37cd990,Uncategorized,Untopiced,Change CMake config to enable universal binary for Mac (#50243)
36ddb00240,Uncategorized,Untopiced,[fix] torch.cat: Don't resize out if it is already of the correct size. (#49937)
ea087e2d92,Uncategorized,Untopiced,JIT: guard DifferentiableGraph node (#49433)
ba1ce71cd1,Uncategorized,Untopiced,Document single op replacement (#50116)
d4c1684cf5,Uncategorized,Untopiced,reuse consant from jit (#49916)
8530c65e25,Uncategorized,Untopiced,[codemod][fbcode/caffe2] Apply clang-format update fixes
375c30a717,Uncategorized,Untopiced,Avg pool 0 dim acceptance. (#50008)
4774c6800b,Uncategorized,Untopiced,Added linalg.inv (#48261)
26cc630789,Uncategorized,Untopiced,Allow arbitrary docstrings to be inside torchscript interface methods (#50271)
92fcb59feb,Uncategorized,Untopiced,Automated submodule update: tensorpipe (#50267)
fd92bcfe39,Uncategorized,Untopiced,Use FileStore in TorchScript for store registry (#50248)
839c2f235f,Uncategorized,Untopiced,treat Parameter the same way as Tensor (#48963)
632a4401a6,Uncategorized,Untopiced,clean up imports for tensor.py (#48964)
d31a760be4,Uncategorized,Untopiced,"move has_torch_function to C++, and make a special case object_has_torch_function (#48965)"
6a3fc0c21c,Uncategorized,Untopiced,Treat has_torch_function and object_has_torch_function as static False when scripting (#48966)
9d8bd216f9,Uncategorized,Untopiced,Use Unicode friendly API in fused kernel related code (#49781)
eb87686511,Uncategorized,Untopiced,svd_backward: more memory and computationally efficient. (#50109)
e29082b2a6,Uncategorized,Untopiced,Run mypy over test/test_utils.py (#50278)
acaf091302,Uncategorized,Untopiced,Vulkan convolution touchups. (#50329)
186fe48d6e,Uncategorized,Untopiced,Format RPC files with clang-format (#50367)
0f412aa293,Uncategorized,Untopiced,Move scalar_to_tensor_default_dtype out of ScalarOps.h because it's only useful for torch.where. (#50111)
6eb8e83c0b,Uncategorized,Untopiced,[aten] embedding_bag_byte_rowwise_offsets_out (#49561)
f10e7aad06,Uncategorized,Untopiced,[quant][graphmode][fx] Scope support for call_method in QuantizationTracer (#50173)
a7e92f120c,Uncategorized,Untopiced,[FX} Implement wrap() by patching module globals during symtrace (#50182)
d390e3d8b9,Uncategorized,Untopiced,[FX] Make graph target printouts more user-friendly (#50296)
271240ae29,Uncategorized,Untopiced,"[JIT] Ensure offset is a multiple of 4 to fix ""Philox"" RNG in jitted kernels (#50169)"
55ac7e53ae,Uncategorized,Untopiced,[quant][graphmode][fx] Support preserved_attributes in prepare_fx (#50306)
559e2d8816,Uncategorized,Untopiced,Implement optimization bisect (#49031)
ec51b67282,Uncategorized,Untopiced,Fix elu backward operation for negative alpha (#49272)
3d263d1928,Uncategorized,Untopiced,Update op replacement tutorial (#50377)
080a097935,Uncategorized,Untopiced,Add docstring for Proxy (#50145)
4d3c12d37c,Uncategorized,Untopiced,[JIT] Print better error when class attribute IValue conversion fails (#50255)
a48640af92,Uncategorized,Untopiced,[JIT] Update clang-format hashes (#50399)
fd0927035e,Uncategorized,Untopiced,.circleci: Remove CUDA 9.2 binary build jobs (#50388)
7efc212f1f,Uncategorized,Untopiced,Add link to tutorial in Timer doc (#50374)
e160362837,Uncategorized,Untopiced,Add range assert in autograd engine queue lookup (#50372)
d76176cc1f,Uncategorized,Untopiced,Raise warning during validation when arg_constraints not defined (#50302)
bb97503a26,Uncategorized,Untopiced,[fix] Indexing.cu: Move call to C10_CUDA_KERNEL_LAUNCH_CHECK to make it reachable (#49283)
9a3305fdd5,Uncategorized,Untopiced,Automated submodule update: tensorpipe (#50369)
ba83aea5ee,Uncategorized,Untopiced,[GPU] Calculate strides for metal tensors (#50309)
b001c4cc32,Uncategorized,Untopiced,"Stop using an unnecessary scalar_to_tensor(..., device) call. (#50114)"
f39f258dfd,Uncategorized,Untopiced,Ensure DDP + Pipe works with find_unused_parameters. (#49908)
5f8e1a1da9,Uncategorized,Untopiced,add type annotations to torch.nn.modules.module (#49045)
a72c6fd6e0,Uncategorized,Untopiced,[GPU] Fix the broken strides value for 2d transpose (#50310)
2193544024,Uncategorized,Untopiced,[GPU] Clean up the operator tests (#50311)
09f4844c1f,Uncategorized,Untopiced,Pytorch Distributed RPC Reinforcement Learning Benchmark (Throughput and Latency) (#46901)
72c1d9df75,Uncategorized,Untopiced,"Minor Fix: Double "";"" typo in transformerlayer.h (#50300)"
bee6b0be58,Uncategorized,Untopiced,Fix warning when running scripts/build_ios.sh (#49457)
4fed585dfa,Uncategorized,Untopiced,[MacOS] Add unit tests for Metal ops (#50312)
c3b4b20627,Uncategorized,Untopiced,[PyTorch] List::operator[] can return const ref for Tensor & string (#50083)
8c5b0247a5,Uncategorized,Untopiced,Fix PyTorch NEON compilation with gcc-7 (#50389)
78e71ce627,Uncategorized,Untopiced,warn user once for possible unnecessary find_unused_params (#50133)
4da9ceb743,Uncategorized,Untopiced,[doc] fix doc formatting for `torch.randperm` and `torch.repeat_interleave` (#50254)
fb73cc4dc4,Uncategorized,Untopiced,Migrate some torch.fft tests to use OpInfos (#48428)
d25c673dfc,Uncategorized,Untopiced,Cleanup unnecessary SpectralFuncInfo logic (#48712)
53473985b8,Uncategorized,Untopiced,test_ops: Only run complex gradcheck when complex is supported (#49018)
5546a12fe3,Uncategorized,Untopiced,remove redundant tests from tensor_op_tests (#50096)
314351d0ef,Uncategorized,Untopiced,Fix Error with torch.flip() for cuda tensors when dims=() (#50325)
9384d31af5,Uncategorized,Untopiced,Added linalg.pinv (#48399)
4411b5ac57,Uncategorized,Untopiced,add type annotations to torch.nn.modules.normalization (#49035)
6420071b43,Uncategorized,Untopiced,Disable complex dispatch on min/max functions (#50347)
5834438090,Uncategorized,Untopiced,Enable fast pass tensor_fill for single element complex tensors (#50383)
158c98ae49,Uncategorized,Untopiced,Add new patterns for ConcatAddMulReplaceNaNClip (#50249)
b5d3826950,Uncategorized,Untopiced,[PyTorch] Devirtualize TensorImpl::sizes() with macro (#50176)
035229c945,Uncategorized,Untopiced,[JIT] Frozen Graph Conv-BN fusion (#50074)
6971149326,Uncategorized,Untopiced,[JIT] Add Frozen Conv-> Add/Sub/Mul/Div fusion (#50075)
a69f008cb7,Uncategorized,Untopiced,[JIT] Factor out peephole to own test file (#50220)
30aeed7c2b,Uncategorized,Untopiced,"Peephole Optimize out conv(x).dim(), which prevents BN fusion (#50221)"
a389b30bfc,Uncategorized,Untopiced,"Add Post Freezing Optimizations, turn on by default in torch.jit.freeze (#50222)"
b2f7ff7d29,Uncategorized,Untopiced,Fix MultiheadAttention docstring latex (#50430)
5cdc32bf1c,Uncategorized,Untopiced,[vmap] Add batching rules for comparisons ops (#50364)
725640ed84,Uncategorized,Untopiced,Check CUDA kernel launches in caffe2/caffe2/utils/math (#50238)
cf45d65f1c,Uncategorized,Untopiced,Clean up some type annotations in test/jit/...../test_class_type.py (#50156)
c198e6c6fa,Uncategorized,Untopiced,Stop moving scalars to GPU for one computation in leaky_rrelu_backward. (#50115)
6d947067c9,Uncategorized,Untopiced,fixing autodiff to support Optional[Tensor] on inputs (#49430)
50744cd0f7,Uncategorized,Untopiced,[package] better error message when unpickling a mocked obj (#50159)
412e3f46e9,Uncategorized,Untopiced,Automated submodule update: tensorpipe (#50441)
39aac65430,Uncategorized,Untopiced,[quant][bug] Fixing the mapping getter to return a copy (#50297)
7d28f1c81d,Uncategorized,Untopiced,[quant][refactor] Minor refactor of some typos (#50304)
cb37709bee,Uncategorized,Untopiced,[te] Create TargetMachine only once with correct options to fix perf (#50406)
374951d102,Uncategorized,Untopiced,Add type annotations to torch.nn.modules.padding (#49494)
4c97ef8d77,Uncategorized,Untopiced,Create subgraph rewriter (#49540)
8c25b9701b,Uncategorized,Untopiced,Type annotations in test/jit (#50293)
af968cd672,Uncategorized,Untopiced,[Pytorch Mobile] Remove caching (in code) of interned strings (#50390)
49896c48e0,Uncategorized,Untopiced,Caffe2 Concat operator benchmark (#50449)
4e76616719,Uncategorized,Untopiced,[StaticRuntime][ATen] Add out variant for narrow_copy (#49502)
4e248eb3f6,Uncategorized,Untopiced,Change watchdog timeout logging from INFO to ERROR. (#50455)
dea529a779,Uncategorized,Untopiced,Add torch.cuda.can_device_access_peer (#50446)
a0f7b18391,Uncategorized,Untopiced,Fix `fmod` type promotion (#48278)
ca5d9617ba,Uncategorized,Untopiced,Fix remainder type promotion (#48668)
b54240d200,Uncategorized,Untopiced,[PyTorch] Gate tls_local_dispatch_key_set inlining off for Android (#50450)
057be23168,Uncategorized,Untopiced,[doc] Add note about `torch.flip` returning new tensor and not view. (#50041)
4a3a37886c,Uncategorized,Untopiced,Fix fft slow tests (#50435)
2a603145d7,skip,Untopiced,[AutoAccept][Codemod][FBSourceClangFormatLinter] Daily `arc lint --take CLANGFORMAT`
deba3bd1d0,Uncategorized,Untopiced,Fix TORCH_LIBRARIES variables when do static build (#49458)
664126bab5,Uncategorized,Untopiced,Enables build with oneDNN (MKL-DNN) on AArch64 (#50400)
4a2d3d1cfd,Uncategorized,Untopiced,MAINT: char class regex simplify (#50294)
05542f6222,Uncategorized,Untopiced,EMA op (#50393)
7d0eecc666,Uncategorized,Untopiced,Clean up some type annotations in benchmarks/fastrnns (#49946)
a4383a69d4,Uncategorized,Untopiced,Clean up some type annotations in caffe2/test (#49943)
fc5db4265b,Uncategorized,Untopiced,[BE] replace unittest.main with run_tests (#50451)
d2e96fcf17,Uncategorized,Untopiced,Update loss module doc (#48596)
48318eba40,Uncategorized,Untopiced,Fix TestOpInfoCUDA.test_unsupported_dtypes_addmm_cuda_bfloat16 on ampere (#50440)
36ae3feb22,Uncategorized,Untopiced,[te] Benchmark comparing fused overhead to unfused (#50305)
62f676f543,Uncategorized,Untopiced,[te] Optimize allocation of kernel outputs (#50318)
b89827b73f,Uncategorized,Untopiced,Drop unused imports (#49972)
7426878981,Uncategorized,Untopiced,Exclude test/generated_type_hints_smoketest.py from flake8 (#50497)
30a8ba93b1,Uncategorized,Untopiced,Remove a blacklist reference (#50477)
aeefe2ce31,Uncategorized,Untopiced,[ONNX] ONNX dev branch merge 01-06-2021 (#50163)
08b6b78c51,Uncategorized,Untopiced,[FX] Make FX stability warning reference beta (#50394)
21542b43a8,Uncategorized,Untopiced,[FX] Update docstring code/graph printout (#50396)
9ebea77299,Uncategorized,Untopiced,[PyTorch] Reapply D25687465: Devirtualize TensorImpl::dim() with macro (#50290)
50256710a0,Uncategorized,Untopiced,[PyTorch] Make TensorImpl::empty_tensor_restride non-virtual (#50301)
c6cb632c63,Uncategorized,Untopiced,[PyTorch] Make SROpFunctor a raw function pointer (#50395)
4a0d17ba2d,Uncategorized,Untopiced,[PyTorch][codemod] Replace immediately-dereferenced expect calls w/expectRef (#50228)
0b49778666,Uncategorized,Untopiced,[package] mangle imported module names (#50049)
a3f9cf9497,Uncategorized,Untopiced,Fix fastrnn benchmark regression introduced by 49946 (#50517)
5ea9584400,Uncategorized,Untopiced,Assemble technical overview of FX (#50291)
52ea372fcb,Uncategorized,Untopiced,[tools] Update clang-format linux hash (#50520)
fc9f013cea,Uncategorized,Untopiced,HalfCauchy should ValueError if _validate_args (#50403)
19a8e68d8c,Uncategorized,Untopiced,Structured kernel definition for upsample_nearest2d (#50189)
269193f5f5,Uncategorized,Untopiced,Revert D25859132: [te] Optimize allocation of kernel outputs
4ee631cdf0,Uncategorized,Untopiced,Revert D25856891: [te] Benchmark comparing fused overhead to unfused
934805bc49,Uncategorized,Untopiced,cleaned up ModuleAttributeError (#50298)
2639f1d4a6,Uncategorized,Untopiced,Revert D25717510: Clean up some type annotations in benchmarks/fastrnns
d2c3733ca1,Uncategorized,Untopiced,Reorder torch.distributed.rpc.init_rpc docstring arguments (#50419)
0abe7f5ef6,Uncategorized,Untopiced,[BE] fix subprocess wrapped test cases reported as failure (#50515)
443412e682,Uncategorized,Untopiced,"Add batched grad testing to gradcheck, turn it on in test_autograd (#49120)"
ef6be0ec50,Uncategorized,Untopiced,Revert D25903846: [pytorch][PR] Structured kernel definition for upsample_nearest2d
0be1a24b48,Uncategorized,Untopiced,Drop unused imports from caffe2/quantization (#50493)
e05882d2a4,Uncategorized,Untopiced,"Back out ""reuse consant from jit"" (#50521)"
1ea39094a8,Uncategorized,Untopiced,Link to mypy wiki page from CONTRIBUTING.md (#50540)
7fb935806d,Uncategorized,Untopiced,enable CPU tests back (#50490)
3dcf126c31,Uncategorized,Untopiced,Validate args in HalfCauchy and HalfNormal (#50492)
554a1a70c7,Uncategorized,Untopiced,[quant] update embedding module to not store qweight (#50418)
30e45bb133,Uncategorized,Untopiced,Enable GPU-to-GPU comm in TensorPipeAgent (#44418)
468c99fba4,Uncategorized,Untopiced,Reapply D25856891: [te] Benchmark comparing fused overhead to unfused (#50543)
51157e802f,Uncategorized,Untopiced,Use separate mypy caches for TestTypeHints cases (#50539)
171f265d80,Uncategorized,Untopiced,"Back out ""Revert D25717510: Clean up some type annotations in benchmarks/fastrnns"" (#50556)"
1908f56b3a,Uncategorized,Untopiced,"Fix warnings in ""ForeachOpsKernels"" (#50482)"
2ceaec704d,Uncategorized,Untopiced,Fix warnings in TensorShape (#50486)
08baffa8aa,Uncategorized,Untopiced,Drop blacklist from glow (#50480)
4de9d04f03,Uncategorized,Untopiced,[TensorExpr] Hook Fuser Pass to JIT opt-limit utility. (#50518)
be51de4047,Uncategorized,Untopiced,Minor doc improvement(?) on ArrayRef::slice (#50541)
9efe15313a,Uncategorized,Untopiced,"Revert D25563542: Add batched grad testing to gradcheck, turn it on in test_autograd"
e9dc8fc162,Uncategorized,Untopiced,[TensorExpr] Add python bindings. (#49698)
adc65e7c8d,Uncategorized,Untopiced,[ONNX] Handle sequence output shape and type inference (#46542)
6882f9cc1c,Uncategorized,Untopiced,[FX] Add wrap() docstring to docs and add decorator example (#50555)
d9f71b5868,Uncategorized,Untopiced,[WIP][FX] new sections in docs (#50562)
ffefa44e20,Uncategorized,Untopiced,Automated submodule update: tensorpipe (#50572)
366b00ab7b,skip,Untopiced,[AutoAccept][Codemod][FBSourceClangFormatLinter] Daily `arc lint --take CLANGFORMAT`
a9db2f8e7a,Uncategorized,Untopiced,Revert D24924236: [pytorch][PR] [ONNX] Handle sequence output shape and type inference
070a30b265,Uncategorized,Untopiced,"[BE] add warning message to cmake against env var ""-std=c++xx"" (#50491)"
00d432a1ed,Uncategorized,Untopiced,Remove optional for veiw_fn during View Tracking (#50067)
0d981eea6c,Uncategorized,Untopiced,add type annotations to torch.nn.modules.conv (#49564)
296e4a0b7f,Uncategorized,Untopiced,.circleci: Set +u for all conda install commands (#50505)
8e7402441d,Uncategorized,Untopiced,Move irange to c10 (#46414)
0ae0fac1bb,Uncategorized,Untopiced,"Clarify, make consistent, and test the behavior of logspace when dtype is integral (#47647)"
687f6a513a,Uncategorized,Untopiced,[PyTorch] Remove unnecessary dispatcher.h include in builtin_function.h (#50314)
60a1831e61,Uncategorized,Untopiced,[PyTorch] Remove unnecessary dispatcher.h include in op_registration.h (#50315)
c78e7db7ee,Uncategorized,Untopiced,[PyTorch] Remove unnecessary dispatcher.h include in mobile/interpreter.h (#50316)
ab1ba8f433,Uncategorized,Untopiced,[RPC] Support timeout in rref._get_type() (#50498)
d64184ef4c,Uncategorized,Untopiced,[RPC] Support timeout for RRef proxy functions (#50499)
6e3e57095c,Uncategorized,Untopiced,Add complex support for torch.nn.L1Loss (#49912)
8e60bf9034,Uncategorized,Untopiced,add RequiresGradCheck (#50392)
2569dc71e1,Uncategorized,Untopiced,Reapply D25859132: [te] Optimize allocation of kernel outputs (#50546)
b832604ffb,Uncategorized,Untopiced,Fix caffee2 for llvm trunk
585ee119cf,Uncategorized,Untopiced,Updated codecov config settings (#50601)
0291f35b37,Uncategorized,Untopiced,[FX] Make len traceable and scriptable with wrap (#50184)
3df5f9c3b2,Uncategorized,Untopiced,"Revert D25843351: [pytorch][PR] Clarify, make consistent, and test the behavior of logspace when dtype is integral"
c99f356051,Uncategorized,Untopiced,Stable sort for CPU (#50052)
0ea1abe07b,Uncategorized,Untopiced,[PyTorch] Add missing Dispatcher.h include in quantized_ops.cpp (#50646)
da5d4396c5,Uncategorized,Untopiced,remove dulicate newlines (#50648)
a469336292,Uncategorized,Untopiced,Fix pytorch-doc build (#50651)
2001f3a2c9,Uncategorized,Untopiced,Finished fleshing out the tensor expr bindings in expr.cpp (#50643)
7e05d07ca7,Uncategorized,Untopiced,[distributed_test_c10d]Enable disabled ROCm tests. (#50629)
534c82153e,Uncategorized,Untopiced,fix bn channels_last contiguity check (#50659)
1fdc35da2c,Uncategorized,Untopiced,[BE] Fix the broken test -- caffe2/caffe2/python:hypothesis_test - test_recurrent (#50668)
3f052ba07b,Uncategorized,Untopiced,Remove unnecessary dtype checks for complex types & disable complex dispatch for CPU min/max pointwise ops (#50465)
eae1b40400,Uncategorized,Untopiced,Introduced operator variant to OpInfo (#50370)
7f3a407225,Uncategorized,Untopiced,Multi label margin loss (#50007)
227acc2e51,Uncategorized,Untopiced,"Complex autograd support for torch.{baddbmm, addbmm, addmm, addmv} (#50632)"
d140ca8b69,Uncategorized,Untopiced,Optimize implementation of torch.pow (#46830)
f32b10e564,Uncategorized,Untopiced,[BE] Fix the broken test caffe2/caffe2/python:lazy_dyndep_test - test_allcompare (#50696)
8b501dfd98,Uncategorized,Untopiced,Fix memory leak in TensorPipeAgent. (#50564)
94d9a7e8ac,Uncategorized,Untopiced,Enable TensorPipe CUDA sending to self (#50674)
ce30dba36f,Uncategorized,Untopiced,Enable TensorPipe CUDA fallback channel (#50675)
e9b369c25f,Uncategorized,Untopiced,Add SELU Activation to calculate_gain (#50664)
d5e5c5455a,Uncategorized,Untopiced,[ROCm] re-enable test_sparse.py tests (#50557)
b75cdceb44,Uncategorized,Untopiced,[package] Properly demangle all accesses of `__name__` in importer.py (#50711)
5252e9857a,Uncategorized,Untopiced,[pytorch] clean up unused util srcs under tools/autograd (#50611)
c458558334,Uncategorized,Untopiced,kill `multinomial_alias_setup/draw` (#50489)
5f13cc861c,Uncategorized,Untopiced,Automated submodule update: tensorpipe (#50684)
316f0b89c3,Uncategorized,Untopiced,"[testing] Port `torch.{repeat, tile}` tests to use OpInfo machinery (#50199)"
f7a8bfd0a1,Uncategorized,Untopiced,"Add batched grad testing to gradcheck, turn it on in test_autograd (#50592)"
f9a5ba7398,Uncategorized,Untopiced,Added linalg.slogdet (#49194)
1000403f66,Uncategorized,Untopiced,Adding missing decorator for test_device_map_gpu_mixed_self_4 (#50732)
5d64658ce8,Uncategorized,Untopiced,"Add complex support for `torch.{acosh, asinh, atanh}` (#50387)"
1154a8594e,Uncategorized,Untopiced,Add instructional error message for cudnn RNN double backward workaround (#33884)
1a38fa9930,Uncategorized,Untopiced,Striding for lists Part 1 (#48719)
937eff5853,Uncategorized,Untopiced,Consolidate mypy tests and args (#50631)
4511f2cc9d,Uncategorized,Untopiced,Clean up complex autograd test list (#50615)
cad4753115,Uncategorized,Untopiced,Update TensorPipe submodule (#50733)
a9deaf3659,Uncategorized,Untopiced,Shouldn't need user local install for ROCm build (#50299)
5f33f22324,Uncategorized,Untopiced,Fix caffe2 import tools.codegen (#50353)
05036564cf,Uncategorized,Untopiced,Remove workaround for TensorPipe failing to get device of CUDA ptr (#50580)
3344f06130,Uncategorized,Untopiced,[FX] Fix using fx.wrap as a decorator (#50677)
0c9fb4aff0,Uncategorized,Untopiced,Disable tracer warning for slicing indices. (#50414)
f7b2b22b64,Uncategorized,Untopiced,Remove instance of blacklist (#50478)
ebd142e94b,Uncategorized,Untopiced,initial commit to enable fast_nvcc (#49773)
a1b1d0cdc0,Uncategorized,Untopiced,Better split of the windows test jobs (#50660)
a9e46f1413,Uncategorized,Untopiced,add type annotations to torch.nn.modules.container (#48969)
4816bf62d6,Uncategorized,Untopiced,Fix nvcc function signature causing assert in TypeIndex.h (#49778)
526659db20,Uncategorized,Untopiced,whitelist ops we can build shapes for (#49125)
327539ca79,Uncategorized,Untopiced,Fix bug in hipify if include_dirs is not specified in setup.py (#50703)
08c90d9e55,Uncategorized,Untopiced,Automated submodule update: tensorpipe (#50765)
7526e38cd3,Uncategorized,Untopiced,"Revert ""Stable sort for CPU (#50052)"" (#50752)"
38c45bdd2d,Uncategorized,Untopiced,[FX] Fix tracing a free function with embedded constant (#50639)
4ff1823fac,Uncategorized,Untopiced,Add Sparse support for torch.sqrt (#50088)
cebab83d3f,Uncategorized,Untopiced,Fix USE_MKLDN defaults (#50782)
47c57b8836,Uncategorized,Untopiced,Fix Native signature for optional Tensor arguments (#50767)
06c734d8c7,Uncategorized,Untopiced,"Generalize `sum_intlist` and `prod_intlist`, clean up dimensionality functions (#50495)"
dea9af5c06,Uncategorized,Untopiced,Cat benchmark: use mobile feed tensor shapes and torch.cat out-variant (#50778)
8f5ad00e13,Uncategorized,Untopiced,[JIT] Print out CU address in `ClassType::repr_str()` (#50194)
5205cc1c62,Uncategorized,Untopiced,[FX] Fix NoneType annotation in generated code (#50777)
e00966501b,Uncategorized,Untopiced,[quant] Add non-fbgemm fallback implementation for embedding lookup ops (#50706)
4aea007351,Uncategorized,Untopiced,[JIT] Fix archive file extension in examples and docs (#50649)
2ace4fc01e,Uncategorized,Untopiced,Add type annotations to torch.overrides (#48493)
4803eaf502,Uncategorized,Untopiced,Implement NumPy-like function torch.fmax() & torch.fmin() (#49312)
a3b8cbcdfc,Uncategorized,Untopiced,Let TensorPipe detect peer access (#50676)
4a8ef4525e,Uncategorized,Untopiced,Add new backend type for Intel heterogeneous computation platform. (#49786)
1f5c3b3aae,Uncategorized,Untopiced,Revert D25958987: [pytorch][PR] Add type annotations to torch.overrides
a722d28ef0,Uncategorized,Untopiced,[WIP] JIT Static Hooks: adding hooks to class type and adding logic for hook running/compilation (#49544)
9c49457233,Uncategorized,Untopiced,[WIP] JIT Static Hooks: schema checking logic (#49975)
0eb41e67fe,Uncategorized,Untopiced,[WIP] JIT Static Hooks: serialization logic (#49545)
3b88e1b0e7,Uncategorized,Untopiced,[WIP] JIT Static Hooks: python tests (#49546)
22902b9242,Uncategorized,Untopiced,[WIP] JIT Static Hooks: cpp tests (#49547)
e1bb476980,Uncategorized,Untopiced,Issue #48724. Only set the CMake IMPORTED_LOCATION property in static (#49173)
66adfcd258,Uncategorized,Untopiced,tools: Move sha check to else statement (#50773)
1cc8f8a750,Uncategorized,Untopiced,Add complex autograd support and OpInfo based test for torch.addr (#50667)
f1c578594b,Uncategorized,Untopiced,JIT Testing: Improve assertAutodiffNode error message (#50626)
4f3cdd971c,Uncategorized,Untopiced,Fix test_dispatch.py when running with TORCH_SHOW_CPP_STACKTRACES=1 (#50509)
1e0809dbf9,Uncategorized,Untopiced,[PyTorch] Remove CAFFE2_FB_LIMITED_MOBILE_CAPABILITY (#50385)
c18403a693,Uncategorized,Untopiced,[metal] Use MPSCNN kernels for binary elementwise ops
112a583467,Uncategorized,Untopiced,Enable TensorPipe's CMA channel (#50759)
fbf7eec86d,Uncategorized,Untopiced,Update JIT_OPT macro for easier use (#50602)
16faabe7f0,Uncategorized,Untopiced,[ROCm] re-enable tests (#50691)
cf1882adeb,Uncategorized,Untopiced,Fix indexing for overrides. (#49324)
db86dd8ad7,Uncategorized,Untopiced,Fix replication_pad for cuda launch configuration (#50565)
ac8e90fa6d,Uncategorized,Untopiced,quantization: Linear + BatchNorm1d fusion (#50748)
be7e9845a1,Uncategorized,Untopiced,Remove gtest_prod.h from TP agent. (#50766)
c3e3e60657,Uncategorized,Untopiced,Add cloud-tpu-client to xla CI. (#50823)
87fb3707d9,Uncategorized,Untopiced,ZeroRedundancyOptimizer: an implementation of a standalone sharded optimizer wrapper (#46750)
44922f26f5,Uncategorized,Untopiced,Add support for NCCL alltoall (#44374)
24fd84313f,Uncategorized,Untopiced,[pytorch] fix ConstRefCType usage in codegen/api/native.py (#50742)
1bde5a216f,Uncategorized,Untopiced,[TensorExpr] Use wider type for scalars (#50774)
c147aa306c,Uncategorized,Untopiced,Use doctest directly to get docstring examples (#50596)
7fdc6a27b8,Uncategorized,Untopiced,Skip test_variant_consistency_eager_addr_cpu_bfloat16 (#50836)
c945a5bb5e,Uncategorized,Untopiced,fix typo of quantized README.md (#50681)
4954417163,Uncategorized,Untopiced,CONTRIBUTING.md: add instructions on how to remote desktop into Windows CI (#50841)
c88eed97c7,Uncategorized,Untopiced,Make `split_module` results deterministic (#50470)
d0e942f9a7,Uncategorized,Untopiced,[FX][docs] Add limitations of symbolic tracing (#50638)
439afda090,Uncategorized,Untopiced,[Gradient Compression] Fix warm-start for PowerSGD laywerwise compression (#50283)
480bb7d356,Uncategorized,Untopiced,Automated submodule update: tensorpipe (#50807)
24a0272132,Uncategorized,Untopiced,Enable Skipped ROCM Tests in common_nn.py (#50753)
88b36230f5,Uncategorized,Untopiced,Add full reduction benchmark. (#50057)
b96a6516a6,Uncategorized,Untopiced,Add CPP Full Reduction Benchmarks. (#50193)
a0cf5566d8,Uncategorized,Untopiced,[optimizer] refactor SGD to use functional API (#45597)
d6fb27ce72,Uncategorized,Untopiced,[optimizer] refactor Adadelta to use functional API (#50409)
ce1781d8db,Uncategorized,Untopiced,[optimizer] refactor RMSProp to use functional API (#50410)
df96344968,Uncategorized,Untopiced,[optimizer] refactor AdamW to use functional API (#50411)
4ac489091a,Uncategorized,Untopiced,Improve call provenance during GraphModule scripting (#50538)
4cca08368b,Uncategorized,Untopiced,Adds per-op microbenchmarks for NNC (#50845)
4d169258ef,Uncategorized,Untopiced,Revert D25976245: [pytorch][PR] Enable Skipped ROCM Tests in common_nn.py
b5242d66b6,Uncategorized,Untopiced,[quant][doc] Adding a table comparing eager and fx graph mode (#50413)
98e2914614,Uncategorized,Untopiced,[android] Fix YUV camera image to tensor (#50871)
8ede828df7,Uncategorized,Untopiced,[te] Speed up relu on cpu
884fb48794,Uncategorized,Untopiced,Miscellaneous batched grad testing (#50738)
1cce4c5eee,Uncategorized,Untopiced,Update Kineto revision (#50855)
16691516a5,Uncategorized,Untopiced,Add batched grad testing to OpInfo (#50818)
3cd8ed972a,Uncategorized,Untopiced,add and adjust kernel launch checks under fbcode/caffe2/caffe2/utils (#50862)
201f0c1fdf,Uncategorized,Untopiced,Automated submodule update: tensorpipe (#50895)
c082e2184d,Uncategorized,Untopiced,Add autograd tests for complex matrix norm nuclear and +/-2 (#50746)
137f2a385a,Uncategorized,Untopiced,[ONNX] Handle sequence output for models (#50599)
8e9ed27a53,Uncategorized,Untopiced,install magma for cuda 11.2 in conda (#50559)
aa3c28a29e,Uncategorized,Untopiced,[static runtime] Shortcut resize_({0})
eb0fe70680,Uncategorized,Untopiced,[distributed_test]Enable disabled ROCm tests. (#50421)
5016637955,Uncategorized,Untopiced,[FX] Update overview docstring (#50896)
21c2542b6a,Uncategorized,Untopiced,Independent constraint (#50547)
3aed177484,Uncategorized,Untopiced,[PyTorch] inline Dispatcher::singleton (#50644)
533cb9530e,Uncategorized,Untopiced,Introducing TORCH_CUDA_CPP_API and TORCH_CUDA_CU_API to the code (#50627)
57fb2c0fcc,Uncategorized,Untopiced,[PPC] Add missing vec_[signed|neg|sldw] definitions (#50640)
d46210958e,Uncategorized,Untopiced,Remove `use_c10_dispatcher: full` lines added in the last couple days (#50769)
bb909d27d5,Uncategorized,Untopiced,[PyTorch Mobile] Eliminate static default_extra_files_mobile from header import.h (#50795)
d33cc4c01b,Uncategorized,Untopiced,"Use quiet_NaN() in calc_digamma, not NAN (#50412)"
7f22af13b9,Uncategorized,Untopiced,Add alternative prettyprinting method to `Graph` (#50878)
7494f0233a,Uncategorized,Untopiced,snake_case FX IR names (#50876)
e34992ebee,Uncategorized,Untopiced,Set USE_KINETO=1 (#49897)
8eb90d4865,Uncategorized,Untopiced,Add Gaussian NLL Loss (#50886)
b2e5617553,Uncategorized,Untopiced,[ROCm] rename HIP_HCC_FLAGS to HIP_CLANG_FLAGS (#50917)
c7d348fea6,Uncategorized,Untopiced,Turn on batched grad testing for non-autogenerated tests in test_nn.py (#50739)
2ba2ab9e46,Uncategorized,Untopiced,[packaging] add support for BytesIO (#50838)
5f07b53ec2,Uncategorized,Untopiced,[TensorExpr] Add LoopNest::simplify. (#50850)
4bbff92014,Uncategorized,Untopiced,Refactor build targets for torch::deploy (#50288)
0436ea125b,Uncategorized,Untopiced,OpInfo: Remove promotes_integers_to_float and infer it instead (#50279)
002d978428,Uncategorized,Untopiced,Sparse benchmarking utils (#48397)
9ac30d96aa,Uncategorized,Untopiced,Add complex IValues (#50883)
47f0bda3ef,Uncategorized,Untopiced,Improve complex support in common_nn test machinery (#50593)
d60d108280,Uncategorized,Untopiced,[nnc] Expose fast tanh/sigmoid (#50736)
156da22566,Uncategorized,Untopiced,[PyTorch] Eliminate static default_extra_files_mobile from header import.h (#50832)
89cafde8a4,Uncategorized,Untopiced,Modernize for-loops (#50912)
d5dc65a45c,Uncategorized,Untopiced,Document example of Proxy use (#50583)
7cb4712b38,Uncategorized,Untopiced,count_nonzero with requires grad (#50866)
8ab1a1495d,Uncategorized,Untopiced,Rename `set_deterministic` to `use_deterministic_algorithms` (#49904)
c908ebd4a1,Uncategorized,Untopiced,[android] fix yuv conversion - remove define (#50951)
db079a9877,Uncategorized,Untopiced,Padding: support complex dtypes (#50594)
a291b254ee,Uncategorized,Untopiced,Migrate masked_scatter_ CPU to ATen (#49732)
7b12893155,Uncategorized,Untopiced,[BE] .gitignore adding test-reports/ folder (#50952)
2ab497012f,Uncategorized,Untopiced,Add at::cpu namespace of functions for structured kernels (#49505)
7e10fbfb71,Uncategorized,Untopiced,Add note about TCP init in RPC tests to contributing doc. (#50861)
73dffc8452,Uncategorized,Untopiced,Refactor mypy configs list into editor-friendly wrapper (#50826)
ca3ce77746,Uncategorized,Untopiced,Dump torch::jit::AliasDb objects as Graphviz files (#50452)
78f30386c5,Uncategorized,Untopiced,Implement Swish(SiLU) operator in FP16
f0e72e54cc,Uncategorized,Untopiced,Fix CUDA RPC Stream Synchronization (#50949)
dd1c2a06b7,Uncategorized,Untopiced,refactor profiling optional (#47667)
a66851a2ad,Uncategorized,Untopiced,[FX] torch.fx.symbolic_trace patching improvements and `math.*` support (#50793)
de8cd6b201,Uncategorized,Untopiced,[BE] Replace M_PI with c10::pi constexpr variable (#50819)
63838b9330,Uncategorized,Untopiced,Turn on batched_grad testing for NewModuleTest (#50740)
ffc8a26991,Uncategorized,Untopiced,philox_engine_inputs should also round increment to a multiple of 4 (#50916)
5c1c858ca8,Uncategorized,Untopiced,Revert D25977352: [pytorch][PR] Refactor mypy configs list into editor-friendly wrapper
789f6f1250,Uncategorized,Untopiced,[FX] Minor docs changes (#50966)
ab331da7ac,Uncategorized,Untopiced,Rewrite kron with broadcasting at::mul (#50927)
ce0f335515,Uncategorized,Untopiced,[PyTorch Mobile] Add an overload for deserialize() that doesn't accept the extra_files map. (#50932)
069e68a2a4,Uncategorized,Untopiced,Fix ScriptModule docstring (#48608)
6aec1eba15,Uncategorized,Untopiced,[aten] Make aten::flatten call native::reshape (#50859)
5a661e0171,Uncategorized,Untopiced,[WIP][Grad Compression] Unittest to verify allreduce_hook parity (#50851)
5cbe1e4933,Uncategorized,Untopiced,[dist_optim] add distributed functional Adam optimizer (#50624)
cd2067539e,Uncategorized,Untopiced,[dist_optim] add distributed functional sgd optimizer (#50618)
6c81b4d917,Uncategorized,Untopiced,[dist_optim] add distributed functional Adadelta optimizer (#50623)
3f982e56b1,Uncategorized,Untopiced,[dist_optim] add distributed functional RMSprop optimizer (#50619)
2c3c2a4b7a,Uncategorized,Untopiced,[dist_optim] add distributed functional AdamW optimizer (#50620)
e544d74c55,Uncategorized,Untopiced,[CPU] Add torch.trace for complex tensors (#50380)
c9cae1446f,Uncategorized,Untopiced,fix unflatten_dense_tensor when there is empty tensor inside (#50321)
1f40f2a172,Uncategorized,Untopiced,Add improved support for parallelization and related graph opts (#5257)
186c3da037,Uncategorized,Untopiced,Add cusolver gesvdj and gesvdjBatched to the backend of torch.svd (#48436)
48b6b9221a,Uncategorized,Untopiced,[BE] Make Vec256 header only library (#50708)
627a331257,Uncategorized,Untopiced,Port CPU torch.orgqr to ATen (#50502)
5a5bca8ef0,skip,Untopiced,[AutoAccept][Codemod][FBSourceClangFormatLinter] Daily `arc lint --take CLANGFORMAT`
8690819618,Uncategorized,Untopiced,OpInfo: Add DecorateInfo class similar to SkipInfo for decorators (#50501)
806010b75e,Uncategorized,Untopiced,[BE] move more unittest.main() to run_tests() (#50923)
a6257b2fe2,Uncategorized,Untopiced,Fix #48903 (#50817)
f7b339d11c,Uncategorized,Untopiced,Clarify wording around overrides subclasses. (#51031)
5e79b8e06d,Uncategorized,Untopiced,"Back out ""Revert D25903846: [pytorch][PR] Structured kernel definition for upsample_nearest2d"" (#50794)"
ac0a3cc5fd,Uncategorized,Untopiced,Merge CompilationUnit from torch._C and torch.jit (#50614)
09b896261c,Uncategorized,Untopiced,Skip test_lc_1d for ROCM (#50964)
95a0a1a18f,Uncategorized,Untopiced,Update docstring on return type of `jvp` and `vjp` (#51035)
28869d5a80,Uncategorized,Untopiced,[quant][graphmode][fx] Add support for quantizing functional linear + {functional relu/module relu} (#50975)
75cba9d0d1,Uncategorized,Untopiced,More about cudnn refactor (#50827)
9dfbfe9fca,Uncategorized,Untopiced,Add type annotations to torch.overrides (#50824)
a7cf04ec40,Uncategorized,Untopiced,Workaround for MAGMA accessing illegal memory in batched cholesky (#50957)
68c218547c,Uncategorized,Untopiced,Add documentation page for pipeline parallelism. (#50791)
f8eefbdf7a,Uncategorized,Untopiced,fake_quant: fix device affinity and buffer resizing for state_dict (#50868)
ddf26816d3,Uncategorized,Untopiced,"Make torch.svd return V, not V.conj() for complex inputs (#51012)"
3192f9e4fe,Uncategorized,Untopiced,"Add torch::deploy, an embedded torch-python interpreter (#50458)"
250c71121b,Uncategorized,Untopiced,Create a DDPLoggingData and expose it to python interface (#50622)
a347c747df,Uncategorized,Untopiced,Fix TransformedDistribution shaping logic (#50581)
5adbace8e6,Uncategorized,Untopiced,Abort node in fast_nvcc if ancestor fails (#51043)
6ef66213ee,Uncategorized,Untopiced,[PT QNNPACK] Temporarily disable input pointer caching (#51051)
502ca0105d,Uncategorized,Untopiced,Added cuda bindings for NNC (#51046)
880f007480,Uncategorized,Untopiced,"Add torch.eig complex forward (CPU, CUDA) (#49168)"
ffaae32d60,Uncategorized,Untopiced,[Gradient Compression] Allow PowerSGD to run vallina allreduce for the first K iterations (#50973)
9f19843d19,Uncategorized,Untopiced,[Gradient Compression] Typo fixes in PowerSGD (#50974)
a51b9a823c,Uncategorized,Untopiced,Improve docs around Math/DefaultBackend & add PythonDispatcher class. (#50854)
e843974a6e,Uncategorized,Untopiced,"Revert D25850783: Add torch::deploy, an embedded torch-python interpreter"
83315965ab,Uncategorized,Untopiced,Turn on batched grad testing for CriterionTest (#50744)
233e4ebdb6,Uncategorized,Untopiced,Implement autograd functions for c10d communication operations (#40762)
95ae9a20e4,Uncategorized,Untopiced,Enable ROCM Skipped tests in test_ops.py (#50500)
5f297cc665,Uncategorized,Untopiced,Automated submodule update: tensorpipe (#50946)
5834b3b204,Uncategorized,Untopiced,Fix test_jit_cuda_archflags on machine with more than one arch (#50405)
31194750f2,Uncategorized,Untopiced,[jit] Fix ResolutionCallback definition (#51089)
6dda0363bb,Uncategorized,Untopiced,[reland] Refactor mypy configs list into editor-friendly wrapper (#50826)
3562ca2da2,Uncategorized,Untopiced,[dist_optim] add warning to distributed optimizer (#50630)
b822aba8ec,Uncategorized,Untopiced,Enable BFloat support for gemms on arch other than ampere (#50442)
afa79a4df5,Uncategorized,Untopiced,[quant][graphmode][fx] cleanup linear module test case (#50976)
81ae8edf16,Uncategorized,Untopiced,Revert D26018916: [pytorch][PR] Automated submodule update: tensorpipe
c8a24ebe54,Uncategorized,Untopiced,Move AcceleratedGraphModule out of graph_manipulation.
a949d7b1c8,Uncategorized,Untopiced,Workaround Python3.9 limitations in test_jit_py3 (#51088)
83bfab2fb6,Uncategorized,Untopiced,toTensor cleanup on sparsenn & static runtime ops (#51113)
069602e028,Uncategorized,Untopiced,[torch vitals] Initial implementation (#51047)
6f3aa58d80,Uncategorized,Untopiced,Fix autograd thread crash with python-3.9 (#50998)
f08464f31d,Uncategorized,Untopiced,[nnc] Add benchmarks
c4029444d1,Uncategorized,Untopiced,[nnc] Per-operator benchmarks (#51093)
24eab1d80d,Uncategorized,Untopiced,BLD: create a LICENSE_BUNDLED.txt file from third_party licenses (#50745)
57484103be,Uncategorized,Untopiced,Revert D25675618: Move AcceleratedGraphModule out of graph_manipulation.
97ea95ddd7,Uncategorized,Untopiced,Delete tabs from becnh_approx.cpp (#51157)
345844d9d8,Uncategorized,Untopiced,"test, fix deepcopy of tensor with grad (#50663)"
3cc14a0dff,Uncategorized,Untopiced,[p2c2] Add support for Int8FCPackWeight in model transformation
221d7d99e1,Uncategorized,Untopiced,[torch vitals] move into namespace and fix windows tests
e2041ce354,Uncategorized,Untopiced,Fix docstring to clarify logits usage for multiclass case (#51053)
b6eaca9f1f,Uncategorized,Untopiced,Add type annotation logic for complex numbers (#50884)
ba316a7612,Uncategorized,Untopiced,Fix TF32 failures in test_linalg.py (#50453)
42929e573a,Uncategorized,Untopiced,add missing return statement to inlined vec_signed (#51116)
1935880860,Uncategorized,Untopiced,[PyTorch] Remove unnecessary dispatcher.h include in torch/library.h (#51162)
7b85adf20f,Uncategorized,Untopiced,Add back pycuda.autoinit to test_pt_onnx_trt (#51106)
b60494000b,Uncategorized,Untopiced,DOC: udate left navbar links for vision and text (#51103)
0a4bc72890,Uncategorized,Untopiced,[ROCm] work around compiler issue for IGammaKernel.cu (#50970)
ada916675f,Uncategorized,Untopiced,update HistogramObserver to be scriptable (#51081)
fd9a85d21b,Uncategorized,Untopiced,Doc update for complex numbers (#51129)
22ac4f3c59,Uncategorized,Untopiced,"Add `vectorize` flag to torch.autograd.functional.{jacobian, hessian} (#50915)"
5ec2e26310,Uncategorized,Untopiced,"DOC, BLD: make the python docs build failures print a nicer message (#50356)"
0b5303e833,Uncategorized,Untopiced,Propagate CreationMeta when chaining views (#51061)
4a2aa0f5f1,Uncategorized,Untopiced,index_put_ for complex tensors on CUDA (#51148)
16dd5ca8ab,Uncategorized,Untopiced,Followup of kron PR (#51045)
e9ffad088f,Uncategorized,Untopiced,numeric suite: add types to eager (#51168)
9b6d463704,Uncategorized,Untopiced,Move std and var tests to OpInfos (#50901)
00adc7b07f,Uncategorized,Untopiced,Fix more JIT tests under Python-3.9 (#51182)
d3ec204ef2,Uncategorized,Untopiced,[quant][graphmode][fx] Add functional conv2d + relu (#51079)
b77f72b5a0,Uncategorized,Untopiced,Enable TensorPipe's SHM transport (#50760)
1b7a4f9cde,Uncategorized,Untopiced,.github: Add GitHub Actions workflow to build wheels (#50633)
dd1a97b3ae,Uncategorized,Untopiced,[quant][graphmode][fx] Add support for functional conv1d and conv3d (#51155)
6d098095eb,Uncategorized,Untopiced,[numpy] torch.lgamma: promote integer inputs to float (#50140)
40eea6d9d1,Uncategorized,Untopiced,Support device map for distributed autograd while using TensorPipe. (#44859)
f7e90cf311,Uncategorized,Untopiced,Revert D26089965: [quant][graphmode][fx] Add support for functional conv1d and conv3d
1c8d11c9e2,Uncategorized,Untopiced,[PyTorch] Save a refcount bump in make_variable (#51180)
eaf5ca09dc,Uncategorized,Untopiced,Migrate masked_scatter_ CUDA to ATen (#50039)
3b6f30824c,Uncategorized,Untopiced,OpInfo JIT op.output_func handling support (#50775)
2de4ecd4eb,Uncategorized,Untopiced,Add serialization logic for complex numbers (#50885)
621198978a,Uncategorized,Untopiced,Move USE_NUMPY to more appropriate targets (#51143)
98d9a6317d,Uncategorized,Untopiced,Rename profile.next_step() to profile.step() to consistent with optimizer.step() (#51032)
1321f2bfe6,Uncategorized,Untopiced,[PyTorch] Port Caffe2 opti for BatchMatMul batch size 1 to baddbmm (#51057)
3f23ad5bce,Uncategorized,Untopiced,[Bug] fix for module_has_exports (#50680)
42aeb68128,Uncategorized,Untopiced,[TensorExpr] Move 'initializer' field from 'Tensor' to 'Buf'. (#50993)
b804084428,Uncategorized,Untopiced,[TensorExpr] Move 'lowerToStmt' method from 'LoopNest' to 'Tensor'. (#50994)
e975169426,Uncategorized,Untopiced,[TensorExpr] Redesign `Tensor` class. (#50995)
dc2a44c4fc,Uncategorized,Untopiced,"Back out ""Revert D25850783: Add torch::deploy, an embedded torch-python interpreter"" (#51124)"
1c9347c666,Uncategorized,Untopiced,[ONNX] Use parameter values in onnx shape inference (#49706) (#50905)
7e4c956955,Uncategorized,Untopiced,[ONNX] Support opset13 Squeeze and Unsqueeze (#50150) (#50906)
1723ab53c4,Uncategorized,Untopiced,[ONNX] Update Reducesum operator for opset 13 (#50532) (#50907)
b308fb78d1,Uncategorized,Untopiced,[ONNX] Add binary_cross_entropy_with_logits op to ONNX opset version 12 (#49675) (#50908)
e90a480d40,Uncategorized,Untopiced,"[ONNX] Add logical_and, logical_or, logical_xor torch op support in pytorch exporter (#50570) (#50909)"
70dcfe2991,Uncategorized,Untopiced,[ONNX] Enable _jit_pass_onnx_fold_if only when dynamic_axes is None (#50582) (#50910)
68034197e8,Uncategorized,Untopiced,[ONNX] Support gelu for fp16 export (#50487) (#50911)
84e9bff85d,Uncategorized,Untopiced,[ONNX] Replace optional parameters of Resize with placeholder for ops13. (#50574) (#50954)
e2eb97dd76,Uncategorized,Untopiced,[ONNX] Fix param names (#50764) (#50955)
4fb33f1d3a,Uncategorized,Untopiced,Trim profiler file paths (#51192)
ea0d304e2e,Uncategorized,Untopiced,"Rewrite ""ProfilerStep#<num>"" in profiler output (#51194)"
d14d8c7f7f,Uncategorized,Untopiced,Add convenience import (#51195)
983b8e6b62,Uncategorized,Untopiced,fake_quant: add a more memory efficient version (#50561)
0335222a4a,Uncategorized,Untopiced,"memory efficient fq: use it everywhere, delete the old version (#51159)"
dfdb1547b9,Uncategorized,Untopiced,Revert D26094906: Add serialization logic for complex numbers
12a434abbc,Uncategorized,Untopiced,"Revert D26077905: Back out ""Revert D25850783: Add torch::deploy, an embedded torch-python interpreter"""
88baf470d1,Uncategorized,Untopiced,[JIT] Provide more info when attribute fails to convert (#50870)
773c71cb3a,Uncategorized,Untopiced,[atem] Fix type check bug in bmm_out_or_baddbmm_ (#51248)
83287a6f2b,Uncategorized,Untopiced,[pytorch] change codegen dispatch key from string to enum (#51115)
52ab858f07,Uncategorized,Untopiced,STFT: Improve error message when window is on wrong device (#51128)
16132a4b1d,Uncategorized,Untopiced,Make sure ConstantPadNd op preserves memory format (#50898)
d035d56bfb,Uncategorized,Untopiced,[StaticRuntime] Add out variant for reshape and flatten (#51249)
9fe7c0633f,Uncategorized,Untopiced,Add centered FFT example to fftshift docs (#51223)
392abde8e6,Uncategorized,Untopiced,patch nvrtc API for cuda TK >= 11.1 (#50319)
df07e1cea8,Uncategorized,Untopiced,Automated submodule update: tensorpipe (#51203)
0e8e739a9f,Uncategorized,Untopiced,Move AcceleratedGraphModule out of graph_manipulation. (#51220)
7a8c64da4d,skip,Untopiced,[AutoAccept][Codemod][FBSourceClangFormatLinter] Daily `arc lint --take CLANGFORMAT`
b955da3310,Uncategorized,Untopiced,Adding correct error message for for..else (#51258)
096adf4b8b,Uncategorized,Untopiced,[quant][fx] Scope support for call_function in QuantizationTracer (#51086)
4c3f59b70e,Uncategorized,Untopiced,"[quant][fx] Make scale, zero_point buffers in the model and use FQN (for quantized ops) (#51166)"
288b94a8ee,Uncategorized,Untopiced,"[quant][fx] Make scale, zero_point buffers in the model, use FQN (for quantize_per_tensor ops) (#51171)"
c9cebaf9b8,Uncategorized,Untopiced,Enable TensorPipe's InfiniBand transport (#50761)
cc211bb43e,Uncategorized,Untopiced,.github: Add workflow to stale pull requests (#51237)
4288f08d30,Uncategorized,Untopiced,Enable TensorPipe's CUDA GDR channel (#50763)
33d5180684,Uncategorized,Untopiced,[fx] improve args mutation error (#51175)
cedfa4ccd8,Uncategorized,Untopiced,Make DeviceCachingAllocator's error handling more defensive and a bit easier to read (#51158)
96cedefd8e,Uncategorized,Untopiced,[Pipe] Refactor convert_to_balance under non-test package. (#50860)
8b27c2ccca,Uncategorized,Untopiced,add mising VSX dispatches (#51217)
b028653670,Uncategorized,Untopiced,Add missing -inf order for linalg.norm OpInfo (#51233)
f68e5f1dbf,Uncategorized,Untopiced,.github: Update stale messaging add newlines (#51298)
1379842f4a,Uncategorized,Untopiced,Add private mechanism to toggle vmap fallback warnings (#51218)
35990b5f56,Uncategorized,Untopiced,.github: Remove title from stale alert (#51306)
7097c0d4f3,Uncategorized,Untopiced,[quant][graphmode][fx] Add support for functional conv1d and conv3d (#51155) (#51254)
9f6e0de548,Uncategorized,Untopiced,Update third_party/build_bundled.py (#51161)
6e4746c1ac,Uncategorized,Untopiced,Port cholesky_inverse to ATen (#50269)
f9f22c8b5c,Uncategorized,Untopiced,Add serialization logic for complex numbers (#51287)
5ed0ad4b6a,Uncategorized,Untopiced,DataPipe naming convension update (#51262)
592a8ad1c8,Uncategorized,Untopiced,Define static constexpr variable in at::native::vulkan:::api::Handle. (#51006)
8a8fac6681,Uncategorized,Untopiced,Remove debug-only assertion from vulkan::api::Command::Command as the buffer can legitimately be null. (#51160)
00d4ec840e,Uncategorized,Untopiced,clone pytorch.github.io with depth 1 (#48115)
b619d37bb4,Uncategorized,Untopiced,[Gradient Compression] Simplify the implementation of error feedback and warm-start (#50981)
9d731e87de,Uncategorized,Untopiced,[Gradient Compression] Explicitly specify the dtype of the error tensor (#50985)
e7b3496232,Uncategorized,Untopiced,[Gradient Compression] Refactor default_hooks.py and powerSGD_hook.py by creating a util function that make a vanilla allreduce future (#51094)
f2e41257e4,Uncategorized,Untopiced,"Back out ""Revert D26077905: Back out ""Revert D25850783: Add torch::deploy, an embedded torch-python interpreter"""" (#51267)"
267e243064,Uncategorized,Untopiced,fake_quant: more memory efficient per-channel backward (#51255)
05c8cd748d,Uncategorized,Untopiced,"memory efficient per-channel fq: use it everywhere, delete old version (#51265)"
916af892b3,Uncategorized,Untopiced,[quant][fx] Update name of packed weight attributes (#51259)
43f0ccd1ec,Uncategorized,Untopiced,torch.cuda.memory_allocated to return `{}` if not initialized (#51179)
1114fd6b3a,Uncategorized,Untopiced,[nnc] Refactor generation of intrinsics to reduce the amount of macro-hell (#51125)
0a065ebe86,Uncategorized,Untopiced,[nnc][trivial] Refactor llvm_jit so the wrapper class doesn't depend on ifdefs (#51186)
d74a226daa,Uncategorized,Untopiced,[nnc] Use sleef if its symbols are available (#51187)
0a9764ecc1,Uncategorized,Untopiced,[nnc] Expose vectorized math functions to jit fuser. (#51190)
534aabce14,Uncategorized,Untopiced,[nnc] Don't use sleef where it's slower (#51246)
ebe26b81d2,Uncategorized,Untopiced,[PyTorch Mobile] Enable partial loading of GPU models on linux CPU machines (#51236)
3397919dcf,Uncategorized,Untopiced,"Rowwise Prune op (Add the test to OSS run_test), Make the op private. (#46131)"
270111b7b6,Uncategorized,Untopiced,split quantization jit op (#51329)
5a406c023e,Uncategorized,Untopiced,Revert D26070147: [Gradient Compression] Refactor default_hooks.py and powerSGD_hook.py by creating a util function that make a vanilla allreduce future
c0966914bc,Uncategorized,Untopiced,Internal gradcheck wrapper in testing._internal that sets certain flags to True (#51133)
1b479416b7,Uncategorized,Untopiced,Clarify logic in `ir_emitter` (#51299)
30675d0921,Uncategorized,Untopiced,Added OpInfo-based testing of triangular_solve (#50948)
edaa23c8ab,Uncategorized,Untopiced,extend init_group_test timeout to 5s (#51330)
1b089c1257,Uncategorized,Untopiced,Modernize for-loops (#50899)
5021582fe6,Uncategorized,Untopiced,Fix benchmarks/distributed/ddp/benchmark.py (#51095)
c41ca4ae5b,Uncategorized,Untopiced,[doc]Fix autograd.detect_anomaly docs incorrectly formatted (#51335)
dfca1e48d3,Uncategorized,Untopiced,Replace all AT_ASSERTM under c10/ (except Exception.h) (#50843)
ebd2a82559,Uncategorized,Untopiced,Replace all AT_ASSERTM in RNN_miopen.cpp (#51072)
dbfaf966b0,Uncategorized,Untopiced,[android] turn on USE_VULKAN for android builds by default (#51291)
52609c8c65,Uncategorized,Untopiced,.github: Up frequency of stale checks (#51365)
da920fa141,Uncategorized,Untopiced,Enable rocm tests in common nn (#51227)
fe645fdfc7,Uncategorized,Untopiced,Update _torch_docs.py (#51212)
a88e1d3ddf,Uncategorized,Untopiced,[complex] Complex support for masked_scatter and autograd support for masked_scatter and masked_select (#51281)
662b6d2115,Uncategorized,Untopiced,[dist_optim] update the doc of DistributedOptimizer (#51314)
d5541c50a3,Uncategorized,Untopiced,add a c++ interface in processGroup to get its backend name (#51066)
7d30f67659,Uncategorized,Untopiced,remove LegacyDefinitions as it is empty now (#51251)
7ab89f58be,Uncategorized,Untopiced,expose memory_fraction and gpu_process docs (#51372)
09e48dbd33,Uncategorized,Untopiced,Handle error during dict expansion (#51374)
11cda929fb,Uncategorized,Untopiced,[StaticRuntime] Fix bug in MemoryPlanner (#51342)
17b5683156,Uncategorized,Untopiced,Multi-GPU Kineto profiler test (#51391)
e26fccc22b,Uncategorized,Untopiced,update profiler doc strings (#51395)
721ba97eb6,Uncategorized,Untopiced,Create op benchmark for stack (#51263)
c255628134,Uncategorized,Untopiced,[Collective APIs] Make python object collective API args consistent (#50625)
9cf62a4b5d,Uncategorized,Untopiced,[1.8] Add additional tests for object-based APIs (#51341)
0e1c5cb354,Uncategorized,Untopiced,fixing index clamping for upsample nearest kernel backward (#51240)
d1dcd5f287,Uncategorized,Untopiced,[fbgemm_gpu] Use the latest philox_cuda_state API for stochastic rounding (#51004)
40c0fffb4b,Uncategorized,Untopiced,Fixes docs (#51439)
508bab43e7,Uncategorized,Untopiced,Support complex number list in JIT (#51145)
b1907f5ebc,Uncategorized,Untopiced,Fix pickling for Tensor subclasses (redo) (#47732)
449098c2d2,Uncategorized,Untopiced,[SobolEngine] Update direction numbers to 21201 dims (#49710)
50fa415a4d,Uncategorized,Untopiced,[testing] Add OpInfo for ceil and floor (#51198)
765062c085,Uncategorized,Untopiced,[PyTorch] Devirtualize TensorImpl::storage_offset (#51048)
6c24296795,Uncategorized,Untopiced,[PyTorch] Devirtualize TensorImpl::has_storage (#51049)
0831984ed5,Uncategorized,Untopiced,[Resubmission][Gradient Compression] Refactor default_hooks.py and powerSGD_hook.py by creating a util function that make a vanilla allreduce future (#51400)
609f76f27a,Uncategorized,Untopiced,[WIP][FX] Add Interpreter and Transformer (#50420)
ec611aca88,Uncategorized,Untopiced,[Pytorch Mobile] Expose _export_operator_list to python (#51312)
673687e764,Uncategorized,Untopiced,[PyTorch] Refactor Dispatcher to inline less code in fast path (#51163)
341c76dcc1,Uncategorized,Untopiced,[PyTorch] Add C10_ALWAYS_INLINE to critical dispatcher paths (#51245)
4495b49ffa,Uncategorized,Untopiced,[PyTorch] Pass TensorOptions by value (#51165)
9877777fee,Uncategorized,Untopiced,[PyTorch] check isValidUnboxed() in the dispatcher (#51247)
d1ddc5d65d,Uncategorized,Untopiced,[PyTorch] Outline OperatorEntry::assertSignatureIsCorrect fail path (#51269)
642afcb168,Uncategorized,Untopiced,Add sgn to torch.rst so that it appears in the built docs (#51479)
109bc1047e,Uncategorized,Untopiced,[NNC] Generate C++ code for Allocate and Free (#51070)
718e4b110b,Uncategorized,Untopiced,add git submodule troubleshoot to CONTRIBUTING.md (#51458)
c08078031f,Uncategorized,Untopiced,[Gradient Compression] Allow BatchedPowerSGD to run vanilla allreduce for the first K iterations (#51270)
8583f7cbe2,Uncategorized,Untopiced,[doc] Fix linalg.cholesky doc consistency issues (#51459)
8fa328f88e,Uncategorized,Untopiced,[doc] Deprecate torch.cholesky in favor of torch.linalg.cholesky (#51460)
09bc58796e,Uncategorized,Untopiced,Hashing logic for c10::complex (#51441)
b198cf4f1c,Uncategorized,Untopiced,port `index_fill_` from TH to ATen. (#50578)
5b0a6482c1,Uncategorized,Untopiced,Out variant for embedding_bag_4bit_rowwise_offsets (#51324)
a23e82df10,Uncategorized,Untopiced,[nnc] Tweak log_nnc_sleef so vectorization kicks in (#51491)
c77fc2ee06,Uncategorized,Untopiced,[nnc] Vectorize bitwise ops (#51492)
630ee57bc2,Uncategorized,Untopiced,[PyTorch] Provide overload of torchCheckFail taking `const char*` (#51389)
ec3aae8cdb,Uncategorized,Untopiced,[JIT] Enable saving modules with hooks in FBCODE (#51241)
87ad77eb4e,Uncategorized,Untopiced,T66557700 Support default argument values of a method (#48863)
88af2149e1,Uncategorized,Untopiced,Add build option to split torch_cuda library into torch_cuda_cu and torch_cuda_cpp (#49050)
a3353d1ec0,Uncategorized,Untopiced,[FX] Support ellipsis as arg (#51502)
a1c5eba4bd,Uncategorized,Untopiced,[FX] Move some heavily used passes out of experimental (#51392)
1416fb9877,Uncategorized,Untopiced,[PyTorch] IWYU in torch/csrc/utils/future.h (#51293)
205c971431,Uncategorized,Untopiced,[PyTorch] Remove always-empty string args to inferFunctionSchemaFromFunctor (#51307)
4b65a27a35,Uncategorized,Untopiced,[testing] Add OpInfo for round and logit (#51272)
5e09ec6518,Uncategorized,Untopiced,"Fixed SVD ignoring ""some/full_matrices"" flag for empty inputs (#51109)"
d02ea9a141,Uncategorized,Untopiced,[ROCm] add hipMAGMA support (#51238)
c354888e5d,Uncategorized,Untopiced,compare_model_stub_fx API implementation (#48951)
9c474c97b7,Uncategorized,Untopiced,Disable BUILD_SPLIT_CUDA for now (#51533)
f0006315a9,Uncategorized,Untopiced,Add support for complex valued keys for dict in TS (#51472)
7328710cbc,Uncategorized,Untopiced,[PyTorch][codemod] Replace immediately-dereferenced cast calls w/castRaw (#50229)
b106250047,Uncategorized,Untopiced,Introduced AliasInfo for OpInfo (#50368)
f4fc3e3920,Uncategorized,Untopiced,[TensorExpr] Introduce ExternalCall nodes to TE IR. (#51475)
96a22123f4,Uncategorized,Untopiced,Automated submodule update: tensorpipe (#51469)
d555768e8f,Uncategorized,Untopiced,[FX] Added invert example (#51478)
79e7544cb4,Uncategorized,Untopiced,[Gradient Compression] Check start_PowerSGD_iter > 1 and add guidance on tuning PowerSGD configs. (#51427)
5c5db25cd5,skip,Untopiced,[AutoAccept][Codemod][FBSourceClangFormatLinter] Daily `arc lint --take CLANGFORMAT`
8bb0dff7e2,Uncategorized,Untopiced,Write FX Subgraph Rewriter tutorial (#51531)
41e4c55379,Uncategorized,Untopiced,Correct subgraph rewriter pattern containment rules (#51529)
4f37150f40,Uncategorized,Untopiced,Revert D26179083: [TensorExpr] Introduce ExternalCall nodes to TE IR.
a07a37e4fb,Uncategorized,Untopiced,reenable BUILD_SPLIT_CUDA for windows and fixes Linux 11_1 tests (#51538)
c0d58bce0d,Uncategorized,Untopiced,move Tar Dataset to Tar DataPipe (#51398)
1caed167fb,Uncategorized,Untopiced,[doc] Fix linalg.slogdet doc consistency issues (#51353)
c6f37e50f2,Uncategorized,Untopiced,[doc] Add deprecation message to torch.slogdet in favor of torch.linalg.slogdet (#51354)
43084d7aab,Uncategorized,Untopiced,add type annotations to conv_fused/blas_compare/blas_compare_setup (#51235)
c39fb9771d,Uncategorized,Untopiced,[complex] Enable complex autograd tests for `diag` (#51268)
8f0968f899,Uncategorized,Untopiced,Fix: Bad autograd side effects from printing (#51364)
a5b65ae40a,Uncategorized,Untopiced,Fix small typo (#51542)
6465793011,Uncategorized,Untopiced,Fix Dirichlet.arg_constraints event_dim (#51369)
0118dec2e3,Uncategorized,Untopiced,[Pytorch] Expanded Bundled Inputs To Any Public Function (#51153)
74ec9e7ccf,Uncategorized,Untopiced,compare_model_outputs_fx API implementation (#49266)
751c30038f,Uncategorized,Untopiced,[JIT] Properly convert Python strings implictly to device (#51340)
b6c6fb7252,Uncategorized,Untopiced,fix windows 11.1 test2 by disabling test (#51573)
55a4aa79aa,Uncategorized,Untopiced,[package] patch inspect.getfile to work with PackageImporter (#51568)
4fdebdc0c9,Uncategorized,Untopiced,Improve PyTorch profiler flop computation formulas (#51377)
ec378055c3,Uncategorized,Untopiced,add OneDNN linear backward (#49453)
351ee1ece7,Uncategorized,Untopiced,Remove duplicate check for THPLayout in toSugaredValue (#51543)
0ff855efea,Uncategorized,Untopiced,Make empty_cpu sanity test CPU only in DEBUG mode (#51358)
a38a648cb7,Uncategorized,Untopiced,Test if allocator is set only in DEBUG mode. (#51360)
cde7fa6e3c,Uncategorized,Untopiced,update kineto submodule (#51566)
365986cfe0,Uncategorized,Untopiced,Add tensorboard_trace_handler for profiler (#50875)
0402df5427,Uncategorized,Untopiced,[Vulkan] Improve error handling in a few places. (#51423)
2565a33c98,Uncategorized,Untopiced,[Vulkan] Remove redundant qualifiers on writeonly images. (#51425)
4746b3d1fb,Uncategorized,Untopiced,Added missing VSX dispatch for cholesky_inverse (#51562)
a990ff7001,Uncategorized,Untopiced,[SobolEngine] Fix edge case of dtype of first sample (#51578)
bbe18e3527,Uncategorized,Untopiced,[ZeroRedundancyOptimizer] Elastic and pytorch compatible checkpoints (#50956)
506fdf9abf,Uncategorized,Untopiced,[ROCm] disable tests for ROCm 4.0.1 (#51510)
cce84b5ca5,Uncategorized,Untopiced,[WIP] Update foreach APIs to use scalar lists (#48223)
37f1412965,Uncategorized,Untopiced,[Pytorch Mobile] Preserved all functions generated by bundled inputs (#51496)
209e27eaff,Uncategorized,Untopiced,[FX] Add note about more use cases of FX (#51576)
38eb836387,Uncategorized,Untopiced,[complex] Enable complex autograd and jit tests for `trace` (#51537)
5499e839f1,Uncategorized,Untopiced,[Fuser] Do not attempt to use OpenMP if build without OpenMP support (#51504)
e488e3c443,Uncategorized,Untopiced,Exposing linear layer to fuser (#50856)
c791a30484,Uncategorized,Untopiced,"Fix warnings in ""ForeachOpsKernels"" with c10::irange (#50783)"
b283ac6da4,Uncategorized,Untopiced,"""whitelist"" -> ""allowlist"" (#51375)"
5a402274d4,Uncategorized,Untopiced,[ROCm] add 4.0.1 to nightly builds (#51257)
26f9ac98e5,Uncategorized,Untopiced,Revert D26105797: [pytorch][PR] Exposing linear layer to fuser
e54cbb8250,Uncategorized,Untopiced,Create PyTorch DDP logging APIs for applications to use (#50637)
b18eeaa80a,Uncategorized,Untopiced,Implement `np.diff` for single order differences (#50569)
b48ee75507,Uncategorized,Untopiced,Fix quantization doc issue (#50187)
444203c52f,Uncategorized,Untopiced,Fix torch.cdist backward CUDA error due to illegal gridDim setting (#51569)
520f96b8c7,Uncategorized,Untopiced,[QNNPACK] Block Sparse kernel. First commit. (#50585)
eb571b33fe,Uncategorized,Untopiced,[QNNPACK Sparse] Create fc sparse operator (#50586)
7360ce36e4,Uncategorized,Untopiced,[QNNPACK:Sparsity] Add A matrix pretransformed based sparse kernels for FC (#50587)
f7313b3105,Uncategorized,Untopiced,Fix Python.h discovery logic on some MacOS platforms (#51586)
ab4623da16,Uncategorized,Untopiced,Document FX debugging (#51530)
62f6e55439,Uncategorized,Untopiced,Fix the missing parameter in get_sha function (#51290)
7b556db69d,Uncategorized,Untopiced,[PyTorch Mobile] Skip inferring function schema from the C++ function type (#50457)
75ee575671,Uncategorized,Untopiced,[Usability] Handle repeated jit.script calls on function gracefully (#51545)
c311b8961a,Uncategorized,Untopiced,Revert D26113953: [pytorch][PR] [ZeroRedundancyOptimizer] Elastic and pytorch compatible checkpoints
14ee63f7e6,Uncategorized,Untopiced,[WIP][DataLoader] Implement CallableIterableDataset (#50045)
bea0519b0b,Uncategorized,Untopiced,[WIP][DataLoader] Implement BucketBatchIterableDataset (#51126)
52de407b4b,Uncategorized,Untopiced,[DataLoader] Rename Functional DataSet to DataPipe (#51488)
5cf3278723,Uncategorized,Untopiced,Refactor ForeachUnaryOps.cu (#49248)
727f163bea,Uncategorized,Untopiced,caffe2 test.sh pip might not need sudo if pip is root (#50223)
550c965b2e,Uncategorized,Untopiced,Re-enable test_standalone_load for Windows 11.1 (#51596)
896f82aa92,Uncategorized,Untopiced,[optim] make functional api be private (#51316)
18a7ec7d7d,Uncategorized,Untopiced,Update the JIT complex type name to be consistent with Python (#51476)
c639513378,Uncategorized,Untopiced,[TensorExpr] Resubmit: Introduce ExternalCall nodes to TE IR. (#51594)
a651696ab4,Uncategorized,Untopiced,fix misspelling in swa_utils.pyi (#51608)
a3f2fe0d52,Uncategorized,Untopiced,Prevent CUDAFuture from using uninitialized device index (#51505)
3361d365bd,Uncategorized,Untopiced,[Gloo] Use TORCH_CHECK for ensuring tag is nonnegative (#51370)
cae4379826,Uncategorized,Untopiced,Enable FLOPS Computation for Experimental Kineto Profiler (#51503)
00675292ca,Uncategorized,Untopiced,replace silufp16 with cubic interpolation (#51645)
43df03de13,Uncategorized,Untopiced,[Gradient Compression] Replace torch.sqrt(torch.sum(col ** 2)) by torch.norm() (#51629)
648cdb7d0a,Uncategorized,Untopiced,Relax type signature for tools.codegen.api.translate (#51477)
81c7c3bae5,Uncategorized,Untopiced,Add api.structured; switch structured kernels to use const Tensor& everywhere (#51490)
333a0c8b6f,Uncategorized,Untopiced,Add support for generating faithful at::cpu signatures (#51499)
47557b95ef,Uncategorized,Untopiced,Removed typographical error from tech docs (#51286)
56ef24bc0f,Uncategorized,Untopiced,Use new TensorPipe functions to create transports (#51549)
8e53bf010d,Uncategorized,Untopiced,Use new TensorPipe functions to create channels (#51550)
f38e1d2d60,Uncategorized,Untopiced,[quant][graphmode][fx] Enable inception_v3 and googlenet static quant test (#51402)
c60dacd4cf,Uncategorized,Untopiced,Replace all AT_ASSERTM in ATen/native (#51147)
fe67438f32,Uncategorized,Untopiced,Replace AT_ASSERTM in ATen/core (#51579)
0d9ca21d74,Uncategorized,Untopiced,[Static Runtime] Native stack for contiguous inputs (#50863)
34d4d79966,Uncategorized,Untopiced,Autograd doc note fix (#51661)
1ee0c42d6d,Uncategorized,Untopiced,move ZipDataset to Zip DataPipe (#51599)
16cfe970e0,Uncategorized,Untopiced,Updates linalg documentation per feature review process (#51620)
d1bc1ab8ca,Uncategorized,Untopiced,Revert D25502940: Refactor ForeachUnaryOps.cu
443a431ac3,Uncategorized,Untopiced,Revert D25074763: [WIP] Update foreach APIs to use scalar lists
45e5562fcc,Uncategorized,Untopiced,"Beef up {jacobian, hessian} vectorize docs; eliminate a warning (#51638)"
50d903f19f,Uncategorized,Untopiced,[optim] make functional api be private (#51316) (#51665)
627ec8badf,Uncategorized,Untopiced,Type-annotate tools/generate_torch_version (#51637)
f2c4deabeb,Uncategorized,Untopiced,Extend subgraph_rewriter logic (#51532)
7918f37e8c,Uncategorized,Untopiced,[FX] Move examples to pytorch/examples (#51686)
0c60922fb0,Uncategorized,Untopiced,mem-efficient learnable fake quantization (#49315)
5d123ecf2f,Uncategorized,Untopiced,Fix caffee2 for LLVM trunk
d8742eeed0,Uncategorized,Untopiced,[quant] Support 2 dim input in quantized batchnorm 1d (#51597)
bd3ae117fc,Uncategorized,Untopiced,Fixes cat backward formula to return correct gradient values for R -> C case (#51681)
f1a63b7c10,Uncategorized,Untopiced,[FX] Added how to write transformations section (#51278)
c41678fd53,Uncategorized,Untopiced,Use deterministic impl of `index_put` and `index` backward CPU when `torch.are_deterministic_algorithms_enabled() == True` (#51388)
1ffd26f8d8,Uncategorized,Untopiced,[quant] Add reflection padding to conv (#49011)
23c50a4a50,Uncategorized,Untopiced,[PyTorch Mobile] Support torchbind custom classes in lite interpreter (#51432)
e60f18c2ad,Uncategorized,Untopiced,Generate header with version #defines for LibTorch (#50073)
6a945bfb5c,Uncategorized,Untopiced,Fix memory leak in qnnpack ops (#51612)
1518aee639,Uncategorized,Untopiced,unbreak bc test (#51702)
c8af338407,Uncategorized,Untopiced,Expand benchmark utils docs (#51664)
86861095fa,Uncategorized,Untopiced,Graceful invalidation of Python Node/Value/Block when C++ object is deleted (#50326)
8c3e0ddbc6,Uncategorized,Untopiced,[Usability] Tolerate `torch.jit.script` call to Enum classes (#51624)
7abba67d8c,Uncategorized,Untopiced,add dumping callstack to kineto (#51565)
d6452a1a0c,Uncategorized,Untopiced,[profiler] Default activities value (#51561)
a9584f29c1,Uncategorized,Untopiced,Fix attribution of some CUDA events to CPU events (#51632)
f1f9b049d8,Uncategorized,Untopiced,[profiler] Support top-level memory events (#51421)
ecf8166522,Uncategorized,Untopiced,"Support Union[NoneType, T] as input type (#51605)"
9920ae665b,Uncategorized,Untopiced,Make te a hidden package for now (#51690)
c22bc4821d,Uncategorized,Untopiced,[FX] Edits after comprehensive pass over docs (#51705)
6045663f39,Uncategorized,Untopiced,Use Literal to model targets. (#51500)
93c4f9f972,Uncategorized,Untopiced,Split out RegisterDispatchKey to its own file (#51508)
a626b78467,Uncategorized,Untopiced,Factor out structured generation into its own subclass. (#51583)
668e0f3598,Uncategorized,Untopiced,Split anonymous and namespaced definitions in RegisterDispatchKey (#51585)
4d85e30133,Uncategorized,Untopiced,Support at::cpu on non-structured kernels (#51590)
6c80fd005f,Uncategorized,Untopiced,Revert D26246231: [FX] Edits after comprehensive pass over docs
003a240e68,Uncategorized,Untopiced,[package] use WeakValueDictionary for global imported module registry (#51666)
7d00aec6bc,Uncategorized,Untopiced,Add compare_set operation and test to TCPStore (#51593)
1e2df9e46d,Uncategorized,Untopiced,[cuda] masked_scatter : static_cast init_value to circumvent cuda 11.2 issue (#51614)
de9364aef2,Uncategorized,Untopiced,fixes clang-tidy-11 install by using ubuntu18.04 instead of 20.04 (#51725)
a0137808a7,Uncategorized,Untopiced,Note on Modules for 1.8 docs (#51536)
14273126d2,Uncategorized,Untopiced,Numeric Suite: Swap with shadow modules only for quantized part of model (#51052)
0222966ecd,Uncategorized,Untopiced,Fix several minor things in .circleci/README.md (#51724)
2e8e560cdf,Uncategorized,Untopiced,Fix anomaly mode memory leak (#51610)
2d305b97e9,Uncategorized,Untopiced,[FX] Added partial concrete values for symbolic tracing (#51609)
7255b3f6b7,Uncategorized,Untopiced,[ONNX] Update constant-folding of Gather op (#50554) (#51514)
8dd9fefacb,Uncategorized,Untopiced,[ONNX] Fix bug in unfold symbolic (#50504) (#51515)
1829268e7f,Uncategorized,Untopiced,[ONNX] Improve error message for parse_arg in symbolic functions (#50512) (#51516)
3f185ac18e,Uncategorized,Untopiced,[ONNX] Export get/set attribute nodes (#50768) (#51517)
9191b639ba,Uncategorized,Untopiced,[ONNX] Enable remaining failed tests in opset13 (#50806) (#51518)
0e7e4d4217,Uncategorized,Untopiced,[ONNX] Add silu operator support for onnx (#51193) (#51519)
3cc46002a3,Uncategorized,Untopiced,[ONNX] Fix graph position to insert clone node for inplace op removal (#50123) (#51520)
586c2e8d62,Uncategorized,Untopiced,[ONNX] Fix graph sequence output from loop node (#51305) (#51521)
1c7d966432,Uncategorized,Untopiced,Update error message that displays when encountering an op unsupported for ONNX export. (#51387) (#51522)
8ae6b0c5f9,Uncategorized,Untopiced,[ONNX] Enable Constant Folding for ONNX Opset 13 (#51096) (#51523)
ba824eb2d6,Uncategorized,Untopiced,[ONNX] Update unsafe_chunk() method to support new version 13 of Split operator. (#51415) (#51524)
6d47e2cff8,Uncategorized,Untopiced,[ONNX] Fix opset 11 ConstantChunk with negative dim (#51396) (#51525)
25b18bb5d7,Uncategorized,Untopiced,[ONNX] Support list remove for onnx export (#51373) (#51526)
c7f1595b19,Uncategorized,Untopiced,fix bug (#51222) (#51527)
8c0da1f5e9,Uncategorized,Untopiced,[ONNX] Modifications in remove inplace ops passes to better handle binary inplace ops (#51318) (#51572)
949ab213dd,Uncategorized,Untopiced,"Revert ""Revert D26246231: [FX] Edits after comprehensive pass over docs"" (#51728)"
b150f150ba,Uncategorized,Untopiced,Add division overload with rounding_mode selection (#51706)
d4d5f8569f,Uncategorized,Untopiced,[FX] Fix mypy error in FX for rewriter (#51740)
ecfb73aaca,Uncategorized,Untopiced,Update docs for torch.profiler.tensorboard_trace_handler (#51636)
62aea33d7f,Uncategorized,Untopiced,Revert D26237328: Add compare_set operation and test to TCPStore
ab0cf3b6b5,Uncategorized,Untopiced,Add 'repeat' argument to profiler.schedule (#51630)
094d597679,Uncategorized,Untopiced,raise windows tol to 30% (#51733)
8c737f732b,Uncategorized,Untopiced,replacing ubuntu-latest with ubuntu-18.04 (#51744)
3fec1e5025,Uncategorized,Untopiced,fix hardsigmoid_backward for boundary case (#51454)
47a6703bdb,Uncategorized,Untopiced,"[QNNPACK, Sparsity] ARMV7, aarch32, kernels for dynamic linear (#50588)"
6dcbf396aa,Uncategorized,Untopiced,"[QNNPACK, Sparsity] Added prepacking base aarch32 kernels (#50589)"
4d703d040b,Uncategorized,Untopiced,Linear autodiff revert revert (#51613)
7c12afb5e2,Uncategorized,Untopiced,[doc] Fix inconsistencies with torch.linalg.cond doc (#51641)
4835f203ec,Uncategorized,Untopiced,[doc] Fix inconsistencies with torch.linalg.det docs (#51651)
87504c3265,Uncategorized,Untopiced,[doc] Fix inconsistencies with torch.linalg.eigh (#51658)
0308261ddc,Uncategorized,Untopiced,[doc] Fix inconsistencies with torch.linalg.eigvalsh (#51659)
e7d7256f2d,Uncategorized,Untopiced,doc] Fix inconsistencies with torch.linalg.matrix_rank doc (#51660)
ff4848aaa1,Uncategorized,Untopiced,[doc] Fix inconsistencies with linalg.pinv docs and deprecate pinverse (#51671)
e7ff0854c6,Uncategorized,Untopiced,[doc] Fix inconsistencies with torch.linalg.inv and deprecate torch.inverse (#51672)
de7eeb7752,Uncategorized,Untopiced,Removes nonzero method warning (#51618)
e62aabac43,Uncategorized,Untopiced,[Gradient Compression] Add a documentation page for DDP communication hooks (#51715)
716a8c2153,Uncategorized,Untopiced,make forward AD API private (#51693)
c3f2f3294e,Uncategorized,Untopiced,[RPC] Add option to make rref.get_type not block. (#50977)
21afbba79b,Uncategorized,Untopiced,[torch.futures] Clarify callback behavior when future is completed (#50978)
8e78dd6de8,Uncategorized,Untopiced,[torch.futures] Fix doc inconsistency about callback args (#50979)
c941730b96,Uncategorized,Untopiced,[JIT/Futures] support set_exception api (#50983)
1065c2d5b6,Uncategorized,Untopiced,"Fix clang-tidy warnings in python_sugared_value.{h,cpp} (#51703)"
d3023d86ba,Uncategorized,Untopiced,Revert D26249330: [Gradient Compression] Add a documentation page for DDP communication hooks
28c5d90b67,Uncategorized,Untopiced,[JIT] Allow implicit boolean conversion of containers (#51683)
e8ee35a666,Uncategorized,Untopiced,Add script to compare namespace content for release cleanup (#51685)
70830b5ac0,Uncategorized,Untopiced,"[QNNPACK, Sparsity] Sparse kernel with 4x8 blocking (#50590)"
a7ba051fa6,Uncategorized,Untopiced,"[QNNPACK, Sparsity] Add dyanmic linear sparse kernel for arm64 (#50591)"
105c3d2196,Uncategorized,Untopiced,Update CODEOWNERS (#51726)
5a962369e2,Uncategorized,Untopiced,[Gradient Compression] Check if the backend is NCCL when a DDP communication hook is registered (#51759)
aa1fd6b45a,Uncategorized,Untopiced,Add LazyBatchNormXd (#51548)
9c2dd5775a,Uncategorized,Untopiced,Fixed slight bug in FX docs (#51779)
59cb693c90,Uncategorized,Untopiced,[quant] add docs for embedding/embedding_bag (#51770)
33973d45a9,Uncategorized,Untopiced,Add `acc_get_device_type` weak symbol to `kineto_profler` (#51787)
a930162c69,Uncategorized,Untopiced,Revert D26276903: [pytorch][PR] Add LazyBatchNormXd
029f857b22,Uncategorized,Untopiced,"[Metal] Add hardswish and hardsigmoid to metal, fix broadcasting for binary elementwise ops"
3cfbf6d3ac,Uncategorized,Untopiced,[quick-checks] Allow `gradlew` to be executable (#51796)
2054cd56c5,Uncategorized,Untopiced,Optimize relu on cpu using clamp_min (#50924)
50c9c08203,Uncategorized,Untopiced,Enable GPU/RE tags for caffe2/caffe2/python/TARGETS
430329e875,Uncategorized,Untopiced,Revert D26009829: Optimize relu on cpu using clamp_min
5c3a054b12,Uncategorized,Untopiced,Add FLOPS support to the new profiler API. (#51734)
fb07aca7b0,Uncategorized,Untopiced,Adding support for CUDA 11.2 in our nightly build matrix (#51611)
ececbcfff2,Uncategorized,Untopiced,[Conda][Kineto] efine weak `acc_get_device_type` if kineto is used (#51818)
8c48af822e,Uncategorized,Untopiced,pytorch docs: add fake_quantize functions documentation (#51748)
9112f4eded,Uncategorized,Untopiced,[FX][docs] Indent forward (#51802)

7335f079ab,quantization,[pt][quant] qmul and qadd should preserve input memory format (#34834)
226f559394,skip,Updating submodules
53539567cb,onnx,[Onnxifi] Copy partitioning info when lowering to glow
e433271320,skip,Install CUDA manually on Windows CI to avoid flakiness (#34940)
74009dc558,profiler,[profiler] use swap in allocBlock to reduce time the lock is held. (#34499)
37b234a880,quantization,"quantized hardsigmoid, take 2 (#34959)"
c957580133,skip,Add promotion pipeline for S3 and conda artifacts (#34993)
b3fccda4a9,caffe2,[DPER3][Shape inference] Update Shape Information in dper3 backend (#34475)
7065c46ea2,rpc,Respect dist autograd context in torch.jit._fork. (#34360)
02e16b38f3,skip,Remove the use of two magic numbers in vec256 (#35003)
7b59f41009,jit,Add TensorExpr Fuser tests. (#35052)
851579d868,onnx,[Onnxifi] Blacklist ops in the partitions that are supposed to run on CPU (#34991)
733b6315fd,quantization,Add the fusion of quantized batchnorm and relu (#34795)
d2d26bf643,rpc,[rpc] fix test_debug_info for python 3.5 (#34828)
fd57e0901e,quantization,remove the slow path(NCHW) for avg_pool3d (#34994)
33dcaaa872,quantization,[quant][onnx] Add aten::max_pool2d to jit pass (#34912)
d3f5045bf5,InLastRelease,PyTorch should always depend on `future` (#35057)
90045ce5e0,jit,Add equality comparisons to c10::List (#34856)
5f32dfca16,jit,Add equality comparison to c10::Dict (#34892)
8210b2054e,skip,Move ivalue tests to aten (#34985)
a4afac6076,InLastRelease,enforce rref JIT pickling to be in the scope of rpc calls (#34689)
e7fc55ef7b,quantization,Revert D20464855: [pytorch][PR] Add the fusion of quantized batchnorm and relu
3c90a90730,jit,Revert D20540599: Add TensorExpr Fuser tests.
bb63710c9a,rpc,Reduce the number of iterations in test_autograd_context (#35037)
edb794fb19,amd,[ROCm] Enable BFloat16 type for TopK operator on ROCm. (#34849)
991b97277a,skip,"[RELAND] Eager autocasting, out-of-place ops only (with MSVC 2017 fix) (#35011)"
463f7920bd,InLastRelease,repr and _*state_dict for qRNN (#31540)
e65ac7af14,complex_frontend,Also vectorize complex types in fill. (#34973)
89110fbe6c,InLastRelease,Fix torch.mm export to ONNX (#34661)
eb78f7ea41,InLastRelease,torch.cat: disallow inputs on different devices (#35053)
0ccdec6b4c,skip,Revert e7fc55e (#35080)
fe276d541e,skip,"Revert D20541921: [pytorch][PR] [RELAND] Eager autocasting, out-of-place ops only (with MSVC 2017 fix)"
6000dca5df,caffe2,[nomnigraph] Copy device option when customize the op conversion (#34976)
ec9f680973,InLastRelease,Enforce rref python pickling to be in the scope of RPC call (#34755)
1c958f8ef9,bug_fixes_frontend,`Engine::~Engine()` should wait for non-reentrant threads to shutdown (#34529)
781f590f33,InLastRelease,[C++ API Parity] Add xor_convergence test for lbfgs (#35001)
e3272559e4,caffe2,[caffe2] SWA operator (#34394)
a5b5ea9852,profiler,use new cuda kernel launch code in nvprof parsing (#35016)
8bcedf7da2,new_features_frontend,Adds truncated normal initializer (#32397)
91d39de149,skip,Vectorize in-place comparison operators (#33252)
451e4d578d,complex_frontend,"Define +, -, *, / between complex numbers and integers (#34506)"
7d5a899883,complex_frontend,randn cuda kernel complex dtype (#35056)
bf41a7624e,opbench,fix missing comma in activation benchmarks (#35104)
8998a1b3d3,jit,Add tensorexpr benchmarks. (#35064)
ea41bf3100,mobile,[android] Maven publishing license fix (#32474)
faa853fefb,skip,Revert D20254663: [pytorch][PR] Vectorize in-place comparison operators
3c409fc66c,jit,Add guard elimination cases for operators encountered on an RL workload. (#34967)
12f0052eee,jit,Add TensorExpr Fuser tests (resubmit). (#35085)
62f11f0a35,jit,[JIT] add id function (#34975)
ca1e2cda05,th_aten_frontend,Port set_ to ATen. (#34403)
4bd5d1b3be,caffe2,[TVM] Use caffe2_predictor_model_shape_hints to pass shape_hints to TVM (#35091)
f9cddff25a,mobile,[android] Preload module actions do only once (#32313)
df8d6eeb19,InLastRelease,Update docs about DP and DDP for CUDA (#35063)
3e58cba3c5,quantization,Fixes the Conv2d batch_norm folding for various cases. (#34932)
65ff064763,performance_frontend,Parallelize cpu index_put accumulate float path with cpu_atomic_add_float (#29705)
e0496a70fc,InLastRelease,[JIT][torchbind] Namespaces for torchbind classes (#35054)
3a772b798a,rpc,Auto-format jit/rpc_test.py with flake8-black (#35075)
064c478453,dispatcher,[pytorch] register c10 ops for static dispatch to unblock c10 boxing
61b680c012,dispatcher,[pytorch] force c10 schema registration for custom build
4025729e88,rpc,[1.5 Release][RPC Reliability] RRef Idempotency and RPC Retry enablement (#33636)
e98b8eb35f,profiler,[profiler] remove unused _push_range and _pop_range (#35028)
bf31b1b6be,build_frontend,Upgrade protobuf as bazel build preamble (#34662)
4594433319,skip,Add retry to pip usage in mobile job (#35122)
d45e135d89,skip,Updating submodules
43fc97db88,skip,Updating submodules
c21fde6421,rpc,[jit] make jit/rpc share the same PythonFutureWrapper (#35039)
845b19c4ef,caffe2,Add weight_scale in Adagrad (#34944)
d7462dcea6,InLastRelease,"Fix AdaptiveAvgPool{2,3}d and AdaptiveMaxPool{2,3}d implementation (#35022)"
ef7fe371ce,InLastRelease,Fix Conv and ConvTranspose implementation (#35023)
c0958c883e,InLastRelease,Fix fractional_max_pool3d_with_indices implementation (#35024)
a2557970f3,InLastRelease,Fix F::interpolate and torch::nn::Upsample implementation (#35025)
d87750cd04,caffe2,[caffe2.proto] Add backend_option to PartitionInfo
3fa7813b9f,quantization,[quant] Add dequantize.tensors (#34348)
3342ab89ac,dispatcher,[pytorch] revert register c10 ops for static dispatch (#35148)
65cea95777,jit,"[TensorExpr] Rename schedule.{cpp,h} to loopnest.{cpp,h}. (#35119)"
d609f356de,jit,[TensorExpr] Use `const Expr*` instead of `ExprHandle&` in Range. (#35125)
95ad94c75b,jit,[TensorExpr] Nuke tensorexpr::schedule namespace. (#35126)
f515d87296,skip,Updating submodules
bbec4520c6,InLastRelease,Add inplace tests for several torch::nn modules / functionals (#35147)
a100cf5146,jit,Revert D20541090: [JIT][torchbind] Namespaces for torchbind classes
5306713a36,misc,Replace Generator* with Generator that holds std::shared_ptr<GeneratorImpl> (#34468)
cfc0ff1691,InLastRelease,"Renaming: MultiLabelMarginLossFuncOptions -> MultilabelMarginLossFuncOptions, MultiLabelSoftMarginLossFuncOptions -> MultilabelSoftMarginLossFuncOptions (#35163)"
a5b509985a,skip,Updating submodules
1ff5d9c557,skip,Updating submodules
e1c092fe3a,mobile,Changes to transition to generic API for ops with weight prepacking (#35010)
b248e23de0,docs_frontend,Docs fix: Added missing indent (#35017)
11a40410e7,misc,pybind11 type_caster for at::Generator and custom RNG python test (#34774)
1783ea43e7,skip,[pytorch] deprecate code analyzer -closure option (#35179)
3f2aa07b13,InLastRelease,[ONNX] update producer version (#35059)
082e48e346,skip,skip ctc_loss test on Windows (#35069)
a6672f3b30,skip,Updating submodules
d743c22990,skip,Updating submodules
36e36eff2f,skip,Ignores deliberate undefined float->int conversion (#35086)
358ba59f01,bug_fixes_frontend,Add THP_API to THPGenerator_Wrap (#35194)
4caa0db6e8,quantization,[quant][graphmode][fix] preserve the type of original value when inserting dequant node (#34349)
28bf0038e5,quantization,[quant][graphmode][fix] Insert dequantize before use node (#34411)
350c522423,quantization,[quant][graphmode][refactor] insertObservers for Block (#34414)
c85697d74d,quantization,[quant][graphmode][fix] use observed_values_ to check values are observed (#34571)
2c69fa93b9,build_frontend,Fix _copysign is not a member of std (Windows) (#35199)
0e0386b434,jit,"Revert ""[JIT] add id function (#34975)"" (#35209)"
3e4076aa9c,quantization,[quant][graphmode] quantization work for prim::If (#34518)
506996c77e,quantization,[pt][quant] Optimized qadd_scalar (#34925)
21ecb8d870,build_frontend,Fix reference to NO_CUDA and NO_DISTRIBUTED (#34831)
02ab6ced8e,complex_frontend,test_complex inherits from common_utils.TestCase; closes #34648 (#34697)
77ccb5c14d,jit,Move functional graph creation to testing utils (#34916)
4fae5a6721,jit,Move module graph creation to testing utils (#34917)
9441c7a944,skip,[JIT] add IR complexity tests (#34918)
521c424b39,performance_frontend,Make discontiguous tensors also benefit from unrolling (#34708)
37e355622a,bug_fixes_frontend,"Pass the missed ""non_blocking"" argument for to() (#35144)"
3cd3f0b3f1,InLastRelease,Fix Tensor __radd__ type hint issue (#35231)
a00e12e755,quantization,[quant][graphmode] weight/bias of linear/conv can be reused for multiple ops (#35221)
93983c7d00,build_frontend,Add `USE_TSAN` option (#35197)
40da01db6a,InLastRelease,Add docs about memory format (#34818)
bfdcc39301,skip,"in test_c10d.py, remove skip_if_rocm from tests that pass locally (#35124)"
6fa0b3df2e,misc,[testing] Pass verbosity settings to `XMLTestRunner` (#35224)
131af4412e,InLastRelease,Add TORCH_CUDA_API to FilterDescriptor (#35131)
7ab25b2e6b,jit,[JIT] add id function (#34975)
c321f02756,jit,Follow up on freezing (#34786)
8bb7f1ad11,rpc,[rpc] various fixes for ProcessGroupAgent (#34943)
b2dcedf71e,skip,.circleci: Ensure describe happens in pytorch repo (#35065)
eff68bc872,quantization,[quant][graphmode] quantization support for aten::add (#34572)
b9fbec96e6,mobile,Support LIST_UNPACK and TUPLE_SLICE in lite interpreter. (#35241)
1b119861a8,jit,"[TensorExpr] Cleanup includes in loopnest.h, use forward declarations when possible. (#35129)"
ccf8dd6209,distributed,Print exitcode on failures in test_distributed.py (#35233)
97ecfb4929,skip,Updating submodules
bd0ef784e0,docs_frontend,FAQ: Add note about recovering from OOM (#35214)
fddcd72a31,quantization,Add the more fusion (conv3d and batchnorm)support in pytorch quantization flow (#33540)
340ccf56fb,rpc,"[PyTorch-RPC] In process_group_agent, avoid read-after-free (#35252)"
ac4a0224f3,quantization,[quant][graphmode] Replicate quantize node for prim::If (#34804)
8346959f38,caffe2,[caffe2] merge internal (RowWise)SparseAdagrad into open source version (#35090)
9e7821ee82,improvements_frontend,[autograd] allow PyNode to persist error message (#34845)
c46c28a7cb,skip,Fix `JitTest.ADFormulas` intermittent failures (#35196)
9c8f09d1a4,quantization,[quant][graphmode] quantization support for prim::ListUnpack (#34807)
4a96911629,quantization,[quant][graphmode] quantization support for aten::chunk (#34806)
537fdd77d5,quantization,"[quant][graphmode] quantization support for view, transpose, contiguos (#34854)"
cd75d4e274,quantization,[quant][graphmode] Add prim::ListConstruct to general op handling (#34345)
7c1ea736ba,new_features_frontend,Extends true_divide to be a method (#34794)
8b8af0d458,skip,Revert D20539336: [JIT] add IR complexity tests
17068ba467,InLastRelease,[JIT] BC shim for TorchBind classes (#35240)
618c6214aa,jit,[reapply][JIT] Namespaces for TorchBind (#35254)
d7a7bcb042,skip,Load torch_global_deps for Windows (#35177)
6f6436ff5d,bug_fixes_frontend,Fix input overwriting in irfft (#35219)
73a36a47a5,complex_frontend,Gradcheck for complex (#35238)
50eb1a389f,performance_frontend,Add cpu_serial_kernel_vec (#34553)
0f0271e255,new_features_frontend,"[RELAND2] Eager autocasting, out-of-place ops only (with MSVC 2017 fix) (#35102)"
925cdd57dc,skip,Replace all uses of AT_INDEX_ERROR with TORCH_CHECK_INDEX (#35050)
36e3c005f0,InLastRelease,Add python excepiton handling catch block to resolve deadlock (#35283)
a045343402,skip,[Autograd Testing] Add a test where child reentrant task fails. (#35223)
55019d357e,quantization,[quant][graphmode] Add observers for dynamic quant (#35121)
1d52530855,performance_frontend,simpler 'cpu_scatter_gather_base_kernel' (#34690)
0f0a5b11b8,build_frontend,Disable C4251 when compiling cpp_extensions on Windows (#35272)
3f896ef743,skip,Trying pinning pyyaml and setuptools on macos to older version (#35296)
fb70893e78,skip,remove cadd_avx2 dead code (#34883)
abcd4eb993,performance_frontend,Optimize min and max(reduce_dim) performance on CPU (#34875)
edad9c102d,mobile,Update XNNPACK to Git revision 1b354636b5942826547055252f3b359b54acff95. (#35081)
39a101d06e,skip,Make GPU loops support mutable lambda (#35015)
84dc8c410a,skip,Add's workaround for ScalarType::Byte for cuda (#35027)
44622bbda9,jit,[jit] Add lazy script decorator (#34935)
b7e4dd15cc,jit,[jit] Remove stray `@script` (#34938)
6b5740c5f6,skip,[quant][graphmode] Add quantization support for aten::cat (#34346)
2dc2933358,InLastRelease,Move NewModuleTest and NewCriterionTest from test_nn.py to common_nn.py (#35189)
fce67800f4,skip,[TensorExpr] Extend arithmetic simplifier to work with multi variable expressions (#35127)
2623448746,cpp,Match case of package name to suppress warning (#35201)
4a84ac5f5d,jit,[jit] make Future type annotation available in Python (#27637)
b6306e1517,skip,Revert D20624698: [pytorch][PR] Make GPU loops support mutable lambda
f3e9fa6122,new_features_frontend,add hardswish FP operator (#34747)
f1efe51028,quantization,add quantized version of hardswish operator (#34820)
ee7cd84fac,skip,Revert D20589145: [quant][graphmode] Add quantization support for aten::cat
a7f8655314,skip,Revert D20624571: [pytorch][PR] [TensorExpr] Extend arithmetic simplifier to work with multi variable expressions
574be9f816,skip,Skip OpenMP thread when OMP_NUM_THREADS is set to 1 (#35324)
b8f509fd9b,skip,Revert D20630949: Skip OpenMP thread when OMP_NUM_THREADS is set to 1
74c02619de,quantization,quantized Conv1d (#35093)
6c39e362fd,quantization,Minor fix to quantized conv docstring (#35134)
93065ff767,caffe2,[1] add missing header for C10_EXPORT_CAFFE2_OP_TO_C10 (#35245)
01a7d6adcb,caffe2,[caffe2] Fix typo in dataset_ops (#35356)
5b2f8cef08,jit,[JIT] Functional Graph Pass (#33020)
aab4beb87f,jit,[JIT] Pass To Safely Remove Aten Inplace Ops (#33186)
f090031e69,jit,[JIT] remove list appends (#33199)
d6377b7cef,InLastRelease,Fix thread_local initializtion in C10 WarningHandler. (#34822)
d6149a7250,caffe2,move some ops to contrib (#35282)
c2804e8229,InLastRelease,Fix Caffe2 mobile compilation (#35288)
3789db40f2,caffe2,[aibench] added support for measuring memory on AI Bench for Caffe2 Models (#35036)
361eed6a6e,mobile,Use JIT op registration directly for lite interpreter. (#34070)
c73e97033a,complex_frontend,Added type promotion logic for complex numbers (#34093)
53fceff1e1,caffe2,Change weight scale test to cpu only (#35346)
3645d9b832,th_aten_frontend,Port `diag` cpu from TH to ATen (#35100)
f9889aa390,skip,[reland] Skip OpenMP thread when OMP_NUM_THREADS is set to 1 (#35353)
032c27cff7,quantization,[quant][graph] Add _choose_qparams function for graph mode (#35235)
7e327e1210,onnx,Enable Constant Folding for ONNX Opset 12 (#34823)
7cb301e48d,rpc,[rpc][easy] remove code duplication on ProcessGroupAgent::enqueueSend (#35311)
5959bd6c29,InLastRelease,Making sure all tensors in `torch.cat` sequence have the same dtype. (#35150)
450738662b,jit,[TensorExpr] Replace `ExprHandle` with `const Expr*` in `Substitute`. (#35173)
ceb4ed3733,jit,[TensorExpr] Methods name cleanup in LoopNest class. (#35174)
db0f715af6,jit,[TensorExpr] Factor out LoopNest::insertAllocFree. (#35175)
51818cc4ea,jit,[TensorExpr] Cleanup implementation of alloc/free insertion. (#35176)
15e5453977,quantization,[reland][quant][graphmode] Add quantization support for aten::cat (#34346) (#35337)
d863fe356d,caffe2,Ignore rest of outputs of LayerNorm when lowering to Glow (#35338)
34b005954e,caffe2,Support merge_fp32_inputs_into_fp16 for predefined partitions (#35361)
de3044b210,InLastRelease,Load all DLLs in the lib directory for Windows (#35362)
40b244ceb4,InLastRelease,Fix handling of non-finite values in topk (#35253)
aadd0fda8b,distributed,Document reduce_scatter collective operation (#35274)
c9117f27c4,rpc,Fix final callbacks for reentrant backwards (#35066)
512bcf68be,skip,[Formatting] `if (` -> `if(` in CMakeLists.txt (#35343)
17abb7c31a,InLastRelease,Add docs to resize_ and resize_as_ (#35392)
a4ea16dbc6,jit,Put prim ops used in full jit only in a separate file (#35232)
00aa23446b,jit,[JIT] [Reland] add complexity tests (#35330)
d7c255d2fc,skip,[jit] add module interface tests to test_jit (#35417)
6bcf0b407b,jit,[TensorExpr] Disable fuser-te cuda tests when run on ROCm. (#35388)
7580470cc5,InLastRelease,Update view op list. (#35399)
7e24ab8c4a,quantization,[quant][graph] Add a new observer type for dynamic quantization (#35265)
64a6faa2c8,quantization,[quant][graph] Update dynamic quant tests to use new qconfig (#35325)
ccc0e35275,quantization,[quant][graphmode] quantization support for prim::CallFunction (#34855)
f3a5081bd4,skip,Enable NNC tests vol. i. add test_tensorexpr.py tests [WIP] (#34897)
e08614ffd5,skip,[Autograd Testing] Test failure in parent graph before child reentrant task (#35268)
efbd6b8533,InLastRelease,[C++ API Parity] [Optimizers] Merged Optimizer and LossClosureOptimizer (#34957)
0a3864f81e,rpc,Throw an actionable error message on user call rref<ScriptModule>.to_here() in torchscript (#35369)
d7de6ad23f,skip,Revert D20640487: [quant][graph] Update dynamic quant tests to use new qconfig
b4b8b3c0ca,skip,Revert D20630988: [quant][graph] Add a new observer type for dynamic quantization
315929f43e,mobile,Refactor code to move const prop to convolution 2d replacer. (#35226)
dc2c4d02f9,mobile,Add a wrapper to wrap all optimization for mobile. (#35227)
2dd867f30f,skip,Move normal() to DistributionTemplates (#35167)
aa01a95c6d,skip,Revert D20630760: [pytorch][PR] Enable NNC tests vol. i. add test_tensorexpr.py tests [WIP]
7fbb562369,skip,"Back out ""[reland] Skip OpenMP thread when OMP_NUM_THREADS is set to 1"""
0ccceb2290,rpc,[dist autograd] profile the amount of time spent executing (#35261)
fa4603ef36,improvements_frontend,Also sync submodule in the Dockerfile (#35423)
a7c232f74c,th_aten_frontend,Port `mm` cuda from TH to ATen (#34891)
be0cdf5d15,jit,[jit] Implement `torch::jit::deregisterOperator` (#35107)
d807292c4a,amd,[ROCm] Hotfix disable tests (#35396)
de3b2f98db,caffe2,[Shape Inference] Add ssaRewrite pybind func (#35410)
843fd740fb,skip,Revert D20645945: [pytorch][PR] [C++ API Parity] [Optimizers] Merged Optimizer and LossClosureOptimizer
e0c227d376,skip,Revert D20655246: [jit] add module interface tests to test_jit
4a4e385e13,build_frontend,"Revert ""Load torch_global_deps for Windows (#35177)"" (#35355)"
299bd6d701,build_frontend,Update randomtemp on Windows (#35375)
79054495d3,bug_fixes_frontend,(Fixes #33934) Fix AttributeError for nn.Module's properties (#34324)
f7f7c4edd9,amd,[ROCm] Update CI dockers to ROCm release 3.1.1 (#33930)
17a01c7c7b,improvements_frontend,feature: deterministic random_split (#34043)
ada40777c4,complex_frontend,Rand function for complex dtype (#34924)
3622e1c90f,amd,Revert D20589048: [pytorch][PR] [ROCm] Update CI dockers to ROCm release 3.1.1
cd9a357f32,rpc,Fix non-deterministic RNG behavior in dist_optimizer tests (#35425)
3b2b6ae1a8,skip,[JIT] Optimize before inlining (#35424)
1422d2cd8b,skip,[tools] Replace clang_format.py with clang_format_new.py (#35114)
6384c2d81b,jit,[JIT] clang-format JIT code (#35115)
61623430d3,skip,[workflows] Add clang-format workflow (#35239)
bf24753570,skip,Add __torch_function__ benchmarks. (#34645)
8d720b7034,complex_frontend,fix complex conversions on cuda (#35344)
1ff85fc08b,skip,Prefer python3 in clang_format (#35490)
e00575044e,skip,Revert D20657271: [pytorch][PR] [JIT] Optimize before inlining
4d39aeec27,skip,Revert D20653072: [pytorch][PR] Add __torch_function__ benchmarks.
a3e10d2a17,jit,Expose enablement of TensorExpr fuser as env variable (#35341)
ea0cab7f46,dispatcher,Guard listener removal add by `at::Dispatcher::addListener()` with mutex (#35486)
c8bd5ac7e9,skip,[workflows] Don't pipe clang_format.py output to a file (#35496)
c1f5a54397,performance_frontend,Optimize index_select for 1D inputs (#35243)
b704f30189,caffe2,[3] register caffe2 mask rcnn ops in lite interpreter (#35246)
6b1ffcbf59,caffe2,[model loading] Skip ssaRewrite for predict_net if it has been ssaRewritten (#35428)
b0459fec72,skip,[clang-format] Replace asyncio.run with approximation supported in python 3.6 (#35501)
9b8c9d6c72,skip,[autograd] add tests for simple reentrant and stackoverflow escape (#35259)
618104185b,bc_breaking_frontend,[autograd] enable graph level thread parallelism on CPU (#33157)
91e4685514,build_frontend,[modules][caffe2/aten] Fix `#include` inside of namespace error (#35302)
086dba3804,caffe2,[caffe2] move fused SparseAdagrad to open source (#35164)
daba68c601,quantization,[quant][graph] Add a new observer type for dynamic quantization (#35455)
8074779328,quantization,[quant][graph] Update dynamic quant tests to use new qconfig (#35451)
2f6f1781af,improvements_frontend,Add warning to a known autograd issue on XLA backend. (#35449)
2e739f822b,skip,Fix PyTorch separate compilation (#34863)
d4f3bc7f8e,caffe2,"[dt] [caffe2] add/fix shape inference for StumpFunc, SliceGradient and ResizeLike (#35430)"
9b4bbaab53,rpc,Add RRef.local_value() for TorchScript (#35433)
9970be2fd2,skip,Update git-pre-commit (#35511)
5d9694250c,skip,Updating submodules
8f18cdf2b8,skip,[Autograd Testing] Few refactors to test_autograd.py (#35443)
e68afe3ab9,jit,[JIT] remove prim::shape op (#34286)
5371fdb1a0,cpp,[C++ API Parity] [Optimizers] Merged Optimizer and LossClosureOptimizer (#34957)
f5383a213f,build_frontend,Fix openmp detection with clang-cl (#35365)
00a261fddd,mobile,[pytorch] add fallthrough variable kernel for C10_MOBILE (#35491)
77bbbf042d,jit,[JIT]Support converting str to float. (#35352)
98362d11ff,rpc,[rpc] create error string in listenLoop outside of lock (#35393)
8240db11e1,build_frontend,[pytorch] Remove python2 support from tests and torch.jit (#35042)
bd604cb5b7,performance_frontend,Upgrade MKL-DNN to DNNL v1.2 (#32422)
8c90ae11b3,jit,[JIT] fix glow subgraph inputs ordering (#35508)
da4e68faed,mobile,Make operator names consistent between export_opnames and the lite interpreter (#34674)
d2d40c45b6,skip,Report results from cpp unittests on Windows and Linux (#35500)
ac639d927a,rpc,"Reland ""[RPC] Use qualified name str directly in RPC torch script code path"" (#35489)"
025a0abe5a,skip,ONNX Update training ops and training amenable export API (#32950)
e5cd17cc9e,quantization,[4] register quantized ops for lite interpreter (#35247)
45e1be9762,skip,Revert D19710370: [pytorch][PR] ONNX Update training ops and training amenable export API
181da12126,skip,Revert D20687652: [pytorch][PR] Report results from cpp unittests on Windows and Linux
2d023fe6a7,caffe2,[7] add missing roi_align_rotated op to lite interpreter (#35244)
58f5a89c9a,caffe2,Refactor RoIAlignOp on CPU (#34698)
25fe7f33ce,skip,Add cmakelint to CI (#35525)
16394a9d3f,caffe2,[caffe2] early return for empty indices in SLS (#35498)
77ad3c5aeb,skip,Revert D20683972: [pytorch][PR] Fix PyTorch separate compilation
3c02de0011,complex_frontend,copy_ fixed on cuda so removing the workaround in test_many_promotions (#35528)
5a02930d3a,performance_frontend,Vectorize (CPU) generic types for binary bitwise operators (#34338)
b33e38ec47,performance_frontend,Allow a higher-precision step type for Vec256::arange (#34555)
0c16cedafe,skip,Fix some incorrect annotations found by clang-cl (#35364)
3cc43bcbb5,skip,Skip slow quanitized tests under ASAN (#35533)
2c300df2ac,quantization,[fix] at::print for quantized Tensor (#35545)
3af46c90bd,caffe2,[caffe2] Header path in byte_order.h (#35519)
930d218fbf,memory_format_frontend,Increase Channels Last test coverage (#35504)
9e22d15f14,jit,Enable tensorexpr cpp tests in CI. try #2 (#35454)
ff71a4192d,skip,Bump base version to 1.6.0a0 (#35495)
835ee34e38,amd,[ROCm] Update to ROCm 3.1.1 (#35552)
05e973d673,rpc,Add WorkerInfo through TorchBind to make it an available type in TorchScript (#35447)
ef511d884b,memory_format_frontend,Calls to _empty_affine_quantized pass MemoryFormat by TensorOptions (#34248)
4529d03971,skip,Move test_libtorch from win-test2 to win-test1 group (#35540)
02d6e6e55f,docs_frontend,histc: Add a note on elements outside of given bounds (#34889)
e1773f2ac0,InLastRelease,".circleci: Change default CUDA for pip, cu101 -> cu102 (#35309)"
04a3345335,quantization,[quant] Make conv2d_prepack and linear_prepack pure (#35073)
45c9ed825a,skip,Formatting cmake (to lowercase without space for if/elseif/else/endif) (#35521)
f101949390,skip,Remove python2 support from setup.py (#35539)
96eec95ece,complex_frontend,torch.from_numpy for complex dtypes (#35531)
b9adbb5002,skip,Fix/relax CMake linter rules (#35574)
cfcb63de34,jit,custom class method holder should hold a unique_ptr (#35218)
f27403d761,jit,[jit] Fix named tuple resolution (#35409)
76a8d30693,quantization,[quant][graphmode] Fold quantized prepacking ops (#35077)
6d13ef719e,improvements_frontend,Update warning message for autograd issue + XLA backend (#35543)
238903b7be,jit,[jit] Delete polyfill typing (#27510)
a9b540d109,skip,Revert D20670031: [pytorch][PR] Fix some incorrect annotations found by clang-cl
43928effee,jit,[jit] Remove _assert_int_or_pair op (#34509)
75e4c53b35,rpc,[rpc] Add a debug only check to debug python cleanup races (#35395)
ad1091f753,onnx,Fixes default dtype value for onnx hardtanh export (opset11) (#35467)
2ef5b947a8,skip,Disable unit test failing on Windows (#35549)
26b2725167,quantization,[quant][graphmode][refactor] swapDeQuant takes block as arugment (#35135)
c672a7340b,quantization,[quant][graphmode][refactor] getGeneralOpTensorInputIndexes -> getGeneralOpTensorInputs (#35141)
1cc4e5c338,quantization,[quant][graphmode] SwapDeQuant support prim::If (#35142)
21c94606b8,improvements_frontend,"Cleans up type conversions, adds CPU test comparing with NumPy (#35374)"
df27b32014,quantization,[quant][graphmode] Make interpolate/upsample work again (#35130)
f1d69cb2f8,quantization,[quant][graphmode] Quantization support for permute and repeat_interleave (#35332)
683246e5ea,improvements_frontend,"Improves precision of linspace, logspace (#35461)"
5b3492df18,jit,[TensorExpr] Extend arithmetic simplifier to work with multi variable expressions (Attempt 2) (#35415)
5557ceb84e,skip,Remove `pytorch_linux_xenial_py3_5` build and test jobs (#35587)
e90c32f11f,quantization,[quant][graphmode][refactor] Support filter function in quant fusion patterns (#35333)
28ab8c6ff8,skip,New operator registration API (#35061)
cd00bbc23f,skip,clang-format. (#35605)
76d5102587,jit,add a cuda/fuser job for legacy graph executor (#35419)
444332710c,quantization,[quant][graphmode] Quantization support for `quantized::add_scalar` (#35334)
486277a309,misc,Replace four make_offset_calculator functions with one (#35551)
227beb9095,skip,Revert D20680520: New operator registration API
efec027653,quantization,[quant][graphmode] `prepare_script` takes original qconfig_dict (#35335)
67c3822944,quantization,[quant][graphmode] Make `aten::relu` a general op (#35420)
860790de88,complex_frontend,"Makes torch.real and torch.imag NumPy compatible, but disables them for complex tensors (#35560)"
64058796e0,skip,clang-format (#35635)
6fc2403951,quantization,[quant][graphmode] qconfig_dict support None (#35336)
dbd2b8bb41,caffe2,[SigridHashOp] Fix converter (#34836)
915a45298c,skip,[aten] remove warning on change of sign (#34016)
77b4e2d2fc,quantization,[quant][graphmode][fix] Add filter for `quantized::add` (#35345)
e397f87c4b,skip,[aten] remove variable set but never used warning (#34015)
86be6443d8,quantization,[quant][graphmode] Quantization support for `aten::conv3d` (#35347)
9e3605de98,dispatcher,[RELAND] New operator registration API (#35061) (#35629)
2c19b53d4f,mobile,[iOS] Enable selective build for testing FBNet in PyTorchPlayground (#35647)
1f759936f0,caffe2,Propagate model id used by Predictor to Caffe2 logging
728c7dcea3,onnx,ONNX Update training ops and training amenable export API (#35567)
340048b67c,quantization,[quant][graphmode] Remove unused patterns (#35385)
e3daf70184,build_frontend,Fix AVX detection with clang-cl (#35653)
0eb26fb01e,amd,[ROCm] Properly blacklist (#35230)
bf2b411730,skip,Save results of cpp unittest to `test/test-reports` folder (#35686)
3bdc4a37ed,skip,CMake script cleanup - mixed case for function names (#35589)
e7a37823b0,skip,[WIP] [reland][pytorch][PR] Fix some incorrect annotation… (#35588)
3f3b96b1f8,skip,Revert D20735881: [pytorch][PR] [WIP] [reland][pytorch][PR] Fix some incorrect annotation…
bb32e123e6,skip,Report results of python unit tests during window test runs (#35687)
f3151052ce,bug_fixes_frontend,[autograd] fix engine flakiness (#35599)
e7371957cf,skip,Report results from CPP unittests on Windows and Linux (Reland) (#35590)
b1f08e7426,performance_frontend,Call uncheckedSetDevice in ~InlineDeviceGuard only when device index are different (#35438)
39d0500434,build_frontend,Fix PyTorch separate compilation (Reland) (#35581)
35dbc6ebda,skip,[BC] Fix the BC CI (#35692)
af4d86788c,caffe2,Split SparseLengthsSumSparse into SparseLengthsSumSparseLookup + SparseLengthsSum (#35507)
e90e89d189,caffe2,Transform pass to split SparseLengthsSumSparse (#35522)
dd98abb453,caffe2,Enable splitSparseLengthsSumSparse in onnxifi (#35555)
788ef939d8,InLastRelease,float2::x and float2::y may not be the same as float on ROCm (#35593)
639c68b2fe,skip,bfloat16: enable basic math function (#35172)
a0dc36e501,build_frontend,[Windows] Fix torch_cuda's forced link (#35659)
35715a56a9,performance_frontend,[reland] Skip OpenMP Thread when OMP_NUM_THREADS is 1 (#35541)
4e19e02976,quantization,[quant][graphmode] Quantization support for `quantized::add_scalar_relu` and `quantized::add_scalar_relu_out` (#35509)
5e27de021e,rpc,[rpc] fix backward compatibility test (#35703)
e021c13d2d,skip,[doc] Add overflow notice for cuFFT on half precision (#35594)
8981271d9f,skip,Skip test_mm on XLA (#35709)
46330b368a,mobile,[5] register aten ops in lite interpreter for detectron2go model (#35248)
95c1b16fc5,performance_frontend,don't replace TensorImpl for inplace min/max dim (#35591)
56fabface2,skip,fp16 include not needed (#35708)
a15a4a5caf,skip,Revert D20722426: [pytorch][PR] [doc] Add overflow notice for cuFFT on half precision
fdadaf62b0,skip,Disable batch_norm_relu batch_norm3d quanitized ops tests (#35727)
2f3b952d16,InLastRelease,Use `std::abs` instead of `abs` in lbfgs.cpp (#35698)
c2ca4371ae,skip,[PyTorch BC] Clean up whitelist (#35730)
8add1843a9,quantization,[quant][graphmode][fix] docs for InsertObservers (#35557)
9018538ab3,quantization,[quant][graphmode][refactor] getGeneralTensorInputs(Node*) -> getPassThroughInputs(Value*) (#35558)
cd760fbd7f,skip,Updating submodules
726baf69d7,build_frontend,Do not link BLAS into torch_cuda/torch_hip (#35724)
4f4ed5c108,dispatcher,Disable c10::import(ns) (#35398)
35087b8d77,caffe2,[Shape Inference] Try to infer input of elementwise ops (#35701)
b0f8429826,skip,Update clang_format.yml
1f7ee7b6b7,quantization,[quant][graph] Add pass to insert quant dequant for dynamic quantization (#35448)
a090de380c,quantization,[quant][graph] Add quant fusion for dynamic quantization (#35586)
8fef8d19fa,skip,clang-format (#35752)
800d5617c0,jit,Recording of TorchScript functions (#34710)
59268d4cbf,jit,[JIT] Improve the error message when registering a custom class twice (#35568)
539d3ff344,cpp,Revert D20749588: [pytorch][PR] Use `std::abs` instead of `abs` in lbfgs.cpp
d2343bea32,complex_frontend,"Disables complex floor, ceil, trunc (to be compatible with NumPy) (#35592)"
81c2412721,caffe2,[caffe2] Switch to using `public_include_directories
ada647214f,caffe2,[caffe2] explicitly pass use_offsets=false when calling fbgemm embedding kernels (#35711)
8ff05031b0,improvements_frontend,Update collect_env.py to detect relevant conda-installed numpy and cudatoolkit (#35646)
3d6b5bac0a,skip,Move libtorch to py3 and cleanup other CircleCI config (#35700)
b4c4342747,docs_frontend,hswish and hardsigmoid: improve docs (#35431)
f182b43760,rpc,[rref] Handle exceptions returned via remote() calls (#35331)
063275fd33,jit,Fix a bug in subgraph rewriters. (#35704)
8e49afa908,skip,Updating submodules
07dbf0db46,performance_frontend,"bfloat16: vectorized clamp, clamp_min and clmap_max (#35082)"
7d5350c2a3,skip,[easy] ThroughputBenchmark: print out aten's parallel settings before execution (#35632)
8de01aac0b,caffe2,[Onnxifi] Add initializers to the C2 net passed into Glow (#35764)
9650f465ce,quantization,[quant][graphmode] Quantization support for at::sort (#35571)
e5746eec1e,amd,[ROCm] Remove installation of ca-certificates and apt-transport-https in test.sh (#35676)
8d64a3848c,rpc,"[jit] In RPC Server, handle TorchScript continuations asynchronously (#34109)"
3ba885896d,jit,"[jit] Minor: in unpickler, string tweak in readBytes() (#35550)"
2c6d1e57cd,complex_frontend,is_complex doc fix (#35680)
1ec0676a33,jit,[JIT] register list prim ops cleanup (#35768)
fef6c617d4,quantization,[quant] Move quantization tests into test/quantization (#35688)
2f84a07b58,skip,indexing: throw exception for masks with dtype=uint8 (#34418)
d1a4a64092,complex_frontend,Disables imag for real-valued tensors (#35728)
cae6bdf199,rpc,"[JIT] Mark aten::wait as having side effect, since it can represent RPC message received (#35695)"
6a5d008abf,jit,[jit] factor mangler out (#35716)
995f53b042,jit,[jit] make `python_str` take a custom renamer (#35717)
51fb5ef80e,jit,[jit] add cast<> specialization for NamedType (#35718)
06dcb70905,jit,[jit] Fix Type equality in some cases (#35719)
319aee1afb,skip,Revert D20771828: [quant] Move quantization tests into test/quantization
dc1ecdf8d9,skip,Moves torch cpu math tests to device-generic framework (#35658)
ee6f7c3e62,jit,Remove extra semicolon (#35751)
866d9d4e6a,jit,[jit] Fix name collision on load (#35720)
0ed3f881c5,skip,clang-fmt (#35796)
c382ec88d1,jit,[jit] define equality for IValue (#34986)
2d85daca58,jit,[jit] kill `shallowEquals` (#35005)
fd1dfaa7d0,jit,[jit] kill isSameIdentity (#35019)
bc6bd0bb1a,jit,Debug Information Guard
a5bfcc5323,misc,Unify management of thread local settings (#35523)
1f06db2579,InLastRelease,Refactored rpc docs (#35109)
60a3e82c4e,onnx,"[ONNX] Fix for constant folding: Slice, Added ReduceL1 and ReduceL2 (#35280)"
8c534bb0bd,skip,Add __torch_function__ benchmarks. (#35530)
6318899c9b,amd,[ROCm] [ROCm 2.10+] enable fp16 dot in PyTorch backend (#30431)
409bac48e4,dispatcher,Move all warn logic for overwriting registration to OperatorEntry (#35769)
945d7a7408,distributed,Add All-to-all comms support to distributed module and MPI backend (#32361)
a736b994b7,docs_frontend,Remove old section of the aten doc that is not true anymore (#35807)
ceff21a4fc,skip,port fmod from TH to ATen (#24405)
d463c10668,th_aten_frontend,Migrate prelu_cuda_backward from CUDA_tensor_apply4 to TensorIterator (#33997)
e9d868a529,th_aten_frontend,Kill CUDA_tensor_apply4 (#33998)
6491bf2855,skip,Revert D20777341: [pytorch][PR] Add __torch_function__ benchmarks.
acb59a3b86,rpc,Remove unused header in process_group_agent.h (#35767)
2b068d10b0,skip,Removing references to PYTHON3COMPATIMPORTS. (#35384)
74ef0adf60,new_features_frontend,add mv operator to SparseTensor (#21782)
35cdb78522,improvements_frontend,Make kl_div accept target in log space (#34586)
990b54146f,skip,Revert D16864196: [pytorch][PR] port fmod from TH to ATen
15326fb240,skip,"Revert ""Attempt to fix windows build"" (#35217)"
ab26dfb44e,quantization,[quant] Move quantization tests into test/quantization (#35812)
16a88e4369,dispatcher,Add unboxedCallRedispatch (#35476)
5d1205bf02,amd,Suppress output when checking hipcc (#35789)
26ee0eee10,build_frontend,Use cufft_static_nocallback (#35813)
50b0bb6c6a,skip,Updating submodules
1c93a19a7f,InLastRelease,Fix another case of float2::x and float2::y may not be the same on ROCm (#35785)
9fe3b1857d,jit,[TensorExpr] Fix imports in tensorexpr benchmarks. (#35830)
16774f7353,skip,Increase TimerTest tolerance to 20% on Windows (#35818)
301be851ef,bug_fixes_frontend,Fix grid_sample out of boundary when grid contains large numbers (#35506)
41ef2c0d58,InLastRelease,Improve C++ API autograd and indexing docs (#35777)
e0ee8000ac,InLastRelease,Make test_leaky_relu_inplace_with_neg_slope device-generic and skipIfRocm. (#35816)
e372f42110,caffe2,[caffe2] Explicit vectorization of LSTM operator (#35556)
b3c0939af3,quantization,[quant][graphmode][refactor] Move the whitelists to a centeralized place (#35721)
6792dac90d,rpc,Only Schedule Retries before Agent Shutdown (#35554)
b33ae23c5a,cpp,Revert D20794765: [pytorch][PR] Improve C++ API autograd and indexing docs
6616fad92e,docs_frontend,[Docs] Fix typo in RPC docs (#35809)
2f50c11954,jit,add test_tensorexpr.py (#35776)
051132f119,jit,[TensorExpr] simplification of round + mod pattern. (#35683)
1bd68eafb5,InLastRelease,Skip ROCm test in test/test_cpp_extensions_aot.py (#35838)
c3abcf83aa,skip,[AI Bench] Resumme speed_benchmark_torch.cc to origin
2db61193bb,dispatcher,Add DispatchKey impl overload; remove use of torch::dispatch (#35706)
8e951c5793,skip,Add temporary impl_UNBOXED syntax sugar for unboxed-only defs. (#35714)
6d24f8fe21,jit,Infrastructure for a new CUDA Fuser (#34785)
86f3305859,cpp,Improve C++ API autograd and indexing docs (#35777)
e67951af63,skip,Revert D20775782: Add temporary impl_UNBOXED syntax sugar for unboxed-only defs.
0f99b28431,dispatcher,Revert D20775783: Add DispatchKey impl overload; remove use of torch::dispatch
c4f56e9685,quantization,[pytorch][PR] Optimize qavg_pool3d_nhwc (#35740)
676fc929b7,caffe2,[caffe2] fix type and shape inference for common gradient ops (#35857)
3ef5ff6012,jit,[TensorExpr] Make Load and Store multi-dimensional. (#35800)
602b51eb30,quantization,Changes to qadd for perf improvement.
173e444e66,distributed,track ddp API usage (#35837)
9097b55479,jit,Propagate static_if more completely. (#35834)
a53328e89c,skip,cmake: Grab TORCH_DEFAULT_VERSION from version.txt (#35260)
09660896c0,skip,Break circular dependency between ATen.h and TensorIndexing.h (#35765)
d9dd353a00,skip,fix clang-format (#35884)
bc7fdacf06,InLastRelease,[BugFix] Fix compare_exchange_weak in DispatchStub.h (#35794)
15b711a654,jit,Fix reporting of error message in toBool (#35570)
ddcad5b9ca,jit,temp disable test_tensorexpr.py
dabeff33b9,skip,[pytorch] Fix fblearner flow compiling errors (#35902)
c070e8fb26,complex_frontend,Updated canCast to disallow complex -> non complex conversion (#35883)
2595c62208,jit,[JIT] Better error on default params error (#35888)
2a4ca70832,caffe2,Fix contant/placeholder loading in checkGraphCompatibility
762270c51f,distributed,add c10d dynamic loading mechanism and unit test (#28068)
f5b9574887,skip,[easy] ThroughputBenchmark: make ScriptModuleBenchmark usable from c++ (#35848)
ced1e46399,quantization,[PTM] register aten::dequantize.self for spark spot int8 model
591b5da2c8,new_features_frontend,Removes integer division call sites (#35862)
1a72326942,InLastRelease,.circleci: Bump libtorch builds to 3.7 (#35912)
767ea03b22,jit,Clear profiling information timely and appropriately (#35814)
e2adcc1c53,build_frontend,Report CUDA separate compilation flag (#35726)
c33ea41f9c,mobile,Fixes a bug in serializing min/max plus one more. (#35850)
d0ce94d20e,mobile,Avoid one unnecessary memory allocation in XNNPACK integration. (#35350)
a5af478f29,skip,Use full include path in autogenerated Functions.cpp (#35924)
1a146b0577,performance_frontend,Vec256<bfloat16>::arange step size should accept templates. (#35842)
aeb13f212b,jit,Make ValType hashable. (#35917)
8484ca581e,jit,Add `GRAPH_UPDATE` for `x.size()` in Peephole Optimize (#34865)
be125d18dd,amd,[ROCm] [ROCm 2.10+] enable fp16 dot in Caffe2 backend (#30432)
e707cee501,build_frontend,Fix gcc-5.4 compilation (#35935)
beac3f27f0,skip,Make intdiv_256 a more generic binary operator template (#35422)
a1cf3fd1da,bug_fixes_frontend,lshift and rshift on CUDA should match the behavior on CPU (#35339)
ea8021d726,performance_frontend,Make intdiv_256 a more generic binary operator template (#35422)
87582ae6c4,rpc,Make RRef type_hint mismatch exception message more actionable to users (#35943)
0429d2c9b8,quantization,[quant][graphmode] Add new tensorlist observer for LSTM (#35893)
f0c747243c,quantization,[quant][graphmode] Insert Observers for dynamic LSTM (#35894)
7468ef04c2,quantization,[quant][graphmode] Add quantize_per_tensor.tensors (#35916)
2d8dbcd3ef,skip,"Remove python2 and 3.5 from requirements.txt, README and docs (#35677)"
2fa3c1570d,cpp,Refactor C++ API parity test mechanism and turn it on in CI again (#35190)
6e13a7787b,jit,[jit] Fix type comparisons segfault (#35929)
f48008c261,mobile,Set eval mode during optimization for mobile. (#35903)
c5c63a2e35,mobile,Add quick utility to transform scripted/traced models for mobile. (#35904)
19bbfbe1cf,rpc,[RPC][Better Engineering] Consolidated all rpcAgentRunning atomic booleans (#33915)
596153cad1,jit,[jit] Enable type tags in serialization (#35741)
b46fddf506,caffe2,idtt + zch distributed inference (#35763)
b3d30f2dc4,jit,[TensorExpr] Compiler warnings cleanups. (#35925)
af5121f62a,jit,Invoke TensorExpr fuser pass from a graph executor. (#35913)
ba3cec867f,jit,Reenable test/test_tensorexpr.py (#35914)
7b04772c51,skip,Keep same autogenerated files structure between fbcode and OSS builds (#35951)
71669f0249,skip,Fix flake8 (#35968)
03a4a4887d,skip,Fix `clang-format` (#35969)
ec3b355a0f,skip,Update ostream << TensorOptions printer. (#35892)
a054d05707,new_features_frontend,Add torch.utils.show_pickle for showing pickle contents in saved models (#35168)
eb42199788,skip,third_party: bump fbgemm to 0bb23bf9 (#35988)
d559a47933,quantization,Enable relu fusion with prepacked linear/conv. (#35705)
ccfcf47531,memory_format_frontend,Calls to Tensor::to pass MemoryFormat by TensorOptions (#34249)
4d5fe90046,rpc,[rpc] replace tests on worker_name (#35955)
4b64dffcb6,th_aten_frontend,Move uniform_() to DistributionTemplates(Migrate uniform_ from TH to ATen) (#35580)
585f153d00,build_frontend,Bazel build of pytorch (#35220)
eba5bdbeaa,dispatcher,[pytorch] register c10 ops for static dispatch (#35193)
fced0c9837,complex_frontend,Fix ATen/test/complex_test logic (#35976)
6be9c77998,skip,Revert D20783179: [pytorch][PR] Bazel build of pytorch
e73ab30f3d,complex_frontend,rand() and uniform_() for complex dtype (#35585)
e5c6003f3e,rpc,Mark prim::rpc_async as having side effect (#35994)
de04a1850f,complex_frontend,Remove nonexistent op variable in complex tests. (#35722)
a604041a11,skip,"Back out ""[pytorch][PR] indexing: throw exception for masks with dtype=uint8"" (#36013)"
beb9430ff6,mobile,Propagate input tensor names in XNNPACK backend. (#35351)
b7f4b6a6de,mobile,Support for XNNPACK max pooling operator. (#35354)
e3e2dd7779,skip,[Shape Inference] Set new shape according to precedence of dimType over previous value (#35910)
5fab1bf3e4,cpp,Use `std::abs` instead of `abs` in lbfgs.cpp (#35974)
82087ee7f6,mobile,Add DICT_CONSTRUCT and NAMED_TUPLE_CONSTRUCT to lite interpreter (#36015)
7b2b17f727,skip,Revert D20802884: [Shape Inference] Set new shape according to precedence of dimType over previous value
8a6173edf2,caffe2,[caffe2] tune prefetch distance
7ee88d61f7,dispatcher,Rename boxing/unboxing files and utilities (#35411)
b3cdec88e3,complex_frontend,Fix torch complex exp CPU implementation (#35532) (#35715)
66d50060eb,complex_frontend,Temporary methods for real and imag values of complex tensors (#35879)
81c8ca1e2e,mobile,Disable tracing for Pytorch Mobile client (#36007)
8224398c14,quantization,[pytorch] Fix the extra_repr print message for float16 dynamic quantization (#36044)
e56ba8481e,InLastRelease,[ONNX] fix size for opset 11 (#35984)
82d58ed484,quantization,disable the test to stop breaking the builds (#36053)
d568c7d966,jit,[TensorExpr] add more detail to malformed_input exceptions (#35891)
8dba98da0f,onnx,[ONNX] Added support for constant folding onnx::Add and onnx::Sub (#35869)
4ef383d5db,jit,add type hints on recently added ops to make them scriptable (#35885)
59ed0c5fd7,skip,Strip newline when ingesting `version.txt` (#36002)
45fc881f05,amd,[ROCm] Hotfix: Black list tensorexpr test set that has failures on ROCm (#36049)
0475d7b08d,jit,[JIT] optimize mutableType calls (#35474)
cb385cb6d7,InLastRelease,"Pin Sphinx to 2.4.4 (take 2), fix docs CIs (#36072)"
3e402a5940,amd,[ROCm] Enable BFloat16 type for add_out_sparse (#35978)
3228939f23,InLastRelease,[JIT] Fix fake_range() (#36083)
8ef82fc2c9,skip,[dt][caffe2] enable using smart exceptions in async nets (#34753)
b68c3827de,opbench,add benchmark for quantized batchnorm (#35389)
6405f26a02,opbench,add more quantized activation benchmarks and input sizes (#35729)
cc78914755,opbench,qactivation_benchmarks: small bug fix (#35731)
2ef1ace877,rpc,[rpc] call threadPool.waitWorkComplete after listenerThread.join() to fix (#35394)
b8383b3d4c,jit,[WIP] Enable NNC's LLVM dependency in CI (#35564)
7d1f06462c,rpc,Fixing Potential TSAN issue with joining RPC helper threads (#36094)
2173746f64,InLastRelease,Compile THCTensorTopK per dtype. (#36074)
40a45957a0,InLastRelease,May fix TopKTypeConfig<at::Half> without an additional Bitfield specialization (#36077)
4ced22c5de,jit,[JIT] Add IR Benchmarking tests to ai bench (#35732)
5d33cf5dfc,caffe2,[Shape Inference] Set new shape according to precedence of dimType over previous value (#36081)
f421cf3978,caffe2,update comments on fake operator (#36086)
a81be33a4e,skip,Add trivial reduce for Cuda (#36092)
6a45584272,InLastRelease,Remove `__nv_relfatbin` section from nccl_static library (#35843)
3da67ce367,caffe2,[caffe2] Factor libtorch_python_sources into exposed definition (#36005)
4c140052a6,performance_frontend,bfloat16: vectorized unary ops (#35092)
2f1ca26abd,caffe2,Update NNPI Backend to v0.5.1.4 (#4334)
0f243688be,skip,Updating submodules
459163b8eb,skip,Revert D20449887: [dt][caffe2] enable using smart exceptions in async nets
3570ef6a0f,jit,Revert D20876204: [pytorch][PR] Add trivial reduce for Cuda
449a4ca340,InLastRelease,Add more alternative filters in places people forgot to add them. (#36082)
803a4e135e,skip,Fixes CMake lint error (#36123)
64594d8333,build_frontend,Clang 9 and GCC 9 Support (#35835)
447bcd341d,build_frontend,Bazel build of pytorch with gating CI (#36011)
2e8f9547fa,skip,Updating submodules
70acc9c0f5,skip,Skips test_qadd_scalar_relu (#36128)
3e5d25fdfd,skip,Skips test_avg_pool3d_nhwc (#36130)
b55dee9fe1,bug_fixes_frontend,fix max_pool2d cuda version Dimension out of range issue(#36046) (#36095)
7e84a30ad6,skip,Enable backtrace with MSVC (#36039)
3328a2f903,cpp,Rename CPUGenerator to CPUGeneratorImpl and CUDAGenerator to CUDAGeneratorImpl (#36026)
34b32ca914,cpp,Remove operator-> from at::Generator (#36027)
7920a970c6,build_frontend,Don't statically link MKL multiple times on Linux (#36078)
16d9bcd725,quantization,Fix test_avg_pool3d issue in pytorch_paralleltbb_linux_xenial_py3_6_gcc5_4_test (#36103)
444073efde,skip,Add GenerateI8Depthwise.cc to bazel build definition of fbgemm (#36144)
2b06d5adc6,skip,Fix compilation errors for enabling Intel nextgen compiler (icx/icpx) (#35939)
6bc8ffe824,jit,[JIT] Optimize before inlining (#35562)
681ca45717,onnx,[ONNX] Export torch.inverse op (#35318)
c2901333f1,skip,Updating submodules
8afa001d89,skip,Revert D20885968: [pytorch][PR] Enable backtrace with MSVC
ebf743a63a,build_frontend,Fix bazel-test linking issue (#36157)
43234be525,skip,Update docs for master to remove Python 2 references (#36114)
2afe171538,skip,[JIT] List reland (#36146)
373dc7c8ef,InLastRelease,Group libraries in TOC and add PyTorch Elastic (#34928)
72b55fea6b,jit,[jit] Make torch::utils::Future and ivalue::future apis closer (#35849)
4b916b6b75,jit,Mark every frame with a unique id (#33788)
fc5d658324,rpc,[rpc] allow ability to abort second call to RecvWork::wait() in ProcessGroupAgent::listenLoop (#36084)
986a8fdd6a,InLastRelease,Use counter instead of vector of futures in `_parallel_run` (#36159)
e2f9c668a2,InLastRelease,Use `repo.anaconda.com` instead of `repo.continuum.io` (#36201)
25fe27981f,skip,Fix signed-unsigned warnings (#36196)
c04232ae2b,performance_frontend,"Back out ""[reland] Skip OpenMP Thread when OMP_NUM_THREADS is 1"" (#36198)"
f0bddd5e7a,skip,Fix clang-format broken by https://github.com/pytorch/pytorch/pull/33788 (#36203)
6f8017bf07,jit,Enable simple executor for FBCODE (#34748)
83abd7ffbf,skip,Revert D20909696: [pytorch][PR] Fix signed-unsigned warnings
5a03664fd5,InLastRelease,Attempt to fix the pytorch_cpp_doc_push build by pinning breathe. (#36190)
4c8e38c6d7,skip,Minor doc improvement for code_analyzer (#36177)
901bb3c350,skip,Delete as_variable_ref (#36096)
b9260bdb7b,build_frontend,Don't build deps for `python setup.py egg_info` (#36208)
b9fc4358d6,cpp,Enabled debug symbol in test_cpp_api_parity tests by default. (#36209)
9ada7abc18,jit,[JIT] fix comprehension scope writes (#36105)
07306406ce,InLastRelease,s/repo.continuum.io/repo.anaconda.com/ (#36233)
f99e6370dc,caffe2,fix build breakage of //sigrid/... (#36206)
38849e119f,InLastRelease,[pytorch] Add error when PyTorch used with Python 2 (#36151)
e99c53dc86,bug_fixes_frontend,Fix broadcast_coalesce for empty tensors (#35965)
ae71c5c7e6,performance_frontend,Optimized bincount for the CPU by removing extra size() calls (#35822)
93256617c8,InLastRelease,C++ Adam optimizer - corrected messages for check of default options (#36161)
a91535930f,rpc,[future] Undo some recent torch::utils::Future api changes (#36220)
195362d74c,jit,[TensorExpr] scalar factorization of Div (#36154)
9a2b505563,jit,[JIT] Shape inference improvement (#35051)
246416ac3b,skip,`clang-tidy` workflow only needs `cuda-toolkit` (#36241)
645d57ea01,jit,"Expose JIT Module's ""register_attribute"" to Python (#35630)"
fab06bfb75,jit,Add utility for bundling sample inputs with models (#35631)
5910c51545,InLastRelease,Exclude `torch/csrc/cuda/*nccl*` from `clang-tidy` (#36249)
82dd01150c,rpc,Fix race during RPC shutdown. (#36113)
3be6a4db4d,quantization,improve the quantized batch_norm performance (#35639)
7c76c71616,caffe2,[caffe2] remove quant options of SparseAdagrad from OSS (#35608)
83907ded1d,skip,Revert D20895316: [pytorch][PR] [JIT] List reland
6016f694c0,skip,Revert D20901746: [pytorch][PR] Update docs for master to remove Python 2 references
4db87f4f97,jit,[JIT] Allow mutated values as functional graph inputs (#33297)
4f3af09162,jit,[JIT] Incremental updates to Alias Db in Mutation Remover pass (#35421)
76c7652cc5,distributed,Add distributed data parallel benchmark tool (#35198)
caa45c8e33,jit,[TensorExpr] fix warnings (#36167)
6972c27d94,quantization,[quant] Enable fusion for conv modules with bias (#36173)
16980e455f,skip,"Fix naming of ""strides"" method in TensorType (#35170)"
0f34d648c8,skip,Fix signed-unsigned warnings (RELAND) (#36224)
0bc17ddaa9,performance_frontend,Use templates instead of macro when defining Vec256<BFloat16> bin operators (#35844)
3a8838840b,performance_frontend,Add comparison operators to Vec256<BFloat16> (#36106)
34a10238d5,InLastRelease,fix is_float_scale_factor warning (c++) (#35601)
2458f6c63e,InLastRelease,Move all nccl from torch_python to torch_cuda (#36193)
291c910e85,rpc,[future] Re-land some safe portions of the future change. (#36254)
dd36f8c21b,skip,[FBGEMM] Open sourcing fbgemm_fp16 ops (#36212)
3d199aab08,skip,Updating submodules
f59e646faa,rpc,[rpc] Allow profiling in RPC to work with torchscript function invocations (#36275)
5f25e98fc7,improvements_frontend,Use _sparse_coo_tensor_unsafe to shallow copy sparse tensors in accumulate_grad (#36292)
7487b2a184,caffe2,[caffe2][debuggability] add length checks to MergeMultiScalarFeatureTensors (#36248)
62f9312abd,skip,"Revert D20783298: Fix naming of ""strides"" method in TensorType"
ea8e347135,misc,Replace std::shared_ptr with c10::intrusive_ptr in at::Generator (#36230)
5bbcddae3b,misc,Add at::Generator to IValue (#36231)
075b732f26,docs_frontend,doc fix for KLDivLoss (#36137)
7403545518,bug_fixes_frontend,Fix exception message of `torch.optim.AdamW`. (#36088)
ddf5755ff8,distributed,Fix DDP error checking for unused parameters (#36054)
2b30e7fe11,skip,Move inplace view tests to generic testing framework (#36281)
fdf7a833e7,complex_frontend,Address printing inconsistency between float and complex tensors (#35841)
126d00c8dd,dispatcher,[pytorch] move force schema registration output into a separate file (#36284)
23e5f6a7be,quantization,Add avx2 integer horizontal sum and sum of squares to vec256 qint types (#35693)
f813e7184e,quantization,add quantized layer norm implementation (#35329)
423b01431b,caffe2,make vendor match with this implementation (#36302)
5061ef63f4,skip,"Revert ""Revert D20885968: [pytorch][PR] Enable backtrace with MSVC"" (#36205)"
1443db8dc3,jit,[TensorExpr] fix bug in IRSimplifier when multiplying by 0 (#36287)
866227cfb3,quantization,[pt][quant] Add vector path to copy kernel for quantized data types (#36189)
e311e53abe,dispatcher,Revert D18672405: Revert D18672405: Use codegen'ed unboxing wrappers (#36010)
9497b21e63,bug_fixes_frontend,Grad input padding support for dilation argument (#33872)
264da24c9e,rpc,Fixing RPC Shutdown and Thread Joining (#36239)
8493383e94,skip,remove some code part never been called (#35033)
376542c83d,caffe2,caffe2: preserve python exception type from PythonOp (#36267)
f0ea6862ba,caffe2,Support for pruning delays in Adagrad Optimizer (#34527)
e551bfc8de,jit,New CUDA Fuser code lowering refactor (#36199)
d51ad40fe1,quantization,"[quant][onnx] Mark upsample_nearest2d, sigmoid and reshape as no scale (#36325)"
88c22070fe,quantization,Revert D20768930: add quantized layer norm implementation
90c7db8ae3,caffe2,caffe2/core/plan_executor: add cancellation of async nets on error + propagate exceptions via std::exception_ptr for stack traces (#31966)
477f1c047c,jit,[TensorExpr] add simplication of constant branches to IR Simplifier (#36257)
ef07bb65e9,dispatcher,[RELAND] Add DispatchKey impl overload; remove use of torch::dispatch (#36222)
2de3e491a8,dispatcher,[RELAND] Add temporary impl_UNBOXED syntax sugar for unboxed-only defs. (#36223)
1ffc2d9ace,skip,Updating submodules
9662ef66b7,InLastRelease,Fix `torch.min` docs (#36319)
14ce500a9b,rpc,Appropriately handle exceptions in autograd engine. (#36019)
358466f1da,quantization,[quant] Move graph mode quantization tests to test_quantize_script.py (#36324)
51456dc808,skip,Updating submodules
f2bae8e869,quantization,[quant][fix] at::print for per channel affine quantized tensors (#36280)
7374a00bef,skip,[pt]Supported benchmarking pytorch jit self-contained models. (#35279)
c5662dd5dc,quantization,Base class for the quantized ConvTranspose (#35370)
48bf3eef1a,onnx,[ONNX] disable size optimizations for onnx (#36243)
8cb1950805,jit,[JIT] fix alias assertion (#36178)
d916cf05d4,quantization,[quant][test] Split TestQuantizeScript to two TestCase (#36354)
2f5b523cd0,complex_frontend,Remove unnecessary whitespace in complex tensors (#36331)
d9227bb311,performance_frontend,Target 4096 blocks instead of split to large grid for large reduction (#35997)
3d7c9abbf7,performance_frontend,Refactor thread_reduce for better unrolling and vectorization in the future (#36014)
891a533b24,quantization,Adding Conv1d to quantization default_mappings (#36352)
391a36a59c,skip,Updating submodules
aac36a89ff,jit,[model transform] tuple to arglist jit pass (#36093)
2ec6a30722,caffe2,Bump produced file format version (#36085)
37c1bd2946,caffe2,Move FakeFP16 back to internal to remove dependency on MKL (#36297)
31dca07fa5,skip,Updating submodules
9a4bc67f66,caffe2,[caffe2/detectron2] fix Mask R-CNN caffe2 conversion on GPU (#36366)
7fcf8b0a3b,mobile,[Lite Interpreter] Operator registration migrate from manual to selective build (#35426)
ee4cc96eee,performance_frontend,Vectorize in-place comparison operators (#35117)
586481a6e2,mobile,Revert D20408831: [Lite Interpreter] Operator registration migrate from manual to selective build
a91097bdfb,mobile,Revert D20964368: Revert D20408831: [Lite Interpreter] Operator registration migrate from manual to selective build
817e4f9ef1,bug_fixes_frontend,Correct a ValueError in dataloader to TypeError (#36244)
3aeb2b1562,complex_frontend,Returns float tensors for complex inputs to abs (#35871)
7c825bad10,opbench,[RELAND] Add __torch_function__ benchmarks (#36138)
1875c2e4bd,improvements_frontend,Add torch.Tensor.as_subclass method. (#34369)
b0c90fad93,quantization,Re-enable test_avg_pool3d_nhwc (#36259)
79973a16ce,skip,Add missing TORCH_API annotation (#36391)
247f2df840,caffe2,Fixed include file header guard. (#36329)
d73ee763fc,skip,Fix the clang-format error caused in register prim ops change. (#36393)
e574ff3511,skip,Updating submodules
4a98ba811c,skip,Enable c10 unboxing for ops with TensorList (#36330)
5177906d67,caffe2,[Shape Inference] Infer shape info for second input of elementwise ops (#36365)
42457e634d,skip,[TensorExpr] add support for Reduction Ops (#35866)
15c7486416,skip,"Canonicalize includes in c10, and add tests for it (#36299)"
82be7c755a,skip,[pytorch] reduce memory footprint in fused conv QAT ops (#35002)
f999d600d0,jit,Fix the typo in operator name string (#36296)
c029aaa25c,skip,Updating submodules
d27dccfdaf,caffe2,Open source the missing part of FakeFp16 ops (#36353)
343f2c0925,skip,Port masked_select cuda from TH to ATen (#35429)
7576cf8d00,caffe2,[caffe2] Use cpuinfo in perfkernels to simplify build dependency (#36371)
eddbee19a7,quantization,hardswish: add cuda kernels (#36350)
86e8c49fae,skip,Revert D20523080: [pytorch] reduce memory footprint in fused conv QAT ops
bd4761123d,skip,Revert D20958928: [pytorch][PR] Port masked_select cuda from TH to ATen
6920b13500,caffe2,Move fakelowp tests from glow to caffe2 (#36409)
4305c7f97e,misc,Remove experimental c10 ops (#36394)
e892398922,improvements_frontend,Upstream generic device test patch. (#36321)
d71aeeceef,skip,Updating submodules
5b331e8611,rpc,Catch exception in distributed engine callbacks. (#36118)
409346eee3,skip,Updating submodules
0dbb21f89e,skip,Revert D20931186: Enable c10 unboxing for ops with TensorList
ae452a81a9,rpc,"[DistAutograd x JIT] Capture global state, dist autograd current context id, before thread switching triggered by JIT future.wait() (#36395)"
742c77971a,complex_frontend,Revert D20961711: [pytorch][PR] Returns float tensors for complex inputs to abs
7e8c27ed25,complex_frontend,Fix view_complex_as_float for empty tensors (#36415)
c856a2cb0d,dispatcher,Move unboxing to after dispatch for ops with manual kernel registrations (#36398)
397aa46a3e,jit,[TensorExpr] Bounds inference (#35120)
df5f0a04ff,jit,[TensorExpr] Implement LoopNest::computeAt (#36112)
91441ae87f,mobile,[Lite Interpreter] Move Implicic ops to register_prim_ops.cpp (#36406)
22212a82b4,dispatcher,Remove functor factories in KernelFunction (#35488)
7b9ab91614,dispatcher,Improve boxed dispatch performance (#33313)
7aa6a8fd7a,complex_frontend,Disables complex min and max (#36377)
c1efe1ddb5,caffe2,Enable building of FakeLowP ops (#36170)
e3af0c9f9b,jit,[TensorExpr] Add new file bounds_inference.cpp to BUILD.bazel. (#36440)
4f728c9d81,onnx,[ONNX] Enable constant folding for Shape (#35386)
254be6a201,misc,Adds NumPy array x Torch tensor binary ufunc interaction test (#35945)
0c9bf64989,complex_frontend,Disables complex clamp (#36373)
d83509e603,quantization,[quant] Fix for the conv1d kernel shape (#36397)
4bcd8ab6f7,complex_frontend,Added complex types to get_all_dtypes and turned on masked_fill for complex (#36335)
6be8560375,build_frontend,Do not double compile generated files (#36417)
b92f8d9b7e,complex_frontend,Revert D20950587: [pytorch][PR] Added complex types to get_all_dtypes and turned on masked_fill for complex
d2e0c628e9,skip,Updating submodules
379e4d9cad,bc_breaking_frontend,[pytorch] Make behavior of SobolEngine consistent w/ other RNG functions (#36427)
a2e059cfa6,quantization,add missing 'import warnings' (#35313)
1e15063761,profiler,ThroughputBenchmark: integration with Autograd Profiler (#36282)
35cc2bbca3,cpp,Removed unnecessary call to '_strong_wolfe' in LBFGS. (#36453)
2bc49a4b85,new_features_frontend,block_diag dense (#33449)
e3b6dd1708,rpc,[rref] Minor tweaks in rref_context (#36419)
4f956fcf88,jit,_requires_grad -> requires_grad (#36168)
967cdc2baf,jit,Simplify replicate logic (#36174)
d591a7bb82,jit,Use Function to implement fork. (#36179)
ce54f0d411,skip,"Back out ""Revert D20449887: [dt][caffe2] enable using smart exceptions in async nets"" (#36172)"
d070c0bcf0,cpp,ROCm: enable cpp_extensions.load/load_inline (#35897)
ced9edbaa4,improvements_frontend,[Torch Device][c10] Fix the expected torch device error message (#36446)
765bf8f03d,jit,Remove duplicate bindings from torch/csrc/jit/python/init.cpp. (#36492)
0035aeef40,rpc,[autograd] Avoid holding lock when completing GraphTask futureResult (#35101)
d7b7998370,skip,Enable more tests in fbcode (#36418)
3526627f46,skip,Use unittest assertWarns instead (#36411)
5a7f889a11,build_frontend,Use bazel build rules from fbgemm (#36339)
c9a1fc2b31,misc,replace Generator arguments with c10::optional<Generator> (#36232)
110893abf0,caffe2,[Shape Inference] Infer input(1) from input(0) in elementwise ops (#36498)
b38d505e42,caffe2,[shape inference] use max_seq_size as max_feature_len in SLS and LengthsRangeFill inference (#36346)
0912284830,docs_frontend,CI failure tips (#36507)
c49de6ce0d,visualization,[TensorBoard] fix #33140 (#36497)
1f40bddf57,visualization,[TensorBoard] fix #36471 (#36495)
fd008bd170,jit,Make patterns in test_unmatched_annotations more flexible (#36422)
0b7e832325,misc,Fix signed integer overflow in rng_test.h (#36421)
501d9f33ab,skip,Fix clang format (#36544)
739351fac4,skip,Fix linter warning: replace f-strings with str.format for Py2 compat (#35492)
455d4aab64,quantization,[PyTorch Numeric Suite] Add weight compare API (#36186)
0964b662c3,quantization,qnnpack hardswish - LUTs (#36252)
1e22717118,quantization,qnnpack hardswish - pytorch op integration (#36320)
c7631716da,skip,Output more debugging information for reduce kernel (#35946)
8544591f5a,cpp,Fix a segfault in DeviceThreadHandlePool and PoolWindow (#36416)
eb00bac2b5,caffe2,Make FakeLowP tests work (#36525)
9fcb4ab393,skip,Fix either::map naming (#33904)
36b273abc0,dispatcher,Refactor jit::Operator to more clearly distinguish the two possible states (#33905)
70b826a884,skip,Make DispatchKeyExtractor forget about TensorOptions (#36290)
289d52c120,InLastRelease,Fixing SyncBN dgrad (#36382)
4d1ccafb4b,caffe2,[caffe2] Enable copying for caffe2::Tensor (#36468)
d5ba39c25d,jit,[TensorExpr] Postpone insertion of Alloc/Free statements in computeAt. (#36526)
999d7f6ab2,jit,[jit] tracer flag to guard risky behaivors (#36277)
411ccce279,skip,Revert D20936595: Make DispatchKeyExtractor forget about TensorOptions
6e7eaabf49,rpc,Lock optimizations for DistAutogradContainer. (#36529)
076d46f826,amd,[ROCm] Add debug flag (#36521)
8f501f3083,dispatcher,Update internal invariants in the world of manuallyBoxedKernel (#36388)
dd64e738c5,dispatcher,Expunge TensorId from all DispatchKey names. (#36240)
018c3420b8,jit,"Make dim, numel, element_size into prim ops (#36551)"
fb70b4fb93,caffe2,[caffe2] Add support for std::shared_ptr<std::vector<TensorList>> in PackRecordsOp and UnPackRecordsOp (#36550)
ed2d1cb2c4,dispatcher,Revert D20147487: Refactor jit::Operator to more clearly distinguish the two possible states
69e3ee2d5f,improvements_frontend,DataLoader: properly diagnose exceeding file descriptor limit (#34768)
d3cf9452af,docs_frontend,doc note on deterministic/non-deterministic gradient for min/max/median (#36481)
4b3e3d8227,caffe2,[improve logging] add the param information when logging the optimizer engine (#36558)
f3f640d479,skip,move test_abs to device-generic tests (#36465)
4ebb1278e0,quantization,[quant] Update qbatch_norm name to qbatch_norm2d (#36494)
8a60d8bfe2,build_frontend,Create a new bionic image with clang9 (#36187)
9a680056ad,build_frontend,Remove extern C for TH_API (#36142)
25252816cf,complex_frontend,Add core of c10::complex (#35524)
7390c333d6,InLastRelease,[CI] fix test_distributed for python 3.8+ (#36542)
01b121bd14,skip,Fix bc test (#36588)
6c742af235,jit,Remove attributes and method of submodules in frozen module (#34787)
5150334c1d,dispatcher,Unconditionally register schema even for manual registration. (#36250)
9216c67c9e,complex_frontend,Revert D21021677: [pytorch][PR] Add core of c10::complex
ce3555a635,th_aten_frontend,Relanding masked_select cuda port from TH to ATen (#36539)
67e0bf14b7,jit,Add support of Dict as output when connecting script and tracing (#36265)
73f11a0b23,quantization,Update qbatch_norm2d opbenchmark test (#36630)
1a0b95e7e4,skip,bfloat16: enable basic math function (#35172)
37aab14d14,rpc,[future] Avoid some future callback self-captures. (#36502)
317f598103,jit,[TensorExpr] Clang-format test/cpp/tensorexpr/*. (#36615)
ceecca3324,skip,Clang-format: whitelist test/cpp/tensorexpr/*. (#36616)
80b01ba4f3,visualization,[TensorBoard] fix #34954 (#36496)
91e59f5fe2,build_frontend,[PyTorch] Remove build definitions from `build_variables.bzl` (#36602)
70d3616aa1,build_frontend,[PyTorch] Split `libtorch_sources` into smaller filelists (#36583)
84f4061a67,dispatcher,"Back out ""Revert D20147487: Refactor jit::Operator to more clearly distinguish the two possible states"" (#36634)"
f7c9faab05,caffe2,Implementation and operator test for STORM optimizer (#36225)
cf27d07e04,caffe2,Implementation of STORM optimizer caffe2 python wrapper (#36399)
f99a28f515,onnx,[ONNX] Adding a pass to replace interpolate function with aten::__interpolate (#35744)
9cac2b83d9,skip,[pytorch] improve code analyzer to dump ops called from c++ functions (#35941)
cdfefa77a3,improvements_frontend,PR for double backwards of nn.Fold and nn.Unfold (issue #33452) (#36379)
16e90eba59,quantization,hardsigmoid: add cuda kernels (#36351)
3c8921b747,quantization,hardswish: add backards pass test (#36420)
1e7155caa5,new_features_frontend,Bucketization (#7284) (#34577)
87be115fd0,rpc,Error Handling in RPC Agent (#35263)
4a49ad0da7,distributed,Fixed error Regex Parsing for Node Failure Tests (#36620)
527cf877d6,caffe2,Delete old `mkl_speed_test.py`
f98e0a099a,skip,[pytorch] handle pybind11 style registration API with code analyzer (#36607)
62e884f8d9,build_frontend,Report bazel-test results as CircleCI metadata (#36643)
ba3d4019e9,jit,Remove prim::CudaFusionGroup from register_prim_ops_fulljit.cpp: it is registered in jit/codegen/cuda/interface.cpp. (#36661)
df9a250b8d,quantization,[pt][quant] avgpool3d for graph mode (#36598)
5afd816793,InLastRelease,Add a warning for Single-Process Multi-GPU DDP (#36656)
efab75730f,InLastRelease,Migrate release CI jobs to CircleCI for Windows (#36657)
e80813fae3,jit,Add trivial reduce for Cuda (#36293)
dad25ae47d,jit,Add the one-block multi-thread global reduction support. (#36306)
a3314f1902,jit,[jit] Add return statement back to Future::addCallback() (#36662)
ddd9eb3e12,jit,Make special cases prim ops instead (#36635)
2cf53128a8,build_frontend,Switch xla job to use bionic clang9 image (#36618)
609b6875f9,amd,Enable test_upsamplingNearest2d_launch_fail on ROCm (#36624)
6bd6b70a02,skip,Fix clang-format (#36685)
5927a6731c,rpc,[PyTorch Docs] Updated RRef docs to indicate RPC Retries (#36678)
8d66f88eb1,jit,[jit] Fix bound method copying (#36546)
a99b169828,jit,[TensorExpr] fix a bug in LLVM codegen around empty kernels (#36660)
9cbeb0faed,jit,[JIT] Dont optimize shape peepholes on inline (#36404)
65df8b3886,quantization,hardswish: make it work in static quantization (#36545)
91f1d79d1b,quantization,hardswish: enable for QAT (#36604)
a5d0d762fa,quantization,redo of add quantized layer norm implementation (#36593)
f64fae9193,rpc,Fix race in mark_graph_task_completed. (#36640)
30dd0b74fd,misc,Save view_fn for inplace update on view tensors (#36073)
f548946363,caffe2,Fix out-of-boundary access in `caffe2::StartsWith` (#36672)
e17cf93b9a,skip,Report tesnro_expr test results (#36684)
7539ea0207,jit,[TensorExpr] Add simplification of length 0 and 1 For loops to IR Simplifier (#36348)
f89fc204c6,caffe2,[caffe] fix input order in SLS op documentation (#36708)
0785585db9,dispatcher,Reland Make DispatchKeyExtractor forget about TensorOptions (#36290) (#36562)
30fabd9398,jit,"Creates ""Versioned Symbol"" pattern to preserve serialized Torchscript semantics (#36300)"
049dede3be,InLastRelease,Move rpc.rst back to the source folder to preserve existing doc URLs (#36675)
9e016f77a8,complex_frontend,Added complex types to get_all_dtypes and turned on masked_fill for complex (#36335)
bede7d9995,jit,Fixed check for the buffer overflow in assert (#36476)
d0c925f1c7,complex_frontend,Returns float tensors for complex inputs to abs (#35871)
d7fabfd5df,complex_frontend,Implements complex isfinite and isinf (#36648)
f11c4f90c2,jit,"New CUDA Fuser: Unrolling support, interface refactor (#36435)"
f5c230b892,rpc,Make futures vector a local function var (#36677)
ac950bb9c8,docs_frontend,Update docs for master to remove Python 2 references (#36336)
83de675ebf,build_frontend,Fail CMake setup if trying to build with Python 2 (#35612)
3c85f44ce8,build_frontend,Fail setup.py if trying to set up with Python 2 (#35613)
e29348f828,dispatcher,Switch to pybind11 style registration function API. (#36258)
54a575c9bd,jit,[JIT] fix torch.tensor jit dtype (#36587)
dd4dece68a,quantization,[quant][graph] Add useQuantizable function (#36691)
cb6bebfa9b,quantization,[quant][graph] Add quantized batch_norm2d support to graph mode (#36692)
3567b881a5,dispatcher,make sure dispatch test works on windows (#36729)
487dc0f961,skip,Re-enable a failing test (#35847)
a85c835196,skip,[WIP] Move profiler to a dispatch wrapper (#33057)
ee3d046f87,jit,[TensorExpr] Add support for Axis reordering in LoopNest (#36540)
4894cba572,skip,Revert D19775659: [WIP] Move profiler to a dispatch wrapper
5b515fd034,build_frontend,Delete pytorch_linux_xenial_cuda9_cudnn7_py3_build (#36731)
37479ddf4e,caffe2,[caffe2] create and register child ws in pybind (#36741)
e9b4580411,skip,Revert D20839674: [pytorch][PR] Re-enable a failing test
1fc3556ec9,jit,Teach the tensorexpr vectorizer to handle nested For loops. (#36467)
66158868d5,dispatcher,Update reference to RegisterOperators in error message in Convolution (#36389)
17c268be10,quantization,[quant][graph] Add quantized batch_norm2d_relu to graph mode (#36552)
753157b88e,quantization,[quant][graph] Graph mode quantization support for sigmoid (#36622)
63e5058c88,jit,"Fix naming of ""strides"" method in TensorType (#36727)"
05bbf6afb6,dispatcher,Revert D20964193: Port to new registration API (part 1)
e1cb8577ac,jit,[jit] remove Dict iterationOrder and use insertion order (#36609)
24aac32171,jit,[jit] Add dictionary as output of tracer (#36696)
2c558dba3d,quantization,quantized layer norm: add to static quant (#36690)
484a00b2d3,quantization,[quant] Add backward compatiblity test (#36771)
dcfc121fd7,quantization,Enable jit trace check_trace for quantized inputs (#36740)
d7fc05b0bf,build_frontend,Fetch TORCH_SRCS from `build_variables.bzl` (#36737)
6d4c509168,skip,[autograd] lower MAX_DEPTH limit according to TSAN limit (#36745)
76f9528878,jit,fix an infininte loop in liveness (#36697)
eccb40f505,mobile,Optimize mobile model on cloned module instead of in-place transformation (#36621)
b0227f2965,rpc,Add a test to verify non-contiguous tensors work correctly with RPC. (#36705)
f00014b790,quantization,Revert D21080503: [pytorch][PR] [quant] Add backward compatiblity test
b5483b8286,jit,[pytorch][PR] Re-enable a failing test (#36763)
a89d1ed549,dispatcher,Move unboxing for factory ops to after dispatch (#36564)
b45b9673a1,skip,Fixes clang format (#36787)
31f91d645a,jit,Improve aten::backward handling (#36750)
32bbf12aa7,jit,Make trivial thread-idx for degenerate statements without thread-idx. (#36480)
ebdc4f02ad,InLastRelease,Fix incorrect merge of #34136. (#36760)
46288465fe,InLastRelease,Print keyword-only arg symbol for function signature suggestions. (#36780)
4c666d42ff,InLastRelease,Handle log_sigmoid(out=) properly. (#36736)
9df9aef9b9,amd,[ROCm] Use float datatype for RNN test for MIOpen (#36772)
adca88e821,quantization,Fix hardsigmoid/hardswish for proper device dispatch. (#36704)
e6bc34f549,docs_frontend,Amp gradient accumulation example (#36601)
d92005ff73,skip,Vectorize reduction when reducing on fastest striding dimension (#36709)
3a400b8dc3,visualization,[tensorboard] Fix function input parameter for add_hparams (#31301)
54a1e8509c,build_frontend,Reduce binary size of schema inference (#34735)
cc5befc461,skip,[Format] format a few files (#35187)
d7608c7f56,mobile,Move DICT ops to lite interpreter (#36816)
0a8a012005,dispatcher,[RELAND] Port to quantized and other operators to new registration API (#36799)
fac076a82c,mobile,[pytorch] move prim::TupleIndex from register_prim_ops_fulljit to register_prim_ops (#36808)
86f354c530,mobile,Python binding api to optimize for mobile model on script module. (#36357)
4668d47d1f,build_frontend,Add build_variable.bzl to CMAKE_RERUN target (#36809)
f767de608c,visualization,[tensorboard] Add strings to image boxes (#30941)
681158e211,skip,Print all test output while running unit tests in bazel (#36825)
a64ea8ea04,skip,"Back out ""Vectorize reduction when reducing on fastest striding dimension"" (#36854)"
6963973d5b,amd,Print GPU info for ROCm test runs (#36827)
dc1f9eee53,amd,"Avoid printing erroneous warning about ""MIOpen not found"" for ROCm builds (#33837)"
b08494eb19,caffe2,Use hypothesis to to control the rand seed (#36717)
1b1a6a90c0,caffe2,Open source fakefp16 BatchMatMul op (#36789)
b245b1d23e,caffe2,Open source fbgemm fp16 pack op (#36791)
57c50db441,quantization,[reland][quant] Add backward compatiblity test (#36842)
197c85fcbc,caffe2,Use hypothesis to generate seed (#36860)
2e93808cde,docs_frontend,Update functional.py (#36600)
5d9b4d5720,docs_frontend,Update contribution_guide.rst (#36438)
0e6c66493a,rpc,[engine] Ensure future is complete when exiting Engine::mark_graph_task_completed() (#36856)
d933ec14ce,caffe2,[c10] Fix the hanlding for Caffe2 ops which return tensor list (#36841)
136d84dd38,distributed,Enhance error message for MPI unavailability. (#36781)
6ba734bae9,performance_frontend,Vectorize reduction when reducing on fastest striding dimension [resubmit] (#36873)
8b685a8af0,cpp,"C++ make constructor NamedAnyModule(name,any) public (#36869)"
b0b9e704ed,caffe2,[nnpi glow unit test] SLS tests shape sweep with hypothesis testing (#36833)
3aec9f7924,mobile,[AIDemos] Add missing operators for AIDemos (#36756)
54ed6fd3ee,skip,Use both absolute and relative tolerance in testing (#34258)
f6daa6220e,skip,QuantizedCUDA implementation (#35463)
49b10c58a3,skip,Revert D20896697: [pytorch][PR] QuantizedCUDA implementation
be9748f226,caffe2,Minor tweak of FakeLowp CMakefile (#36861)
1b3741aa7f,improvements_frontend,[WIP] reenable bfloat16 masked_select (#36859)
1341ea4802,bug_fixes_frontend,Fix MaxPool3d CUDA backward incorrect results for non-square output (#36820)
3c55b5a8ef,InLastRelease,Update persons_of_interest.rst
60c3060621,misc,Remove CUDA9Workarounds.cuh (#36840)
246e9abf3f,caffe2,Backward-compatible workaround for ATenOp index with dtype=uint8 (#36667)
49457a7be7,caffe2,Logging for ATen op subtype
9d5dda7c2f,skip,[pytorch] Route default warning sync to LOG(WARNING) (#36768)
0f0d69009e,bug_fixes_frontend,Makes CUDA -float->uint8 cast consistent with CPU (#36832)
30e7055ed7,skip,Revert D21078446: [pytorch] Route default warning sync to LOG(WARNING)
c7cf4c1bd6,new_features_frontend,Bmm sparse dense (#33430)
25649684ed,opbench,ai-pep: align qconv benchmark to conv (#36673)
13391cebe2,opbench,ai-pep: match the qlinear benchmark to linear (#36674)
399f494d22,skip,Add at::aten::hardsigmoid symbol (#36851)
68f847c4c6,rpc,[rpc] Remove redundant call to createExceptionResponse (#36857)
2fa17dedac,performance_frontend,add a fast path for EmbeddingBag calling FBGEMM (#36679)
dc4d888193,amd,ROCm: don't warn about CUDA compute capabilities (#35949)
1e054bfbdc,complex_frontend,"Report error for lt, le, gt, ge in complex Vec256 (consistent with <, <=, >, >=) (#36646)"
752d3c281a,profiler,[profiler] Allow record_function ctx manager to profile futures (#35055)
e0e70589ef,quantization,[quant][graphmode] tanh pattern and test (#36880)
4d2502a0c2,build_frontend,fix explicitly defaulted constexpr assignment operator fails to compile error for gcc 5.3.0 (#36561)
4e365b9cd1,distributions,[Distribution] Implement kl divergence for Cauchy distribution (#36477)
63e9d95c12,dispatcher,Remove hacked twins from codegen (#36666)
a2951a1ea1,quantization,[quant][graph] Update quantize_dynamic_script API to take sample model args (#36817)
47023148ee,skip,Convert C casts to static casts (UnaryOpsKernel) (#36400)
97f2513c26,skip,"Canonicalize includes in aten, and add tests for it (#36301)"
1d720228d2,quantization,"hardsigmoid operator for QNNPACK, using LUTs (#36698)"
4d171c0ed9,quantization,hardsigmoid: add PyTorch wrapper for the QNNPACK path (#36699)
28f439d4f4,improvements_frontend,add absolute alias for abs (#36597)
dbdd0f50f4,quantization,[quant] Minor refactor in fused conv names (#36883)
1c15cb4773,skip,Add bundled input support to speed_benchmark_torch (#36765)
ee2a9ac56e,quantization,[quant][graph] Support for quantized::mul and quantized::mul_scalar (#36818)
c03d149483,quantization,[quant][graph] Add quantizedmul_relu and quantized::mul_scalar_relu ops (#36844)
0647f34477,build_frontend,Delete docker build job for pytorch-linux-bionic-clang9-thrift-llvmdev (#36930)
5e504e83e8,jit,Add sync-point insertions and block/thread local memory allocations (#36563)
32307efd68,distributed,Fix flaky test_barrier_timeout* tests for test_distributed. (#36963)
a14a8376aa,distributed,Link NCCL lib to TORCH_PYTHON_LINK_LIBRARIES when USE_NCCL=1 (#36948)
3ae70cb847,profiler,Add RecordFunctionGuard (#36215)
346215caa4,jit,[jit] Adding vectorized load/store support for JIT generated CUDA kernel (#36555)
59f923e884,caffe2,Update NNPI backend to 0.5.1.8 (#4397)
ce0500eb4c,InLastRelease,Ensure linearIndex of advanced indexing backwards is contiguous. (#36959)
742d9796bc,amd,[ROCm] Enable wrongly skipped tests on CPU on ROCm (#36968)
cdc1ca040a,skip,Enable test_hardsigmoid_grad_xla on pytorch side (#36967)
a1eb591ea6,performance_frontend,"fmadd in vec256_base should be on Vec256<T>, not T (#36751)"
3d2d5c82da,performance_frontend,Clean-up non-AVX variant of `bitwise_binary_op` template (#36966)
68f6b9873b,skip,[TEST] add ops for portal TTS model (#36971)
98c293c1ef,quantization,Do not use VLAs in vec256_qint.h (#36855)
0f3af8529a,skip,Revert D20961463: [TEST] add ops for portal TTS model
ff435a0e6b,improvements_frontend,[pytorch] add test for empty tensor support in nn.Linear (#36983)
be52b7f0ea,docs_frontend,"Documentation LU Decomposition: deriving L, U, and P (#36907)"
246b208e4f,caffe2,make merge_fp32_into_fp16_inputs to generate ops for each partition (#36973)
db84689c09,skip,CMake/Ninja: fix dependencies for .cu files (#36938)
01100cb477,dispatcher,Put TORCH_LIBRARY in torch/library.h; add custom class API (#36742)
00b7d84eb7,distributions,Add a .with_cache() method to distributions.Transform objects (#36882)
54f265249c,performance_frontend,Optimize grouped Conv3d performance (#36355)
71ec8b2002,skip,Switches test_jit to use float32 as its default scalar type (#36982)
a05406ea56,skip,[clang-format] Disable progress bar if stdout is piped (#36955)
2ccdc39dce,dispatcher,Revert D21089648: Put TORCH_LIBRARY in torch/library.h; add custom class API
6383373a04,quantization,[quant][graphmode] fused conv3d + relu (#36885)
4efef475d7,distributed,[WIP] make test_distributed gloo test use MultiProcessTestCase (#36970)
97d3a8495d,skip,[reland][quant] QuantizedCUDA implementation (#36936)
ea97fa1f2a,rpc,[PyTorch][Dist] Trigger pre/post hooks of output function nodes under distributed autograd (#34501)
6d13a334f6,dispatcher,Remove use_c10_dispatcher: unboxed_only (#36838)
9854df673c,jit,[TensorExpr] Fix bug in For elimination in the IRSimplifier. (#36965)
b607c83a26,improvements_frontend,Add support for bool/byte `attn_mask` tensor in MultiheadAttention/Transformer modules (#33763)
4e463b6366,jit,add missing ops for portal TTS model (again) (#37007)
1f82679311,build_frontend,Revert D21156042: [pytorch][PR] CMake/Ninja: fix dependencies for .cu files
6eb109e1ad,quantization,Enable float only requantization. Part 1. (#35856)
e1742e8e4e,dispatcher,"Revert ""Revert D21089648: Put TORCH_LIBRARY in torch/library.h; add custom class API"" (#37019)"
bf676682e7,skip,Fix long line splitting issue in python_print (#36188)
6ebfff6c4e,dispatcher,Add locks to fallback register/deregister. (#36628)
806f22b167,build_frontend,find backtrace by cmake module (#36017)
a92f1dc85e,skip,native_functions.yaml: reset_grad_accumulator (#36431)
bcdb0727c2,skip,Revert D20907254: Fix long line splitting issue in python_print
1592d6842c,profiler,[resubmit] Move profiler to a dispatch wrapper (#36766)
f0a533c5dd,rpc,Fix flaky test_backward_node_failure_python_udf (#36969)
b019a8d484,caffe2,fix spatialbatchnorm on nnpi (#36987)
443fe7ca0e,skip,[rpc] Avoid wireDeserializer overreading buffers by 1 byte (#36976)
8eb22f6ee9,dispatcher,"Revert D21161361: [pytorch][PR] Revert ""Revert D21089648: Put TORCH_LIBRARY in torch/library.h; add custom class API"""
359e7f4bba,jit,Teach IRParser to parse strides along with sizes in a tensor type. (#36951)
dc327d9082,jit,[TensorExpr] Remove obsolete code for handling dynamic shapes from kernel.cpp. (#36686)
a850d8a526,bug_fixes_frontend,Fixes exponential with lambda=0 (#36837)
25abdcb3d1,jit,[TensorExpr] add Block flattening to IR Simplifier (#37013)
b982a6a247,distributed,Expose torch.distributed.is_available() API (#37021)
5c2b273089,rpc,Add RRef Python Helper to launch function on the referenced object (#36619)
4a2372bc90,complex_frontend,Implements torch.isclose for complex tensors (#36456)
7b03ce7bb3,jit,make sure logs work inside aten/c10 namespaces as well (#37018)
4bbc49f53a,quantization,Revert D21143025: [reland][quant] QuantizedCUDA implementation
4593d87b84,build_frontend,Do not link torch_python with nccl (#37040)
6df90bcecc,skip,setup.py: Remove conflicting double documentation of USE_FBGEMM (#36993)
b8e2d797c0,jit,[TensorExpr] Insert allocations for temporary buffer at the innermost valid scope. (#36836)
799793f279,jit,[TensorExpr] Cleanup IRPrinter implementation for statements. (#37050)
3e3498cf03,quantization,[quant][graphmode] torch.clamp (#36887)
191fa528f5,skip,Rebase xla job on top master before running CI build. (#36852)
25eb250d77,complex_frontend,"Added complex dtypes to get_all_math_dtypes, complex acc type for cpu, fixed rdiv and pow for complex (#36747)"
28fadfc4eb,performance_frontend,Reduce overheads on several CPU kernels by avoiding restrides. (#36875)
3b832ee2bf,misc,Use Python3 `super()` throughout `torch.testing.` (#37024)
a894fff265,dispatcher,"Back out ""Revert D21089648: Put TORCH_LIBRARY in torch/library.h; add custom class API"""
e75fb4356b,skip,Remove (most) Python 2 support from Python code (#35615)
7c9e7ef128,skip,Revert D21171747: [pytorch][PR] Rebase xla job on top master before running CI build.
e7a72bb0c6,caffe2,Add nomnigraph include folder to `Caffe2_GPU_INCLUDE` (#37056)
a00d6758b8,th_aten_frontend,Migrate `cosh` and `cosh_` from TH to ATen (CUDA) (#36654)
9b0e7ebab0,mobile,[iOS] 1.5.0 Cocoapods Release (#37039)
3580c93716,rpc,[autograd] Demote the dist container shard line to VLOG(1) (#36978)
171476e870,caffe2,CUDA implementation of Sparse Adagrad Fusion for GPUs (#35762)
cf77e56938,skip,clang-format don't run on master (#37058)
5710f278a1,skip,ci: Change file_diff_from_base to be dynamic (#36260)
8a6ab004f7,build_frontend,Dockerfile: Update miniconda installer download location & remove unnecessary flag (#37082)
b0ee6c70aa,mobile,Remove register_mobile_ops.cpp (#37035)
7bd2014eec,rpc,[resubmit][rpc] per-RPC timeouts for rpc_sync and rpc_async (#34650)
76cb7f2043,build_frontend,Use filelist from build_variables.bzl to fetch distributed file list (#37090)
73bffeff62,skip,scripts: Distinguish between platforms in conda promote (#37089)
5fc391a646,bug_fixes_frontend,Enforce type promotion in `torch.cat` (#35030)
e921cd222a,build_frontend,Move bulky constants from SobolEngineOpsUtil.h to .cpp file (#37086)
78d5707041,improvements_frontend,Fix type annotations and make MyPy run on torch/ (#36584)
efcbcca454,complex_frontend,"Revert D21138687: [pytorch][PR] Added complex dtypes to get_all_math_dtypes, complex acc type for cpu, fixed rdiv and pow for complex"
8d6a8d2b3f,InLastRelease,Fix DDP bug in single process multiple device use cases (#36503)
baaa0943f1,build_frontend,"Update third_party/cpuinfo to include a fix for conda builds, older kernels (#37083)"
6fcabf619d,distributions,[takeover] BTRS algorithm for fast/efficient binomial sampling (#36858)
2773ed3082,quantization,hardswish: remove unnecessary quantize call (#36980)
7f50162d1e,quantization,quantized activations: clean up more unneeded quantizations (#36981)
de090c42b1,build_frontend,Optimize binary size of assert macros (#37023)
4ab46f6baf,skip,[pytorch] Delete unneeded scripts
e557b7cec2,jit,Kill BC hack in torchbind (#37112)
d0291df7d9,skip,[resubmit] Rebase xla job on top master before running CI build. (#37085)
ca665c682c,build_frontend,Separate RTLD_GLOBAL from _load_global_deps() (#36682)
7c7cb74887,complex_frontend,Add missing ${CMAKE_CURRENT_SOURCE_DIR}/complex_test.cpp (#37080)
45706bf6d8,skip,properly whitelist clang-format in CI (#37122)
f771c96852,complex_frontend,Returns float from complex angle (#36896)
f46231a2f4,skip,Revert D21144940: [pytorch][PR] ci: Change file_diff_from_base to be dynamic
355cafde26,amd,[ROCm] Don't use MIOpen for tensors with more than INT_MAX number of elements (#37110)
b889e0da8a,skip,[torch] Excluding test_fft_input_modification without MKL (#36680)
50a1850d8d,skip,[pytorch] Route default warning sync to LOG(WARNING) - second try (#36984)
0dd21c3b72,skip,Lets @dtypes take tuples of dtypes (#36908)
a38c6e0454,skip,Migrate addmv and mv from legacy to ATen native (CUDA & CPU) (#30898)
11cef0fe88,skip,Update cusparse deprecated Xcsrmm2 call (#36845)
b3f04a398a,jit,Re-enable JIT test `test_class_sorting` (#37140)
3880f14b64,skip,"Canonicalize includes in torch, and add tests for it (#36303)"
9763db3031,distributed,`MultiProcessTestCase` to use instance rather than class method wrappers (#36826)
3799d1d74a,docs_frontend,Fix many doc issues (#37099)
f11df2d2b4,bug_fixes_frontend,Use temporary variable to store input parameters in loop. (#36288)
ab2a9ab925,misc,Non-blocking SyncBatchNorm update (#36659)
230b68168b,quantization,[quant] Refactor test files (#36964)
438aed63a1,bug_fixes_frontend,Fix prelu_backward TensorIterator split (#36134)
c306f2ed08,skip,Revert D20660338: [pytorch][PR] Migrate addmv and mv from legacy to ATen native (CUDA & CPU)
ebfe631ed8,jit,[TensorExpr] Cleanup TensorExprKernel class and add CPP tests for it. (#36952)
006f1a32f8,mobile,Mobile CPU allocator. (#36032)
7aec364bdf,bug_fixes_frontend,extend gather shape check to handle incorrectly sized outputs (#37102)
e98cdfa26f,th_aten_frontend,Migrate `tanh` from TH to ATen (CUDA) (#36995)
72f80b5247,mobile,Enable stateless XNNPACK convolutions. (#35790)
ba3f8d35e0,mobile,Enable stateless XNNPACK linear. (#35791)
c4b9f3bf55,skip,Enable torch_speed_benchmark to accept different memory formats. (#36202)
989341c0c6,distributed,Add comments to explain how MultiProcessTestCase works (#37179)
fd5b5cd604,jit,Allowing casting str to int in JIT (#36016)
35f7945828,skip,Revert D21196366: [pytorch][PR] Update cusparse deprecated Xcsrmm2 call
05e98149ae,distributed,Refactor lambda post hook. (#37025)
ff21b15624,build_frontend,"cmake: add USE_SYSTEM_{LIBS,CPUINFO,SLEEF} options (#14699) (#37137)"
070dea2d7e,skip,Updating submodules
3ff892febb,performance_frontend,Remove redundant definition of fmadd functions in complex Vec256 (#37167)
a633c2d112,rpc,Fix const-cast lint error in process_group_agent.cpp (#37184)
827f04a075,rpc,Supporting create an RPC gang of size 1 (#32731)
fba9b9a023,skip,[PyTorch Numeric Suite] Add module level comparison (#36669)
35b9c89dc1,skip,Revert D21045393: [PyTorch Numeric Suite] Add module level comparison
a50a1fb4c3,skip,Enforce kw-only args now that py2 is unsupported (#37069)
8254a63802,quantization,Speed up calculate Qparams for per-channel observers (#30485)
77abb6938e,jit,Port register_string_ops.cpp to new operator registration API (#37008)
385165ec67,quantization,[reland][quant] QuantizedCUDA implementation (#36936) (#37081)
cae77fa351,docs_frontend,[doc] Fix broken links in the TOC of CONTRIBUTING.md (#37131)
6ac0f67699,caffe2,[C2] Optimize MulGradient Operator when inner_size is 1 (#36767)
20328f67bb,complex_frontend,Add core of c10::complex [resubmit] (#36626)
5a27ec09b8,new_features_frontend,Add Inverse Short Time Fourier Transform in ATen native (#35569)
af08334c63,skip,better local command for clang-format check (#37127)
1beca4ac6a,misc,Prerequisites for CSPRNG (#36631)
6e92579883,complex_frontend,Added autograd support for C->C functions and enabled requires_grad=True for complex (#36932)
93cd05b0f4,build_frontend,Fix CMake errors on systems where {Q/X}NNPACK is not supported (#35607)
fc528ccbaf,dispatcher,[wip] Allow ArrayRef as kernel parameter (#34335)
deefafb01d,dispatcher,Allow std::array as operator argument and return (#34399)
2baff9476e,skip,Test test_is_nonzero make expected exception inline (#37128)
9f02897431,mobile,Account for the change in optimizeForMobile API change.
a13b5b0ae8,skip,Split reduction compile units (#37205)
5362a0b948,jit,[jit] fix lifting bug in tracing module calls (#37189)
c38dcd45d7,jit,[jit] fix return different types bug in tracing module calls (#37190)
4f3946a89b,complex_frontend,"Added complex dtypes to get_all_math_dtypes, complex acc type for cpu, fixed rdiv and pow for complex (#37193)"
d6ce6570f9,skip,Remove unused imports in aten/src/ATen/function_wrapper.py (#37245)
b6bb644e41,jit,Fix long line splitting issue in python_print (#37088)
047488a7ff,dispatcher,Mask all high dispatch keys in BackendSelect kernels (#37257)
b60c3dfdd9,profiler,Add fallback wrapper for profiler (#37194)
521910e0e9,skip,Update clang_format_ci.sh (#37268)
47c4dca1ab,skip,Remove python-2 or python<3.5 checks from unit tests (#37252)
1f08ff12ec,jit,[jit] fix named tuples as attributes (#37251)
1d8012a624,dispatcher,Delete dead code (#37254)
1d0334dd62,build_frontend,Add cpu build and test to Windows CI (#37135)
4a72ddedcd,build_frontend,Show cpu info for macos jobs (#37220)
686b521784,misc,Update cusparse deprecated Xcsrmm2 call (#37202)
a80a438e37,jit,correctly set and restore states in te tests (#37210)
ef9ec03e77,misc,[CUDA11] Pytorch change (#37187)
904949382e,quantization,Ensure that histogram observers have zero-point of zero for post ReLU activations (#37107)
30eb0bdf32,build_frontend,"Do not define list ""0"" in torch/CMakeLists.txt (#37275)"
6ea2aedab9,skip,Cast shape_.size() to int64_t before comparing with squash_dim (#37109)
4e976b9334,dispatcher,Remove callBoxedWorkaround (#36850)
6e659e928b,skip,Enable global observers API (#37195)
e6231c9e24,skip,Do not run valgrind on the Aten unit tests compiled with clang (#37152)
856e8cf028,skip,Revert D21213786: Enable global observers API
d7f7c290e3,th_aten_frontend,addmv migration [resubmit] (#37236)
6e1e55c134,rpc,Prevent RRef unpickle to block waiting for OwnerRRef creation (#36785)
269ec9a139,rpc,Prevent RRef.to_here() to block an RPC thread on the callee using Future callbacks (#36805)
3d934c3d36,rpc,Add using torch::utils::Future to simplify code in RRefContext (#36811)
c52deb694e,rpc,Consolidate usage on torch::jit::toPyObject in RPC request_callback (#37249)
04b36fc264,jit,[TensorExpr] rfactor implementation (#36237)
f5e6f1f333,skip,if_constexpr for C++14 (#31091)
b18f57e548,skip,Boxing uses if_constexpr instead of SFINAE (#31092)
cb27067b32,onnx,[ONNX] Remove inverse op (#37005)
44345ad08c,skip,Do not define C10_IOS on Mac (#37283)
ea741f829e,skip,Add `--repeat` option to python unit-test (#37281)
c90955e3d1,profiler,[profiler] Sort by end interval as well when parsing CPU trace (#37297)
84a31fb4e7,skip,Revert D18927221: Boxing uses if_constexpr instead of SFINAE
34284c1279,skip,"Fix NaN error in dynamic quantization in qLinear, re-enable test_quantized_rnn (#36009)"
bf860a4eba,docs_frontend,Adds missing documentation . (#37295)
59052e39b8,quantization,[quant] qtensor resize (#36442)
a04022c656,profiler,Use `std::chrono::high_resolution_clock` for profiling on Mac (#37280)
ca39f99d48,quantization,[Pytorch Numeric Suite] Add module level comparison (#37242)
205c6ffbc5,quantization,[quant] Generalizing _calculate_dynamic_qparams in quantized test (#36449)
92e91cee8d,onnx,ONNX Export Support for CrossEntropyLoss (#34830)
7604f470ed,caffe2,Add weight info in debug_ssa_net (#37262)
b198796a28,quantization,[quant] quantized reflection_pad1d (#36450)
d98ea604f4,rpc,Improve Error Message for Dist Autograd Context Cleanup Failure (#37255)
2b050371b4,rpc,Make listenLoopInternal non-virtual (#37265)
f8ec51bd86,distributed,Ensure DataParallel replicas can be saved (#37307)
b64fc3c4b5,improvements_frontend,Changes warnings generated in cpp to show point of Python origination (#36052)
b428f454e1,skip,Revert D18927220: if_constexpr for C++14
47fec01c45,InLastRelease,Fix cpp extension compile failure on some envs (#37221)
ed9ec3c96f,rpc,[autograd] refactor some functions (#37061)
f41742ff2f,rpc,[autograd] remove spinning for dist engine (#36606)
828d590b06,amd,[ROCm] Update to ROCm 3.3 (#37247)
22ac071d9a,new_features_frontend,Add SWA to PyTorch mainline (#35032)
007163407c,build_frontend,"[cmake] Support ""Generic"" BLAS (#14699) (#37276)"
3a0ff3cd2f,build_frontend,Generate environment restore script for Windows build jobs (#37319)
5b9f7f7b0e,build_frontend,"[cmake] Add USE_SYSTEM_{GLOO,FP16,PTHREADPOOL,PSIMD,FXDIV,BENCHMARK} options (#14699) (#37277)"
5c9d1e4824,mobile,Propagate module lints for mobile scripted module. (#37046)
a08a9f3b82,improvements_frontend,Enable uint8 upsampling 2 (#35029)
6d409481b3,complex_frontend,Add overloads of std:: math functions for c10::complex (#35725)
0048243f70,cpp,Check compiler -v to determine compiler (fix #33701) (#37293)
ec8006cc16,onnx,[ONNX] fix provider_version and add consistency test (#36797)
805c417ec9,memory_format_frontend,Implement avg_pool2d kernel for channels_last (#35855)
201ba13911,mobile,Correct $ANDROID_HOME string empty check (#37064)
045c588bc6,dispatcher,Enable use_c10_dispatcher: full for some more ops (#37273)
af9c3a3652,caffe2,uniform_int_distribution does not support uint8_t (#37260)
d167a7f654,complex_frontend,Revert D21256854: [pytorch][PR] Add overloads of std:: math functions for c10::complex
e49ccdf211,jit,[TensorExpr] Add IRPrinter::visit for AtomicAdd. (#37304)
e8421807d8,jit,[TensorExpr] Fix indendation in CudaPrinter. (#37305)
c4401ea9ab,quantization,Make test_quantize runnable (#37357)
e33c3e49d5,caffe2,Fix hard-code cmake target (#37310)
5fab4c30dd,skip,[resubmit] Enable global observers API (#37292)
f07b85b6a6,quantization,Revert D20984967: [quant] quantized reflection_pad1d
f463586739,quantization,Revert D20984966: [quant] Generalizing _calculate_dynamic_qparams in quantized test
8dc5502cb1,build_frontend,Do not add special `CUDNN` search path rules for `torch_python` (#37349)
023c3575f0,skip,[doc] Fix JIT code highlighting (#37338)
16f4501cd4,docs_frontend,Improve checkpoint docs to warn users about detached gradient issues (#37266)
b3ada29584,skip,Skip test_profiler_custom_op on ROCm (#37374)
1039b95ff0,docs_frontend,[autograd] add documentation about multithread autograd (#37020)
d294c06287,build_frontend,Fetch TORCH_PYTHON_SRCS filelists from build_variables (#37267)
20143e5f27,skip,Revert D21245094: [resubmit] Enable global observers API
b8ec165c0d,skip,Fix failing test in test_torch.py (#37362)
ed0a572eed,th_aten_frontend,Migrate `scatter` and `scatter_` from the TH to Aten (CUDA) (#35697)
cf41f6bed1,profiler,Fix record_function (#37364)
fae87908d9,skip,"Back out ""Fix NaN error in dynamic quantization in qLinear, re-enable test_quantized_rnn"""
f1e89fbe53,quantization,[pytorch] add missing host-device attribute to fix clang build (#37358)
a4383266f0,skip,Revert D21262421: [pytorch][PR] [doc] Fix JIT code highlighting
5a59bbc1da,jit,[TensorExpr] IRPrinter: show output_args separate from reduce_args when printing ReduceOp. (#37367)
4ff4119d45,rpc,[rpc] Move _set_rpc_backand and RpcBackendOptions to use float instead of timedelta (#37027)
da64ed14f6,profiler,Reduce volume of spammy warning (#37360)
48b126f496,caffe2,[caffe2] Fast path for single tensor in UnPackRecordsOp (#37361)
b37080d97a,profiler,remove record_function_enter and record_function_exit from header (#37052)
ebcacd5e87,build_frontend,[Bazel] Build `ATen_CPU_AVX2` lib with AVX2 arch flags enabled (#37381)
8fe2a5e91b,bug_fixes_frontend,Fixes type annotations for named tensors #27846 (#36890)
c5d6f59ab1,performance_frontend,Replacing EHa with EHsc (#37235)
4234d62489,build_frontend,[hotfix] Workaround for older versions of ninja (#37417)
d068a456d3,quantization,[resubmit] Enable global observers API (#37382)
a51f047c7e,bug_fixes_frontend,Synchronize MAGMA functions with the current CUDA stream (#36605)
580928801f,onnx,[ONNX] Adding 'numel' and 'to' export for script module (#36501)
d1a39815f9,skip,Remove Python 2 string compatibility in ATen/function_wrapper.py (#37388)
5b6f6da18c,caffe2,[caffe2] Copy tensor in single tensor input case in UnPackRecordsOp (#37454)
024f663fc1,quantization,"Resubmit ""Fix NaN error in dynamic quantization in qLinear, re-enable test_quantized_rnn"""" (#37458)"
239ce75a74,quantization,[quant] Generalizing _calculate_dynamic_qparams in quantized test (#37451)
e0a5b443d6,skip,[pytorch] remove unused flags from code analyzer & move format support to python (#37393)
8258d42bd0,skip,[pytorch] add '__BASE__' section to op deps to factor out frequently used util ops (#37404)
6c0f447b51,onnx,Remove ONNX BatchNorm(12) test and converter. (#37309)
dcd8a1b399,quantization,Revert D21286660: [quant] Generalizing _calculate_dynamic_qparams in quantized test
273c464145,bug_fixes_frontend,Fix `TensorIterator::view_offsets_` size (#37214)
e5a24a6389,skip,Retry anaconda upload (#37414)
6fa76b8a0c,jit,[jit] __deepcopy__ for `RecursiveScriptModule` (#32684)
edc5ef1afb,InLastRelease,"run the simple executor for jit tests by default, add profiling jobs … (#37017)"
12f5a32863,InLastRelease,Don't use NonVariableTypeMode in custom ops (#37355)
07bb442b24,build_frontend,Move DistributonTemplates to anonymous namespace (#37429)
92b9089fd9,jit,[jit] Fix pretty printing of functions (#37432)
e55d2e6fa6,quantization,[quant][graph] Add check for qconfig_dict key (#37014)
9dab3ed5c6,quantization,[graph][quant] Enable accessing child/grandchild modules in forward (#37045)
3b9ddab093,quantization,[quant][graph] Run dynamic quantization for specific ops (#37093)
e69115ec52,quantization,[quant][graph] Add JIT passes for dynamic quant multi uses of quant node (#37125)
facdd15cc6,quantization,[quant] Finishing refactor for quantization test files (#37366)
21b7af1e7b,InLastRelease,allow inplace leaky_relu backward calc when slope == 0 (#37453)
74c00b1f69,build_frontend,move to explicit avx2 switching (#37207)
fd4a09ea73,quantization,[WIP] Bind in CellParams for RNN (#35787)
4e3dc34c47,complex_frontend,add complex support to `reciprocal_cuda` kernel (#36749)
0c3a6f941f,jit,disable peephole optimizations that require alias db (#36757)
92129956cf,jit,Add size peephole optimziation (#36758)
cdc0880632,jit,add post unroll optimizations (#36828)
c516f84525,jit,[JIT] Add Lower Tuples Call & Run remove mutation after list unrolling (#36829)
cde1350a5d,jit,Add support for generic list constants (#36953)
45e8451b33,jit,optimize is_float_point calls (#37012)
a55d80e1c5,jit,[JIT] remove dominated guards of functional values (#37105)
4bfa51d405,skip,[jit] fix trace checking reporting divergent names (#37464)
bf53784e3c,misc,Treat cross-execution-space-call as errors for NVCC on Windows (#37302)
1b525f88ce,jit,Print all ops in model converter
253943d5a7,misc,Remove thrust_t from remainder_kernel_cuda (#37470)
ce6077d7a8,distributions,Move log_normal_() to DistributionTemplates (#37392)
06168bf17d,distributions,Move geometric_() to DistributionTemplates (#37418)
ec8517b6df,distributions,Move exponential_() to DistributionTemplates (#37456)
9259a283b7,build_frontend,use detected python version to find pylibs (#34041)
6176931695,mobile,Disable stateless xnnpack for ios. (#37460)
d37a4861b8,bug_fixes_frontend,Explicit attribute setting for pruning and weight_norm upon reparam removal (#34170)
68895eda9d,skip,"add fmt, take 7 (#37356)"
0d9e3b48c4,skip,Remove THCudaMemGetInfo. Use c10's cacheInfo instead. (#37447)
58a46a174e,build_frontend,"[cmake] add USE_SYSTEM_{XNNPACK,ONNX} options. (#37501)"
bbd2350c99,skip,Disable tests failing on test2 in ROCm CI (#37427)
1bb66a0cd4,improvements_frontend,Extend some of the basic ops to kHalf (#37121)
bbf29a5239,skip,Implement cusparse Descriptor class and clean up cusparse code (#37389)
867e05921f,improvements_frontend,Fix multiple issues with type annotations (#36358)
a3ab560f6c,dispatcher,Port xnnpack operators to new registration API (#36800)
9e97e9244f,mobile,Fix mobile type resolution in unpickling (#37425)
ec5fb29b96,jit,Add overload names to dict operators. (#37279)
297cc5512e,quantization,[quant] Enable convolution tests (#37494)
f7dce8508c,skip,Revert D21302691: [pytorch][PR] Implement cusparse Descriptor class and clean up cusparse code
bca82801e7,new_features_frontend,add support for generating Vandermonde matrices (#36725)
6098cf7e33,skip,Add `sched_setaffinity` check from libgomp to `valgrind.sup` (#37532)
7e9cc4df85,th_aten_frontend,Migrate `cos` and `cos_` from TH to ATen (CUDA) (#36653)
f1cd0eeb70,build_frontend,`IValue(bool)` constructor should initialize entire payload (#37513)
896f8130a6,skip,Revert D21297549: [jit] fix trace checking reporting divergent names
5bb9357345,bug_fixes_frontend,Update assertion in MHA forward to support FP16 training (#37539)
1ef992639d,complex_frontend,Make c10::complex the C++ type for complex tensors (#37421)
d5363e6499,onnx,Set onnx opset version before model select (#37466)
e9db51f9af,quantization,Enable float requantization for avgpool/gavgpool ops. (#37037)
d5b38984c8,rpc,Let RPC return FutureIValue instead of FutureMessage (#37519)
322e564ee3,rpc,Minor format cleanup in py_rref.cpp (#37520)
b48239af3c,rpc,Cleanup internal functions in python_functions.cpp (#37536)
b33b46a950,quantization,[quant] Enable qnnpack tests for test_quantize and test_numeric_suite (#37351)
400098d492,quantization,graph mode: add hardtanh op (#37469)
6cdc8cac47,quantization,graph mode: add elu op (#37521)
11b6f70f7d,quantization,graph mode: add hardsigmoid op (#37522)
7ac98c9396,quantization,graph mode: refactor quantized hardswish API for easier graph handling (#37523)
4e7403c286,quantization,graph mode: add hardswish op (#37524)
a961d3acf3,quantization,graph mode: add handling for layer_norm op (#37525)
482d1f4b8c,quantization,[quant][graphmode] fix observer instance copy (#37185)
a0075c4825,mobile,[XNNPACK] Disable xnnpack ops for both iOS and macOS (#37528)
eb5590d6f4,skip,Updating submodules
091a1192d7,jit,[JIT] Convert float Tensor argument to double in prim::tolist (#37465)
ac5403f22e,quantization,[quant] Check qengine for TestNormalization (#37562)
9d0891f886,skip,[pytorch][buck] tweak code analyzer e2e script
68250fa557,build_frontend,Vanilla Pytorch bionic clang9 test in CI (#36711)
6792bafa72,mobile,[pytorch] aten codegen to filter backends for default mobile build
4c8636c74c,build_frontend,Unify the path for environment restore script (#37486)
69e2f1aaff,build_frontend,[cmake] add HAVE_SOVERSION option (default=OFF). (#37502)
f09eb391b9,skip,Move masked_select broadcasting from codegen layer to native layer. (#37543)
5bb01568c3,quantization,speed up and re-enable quantized bn unit tests (#37420)
e9db16e0c1,skip,[Reland] Implement cusparse Descriptor class and clean up cusparse code (#37533)
c5624e831d,complex_frontend,Add overloads of std:: math functions for c10::complex [resubmit] (#37468)
149b468ce2,visualization,[TensorBoard] Fixes missing doc for add_graph (#37504)
d3d10cc14a,jit,Add tests for lower_graph and fix unpack() ops dispatch (#37540)
20ba29d81c,jit,Add support for reductions on CPU in tensorexpr (#37333)
b97341e3dd,skip,[c2][opt] nomnigraph transform for ClipRangesGatherSigridHash fusion (#37535)
8a30553738,rpc,[TensorPipe/RPC] Add TensorPipe dependency (#36695)
287f3b746e,skip,Remove Backend -> THPLayout mapping. (#37527)
13013848d5,bug_fixes_frontend,Fix cpp_ext build dir create permission (#34239)
3e1859959a,skip,Updating submodules
2c33ea1c47,docs_frontend,[doc] improve tensor.view doc (#36728)
cd48fb5030,performance_frontend,Vectorize linspace on CPU. (#27957)
1aedc2c5b9,caffe2,Skip c2 ref onnx model tests (#37591)
6f8838cd2f,skip,Revert D21326386: [pytorch][PR] [Reland] Implement cusparse Descriptor class and clean up cusparse code
cd4c3b48a6,caffe2,Add LN after specialzied output embeddings and flexible LCE (#35178)
e98ad6c05b,improvements_frontend,[RELAND] Remove patches that circumvent MAGMA bug (#35973)
5efd10518f,jit,[jit] speed up alias analysis (#36345)
e841bea465,quantization,[quant] QNNPACK Add deconvolution parameters (#36716)
20f5d4436e,skip,Updating submodules
a09cb5f2f5,quantization,[quant] quantized reflection_pad1d (#37452)
bedc50ed07,skip,Ensure we are diffing against the right thing in clang-format (#37589)
5ab36ec98b,distributions,Move cauchy_() to DistributionTemplates (#37602)
7c4bda7e6f,cpp,Eliminate warnings for cpp extensions on Windows (#37400)
91e74fd843,jit,[JIT] Adds a `code_with_constants` method to module printing (#37586)
0692804747,InLastRelease,add slope == 0 case into standard leaky relu nn test (#37559)
9e32a1f5cd,jit,[wip] update graph fuser aliasdb in-place (#37106)
4ed790d742,jit,"Adding symbolic sizes, contiguity, stride indices (#36101)"
e852b45d9f,complex_frontend,Overload c10::complex operators inside c10 namespace (#37605)
f6c82e04a0,quantization,Move to using MemoryFormat::ChannelsLast for avgpool2d. (#36812)
6de949afaf,quantization,Add quantized adaptive avgpool. (#36813)
1510bdd42d,quantization,Replace empty_affine_quantizer with new_qtensor_cpu. (#36814)
df31ddbd98,quantization,Add channel shuffle op fp32 + quantized. (#36815)
22708be5af,th_aten_frontend,Migrate `tan` from TH to ATen (CUDA) (#36906)
ecf1ea75a7,complex_frontend,Make c10::ComplexHalf a template specialization of c10::complex (#37426)
6ecb5bb1f0,jit,match old fuser rem to eager (#37196)
deb4100928,distributed,[DistributedSampler] Only create torch.generator and seed when shuffling (#37604)
1f09f7ea44,complex_frontend,Python API for Complex Storage and storage copy logic (#35771)
c0a985fcd6,rpc,Allow customizing retryable message types in Faulty agent tests (#37450)
675b3fc834,improvements_frontend,Prevent unbounded growth of sparse tensor in add operation (#36030)
ba5137ea9d,skip,[pyper] Use Caffe2 ops
49c8a37a0d,rpc,Fix doc-gen warnings in RPC (#37666)
ba7461c135,rpc,Add pointer to RPC parameter server tutorial (#37667)
b410d03e6e,skip,"Back out ""[c2][opt] nomnigraph transform for ClipRangesGatherSigridHash fusion"" (#37675)"
831c8f362f,jit,fix the incorrect merge of profiling information of two tensor types for the same value (#36806)
b1790794f6,bc_breaking_frontend,Enforce Tensor.random_ check that from and to are in tensor dtype bounds (#37507)
2658bae570,distributed,use std::move (#34365)
95465dcbaf,bug_fixes_frontend,autograd: move scalar input to a different device when needed (#35286)
fa8ab4b80c,quantization,[pt][quant] Unify numerics between fakequant and quant/dequant (#37188)
099a84ef9b,mobile,Add overload name for aten::tensor and aten::as_tensor (#37655)
fbf110293d,jit,jit/OVERVIEW.md: screen * in 'Node*' for proper rendering. (#37686)
564de515f5,jit,Add an iterator to Block. (#37542)
ae755a73d3,distributed,SyncBatchNorm size check update (#37133)
b4d486abbc,distributed,Enable test_DistributedDataParallel_SyncBatchNorm_2D_Input unit test (#33573)
5e0a24f1f9,quantization,[quant][graphmode] Move numerics changing passes before finalize (#37514)
707e0e86c0,skip,[WIP] retry apt at individual package level and at command level (#37696)
d639418307,rpc,Add timeout injection to faulty agent for testing (#37485)
5baa6b6c34,build_frontend,Add a Bazel build config for TensorPipe (#37691)
cc0f1b22a2,quantization,[PyTorch Numeric Suite] Add module output comparison (#36701)
8cb1f2f9dc,caffe2,implement L2 regularization for Adagrad in caffe2 and dper (#37705)
3403d27def,caffe2,[caffe2] L2 regularization for fused sparse Adagrad (#37652)
506ae60547,caffe2,[caffe2] L2 regularization for rowwise fused sparse adagrad (#37653)
ffed77d0c8,skip,Updating submodules
843c0230f2,skip,Add ops for portal NLU model (#37192)
bd9617d5af,caffe2,[TVM] Implement UnPackRecordsOp (#37489)
e26631b333,caffe2,[caffe2] Shape inference for UnPackRecords
6a6c29c1c9,rpc,Update TensorPipe submodule (#37729)
136bc5a482,skip,Revert D21215050: Add ops for portal NLU model
6c37ad2674,docs_frontend,typo in MultiheadAttention documentation (#37496)
bcdff7eb67,amd,Fix for tests on ROCm (#37616)
66a20c259b,build_frontend,[CircleCI] Store build artifacts for python docs (#37658)
5ec87a3c1a,skip,Move baddbmm broadcasting from codegen layer to native layer. (#37544)
b1e4e4d470,bug_fixes_frontend,Remove zero_dim_dispatch_when_scalar (#37580)
f10fbcc820,docs_frontend,Split up documentation into subpages and clean up some warnings (#37419)
aa54f58041,jit,LoopOptions::gpu_block_index(): bool -> int (#37578)
5216917022,caffe2,[caffe2/dnnlowp] documentation for pack operator arguments (#37719)
b7f258bbd3,build_frontend,add fmt to libtorch_python.so (#37560)
dbcfd62a1c,rpc,Remove unnecessary pickle and unpickle invocation in PyRRef __setstate__/__getstate__ methods (#37638)
e6221f4ca1,complex_frontend,Remove std::complex from TypeMeta (#37632)
812a3fa03d,improvements_frontend,"Show warning if Tensor.random_()'s from and to are not in [-(2^digits), 2^digits] bounds for floating-point types (#37537)"
fd05debbcd,skip,[TS][easy] Typo Fix (#37773)
20f7e62b1d,docs_frontend,Revert D21337640: [pytorch][PR] Split up documentation into subpages and clean up some warnings
c0ff085775,cpp,[PyTorch] Modify `data_parallel` to work with small tensors (#37704)
1bac49f075,complex_frontend,Migrate item() to c10::complex (#37648)
6dd1beaaa8,caffe2,To fix caffe2 model with Copy OP cannot export to onnx model (#37144)
efd8f70cac,cpp,Make msg() and msg_with_backtrace() private (#37094)
a058e938f9,cpp,"Refactor error msg stack handling, add TORCH_RETHROW (#37101)"
77dd00c850,jit,"Permit registration of multiple triggers, but insert warning (#37772)"
a6aa336cc2,quantization,[quant][graph] Fix bug in replaceConvolutionWithConv2d (#37635)
fe8fdb775f,quantization,[quant][graph] Fix bug in replicateDequant (#37637)
4cdaa5956c,jit,capitalize fuseTensorExpr (#37780)
e38d7591a7,skip,"Move broadcasting code for fmod, fmod_ from codegen layer. (#37545)"
73aa49d529,skip,Move addr broadcasting from codegen layer to native layer. (#37546)
4025d87843,skip,Kill the ability to codegen tensor-based broadcasting. (#37547)
4fef3763dd,docs_frontend,"Revert ""Revert D21337640: [pytorch][PR] Split up documentation into subpages and clean up some warnings"" (#37778)"
0a24f33dc1,quantization,[quant][mobile] Return for conv with empty batch (#37779)
20e5749129,complex_frontend,Migrate CPU casting copy kernel to c10::complex (#37649)
57dc4cd0f8,distributed,[MultiProcessTestCase] Improve the error message when a process terminates (#37627)
804e32a467,jit,split out docs tests into separate job (#37793)
d16c8238e1,onnx,[ONNX] Fix numerical errors in softmax when dim is not last dimension (#37326)
0c2a72ec41,docs_frontend,Update README to include few (missing?) links (#37714)
209c6f9ab5,dispatcher,Move device type init from BackendSelect to backend kernels (#37402)
53ca3e5b9c,complex_frontend,"Migrate CUDA cat, scatter, gather, index, index_put to c10::complex (#37650)"
847d102e93,docs_frontend,docs: Fixed docstring indentation for documentation (#37739)
1d43d7caa2,quantization,Use `gpu_kernel` in Affine Quantizer (#37312)
8e5f162b4c,caffe2,[FakeLowp] Reset workspace in test (#37799)
090ea775c9,complex_frontend,Math functions of c10::complex should be overloaded as const reference (#37689)
4a2c642e1f,caffe2,fix ROCm bench CI by increasing first iter timeout (#37633)
1845545075,amd,Enable HgemmBatched for ROCm (#37483)
15df33f797,caffe2,[Onnxifi] Cache output shape inference result for OnnxifiOp (#37796)
f5e6f39e00,complex_frontend,Remove std::complex to std::complex casting specialization (#37574)
faad00a290,quantization,add qnnpack path for hardtanh (#35779)
aff92ef3d6,skip,Make a separate cmake option for caffe2 tests (#37721)
458134f021,jit,Add several ops for portal NLU/ASR model (again) (#37801)
429d90f648,build_frontend,[BE] Split pytorch_linux_test into 3 steps (#37808)
7fa897eac0,caffe2,[caffe2] L2 regularization for (RowWise)SparseAdagrad fusion on GPUs (#37805)
3411ec6e32,rpc,[TensorPipe/RPC] Serialize and deserialize message (#36197)
0549e1f384,rpc,[Tensorpipe/RPC] tensorpipe RPC agent (#35483)
d4edbbd396,build_frontend,Revert D21369541: Make a separate cmake option for caffe2 tests
16c7907ad0,complex_frontend,Migrate CUDA fill kernel to c10::complex (#37651)
6133be31bd,bug_fixes_frontend,Fix for hooks with no name (#37785)
7c2944899b,complex_frontend,Add vec256 for c10::complex (#37690)
51c9444274,distributed,Enable test_distributed test test_backend_full_group (#37794)
d7ccb4b392,complex_frontend,Migrate CUDA unary complex kernel to c10::complex (#37647)
468a9d448e,performance_frontend,"[aten] Pass std::function<> to thread_pool by value, instead of const ref. (#37681)"
12e64916b3,th_aten_frontend,Migrate clamp from the TH to Aten (CUDA) (#37646)
23d0441da7,jit,[JIT] Fix GetAttr inconsistency (#37424)
145560f499,th_aten_frontend,Migrate `erf` and `erf_` from the TH to Aten (CUDA) : Closes #24558 (#36724)
0b693e9601,performance_frontend,uninitialize output and bag_size in the fast path of EmbeddingBag to save overhead (#36681)
b354700e75,quantization,graph mode: round out relu support (#37592)
3673a7245d,quantization,graph mode: more in-place activation handling (#37771)
3b97723f08,improvements_frontend,Let >> and << support half on CUDA (#37670)
5c628ddbd0,docs_frontend,Fix README for installation from source (#37301)
7fa968b10d,jit,[TensorExpr] Add python bindings for TE fuser. (#37831)
9b3911c073,quantization,[quant][graphmode][refactor] rename SwapDequant and refactor code handling general ops (#37555)
782b53b654,skip,Specify _th_ ops in CUDAUnaryOps macros so they are easier to find. (#37582)
5b0244ee8f,jit,Tighten error checking in ConcreteModuleType (#37813)
08304ccccc,jit,add a cuda job for profiling tests (#37812)
25e6129c52,quantization,quant BN tests: remove qint32 (#37832)
b57c8b720e,quantization,[wip] Make quantization modules work with DataParallel (#37032)
9d7a79ac27,caffe2,[Caffe2] raise exceptions instead of str (#37744)
bd220b336b,jit,[jit] fix trace checking reporting divergent names (#37842)
65291fd422,rpc,Remove unused capture in tensorpipe_agent.cpp (#37828)
06e1b68843,skip,[BE] Add @skipIfNoFBGEMM decorator (#37810)
25ba802ce4,bug_fixes_frontend,Fix `cdist` backward calculation for `p=2` (#37337)
3706803b60,skip,Change StorageImpl to track byte count rather than element count (#37776)
a3639fa516,rpc,[Tensorpipe Agent] Adding Tensorpipe Codeowners (#37854)
2c6aed0d61,skip,[Testing] Add `--save-xml` option (#37840)
1c0bad25f3,jit,[TensorExpr] Add dtype to class Buf. (#36611)
27fc2ab9f4,jit,[TensorExpr] Add a constructor accepting a name_hint to class Buf. (#36617)
4c009c7f3e,misc,Make aten_tensor_iterator ASAN safe (#37869)
5325606c37,performance_frontend,Add zero_mask() for Vec256<BFloat16> (#37114)
30a65f1afa,rpc,[Tensorpipe Agent] Call Shutdown from Destructor and Join (#37839)
b57d82fcbb,skip,workaround nvcc host function bug (#37867)
b61fda2313,quantization,reenable quantized test_compare_tensor_scalar (#37422)
0cae718723,quantization,reenable quantization test_qadd_scalar_relu test (#37423)
563bbeb890,complex_frontend,fix undef CUDA_VERSION warning (#37866)
a2fc7f787a,skip,Revert D21171334: [pytorch][PR] Change StorageImpl to track byte count rather than element count
34bf868ebc,InLastRelease,Fix weight quantization in RNNs (#35961)
b8d48d3680,skip,Revert D21406034: [pytorch][PR] [BE] Add @skipIfNoFBGEMM decorator
6792c3ad24,skip,Move addbmm broadcasting from the codegen layer to native layer. (#37603)
91c1505e5a,skip,Move addmm broadcasting code from codegen layer to native layer. (#37613)
0359a9b0a0,build_frontend,Delay loading the cuda library on Windows (#37811)
92f750b5c7,skip,disable clang-tidy modernize-trailing-return (#37888)
e3d1c4eaac,quantization,Revert D21310335: reenable quantization test_qadd_scalar_relu test
96b512be07,misc,fix msan in vec_reduce_all (#37853)
480bd0ad50,bug_fixes_frontend,Stop defining static data in Vec256 (#37767)
5eacc9cb57,skip,[quant][graphmode] Support a new category of ops in graph mode quantization (#37515)
9f060d3873,caffe2,[Caffe2] Increase timing threshold to 50 ms on Windows (#37892)
32b09f7ab9,dispatcher,Devirtualize device init calls in factory op wrappers (#37815)
70f375becf,quantization,[quant] ConvPackedParams with TorchBind (#35923)
402f635bbe,cpp,Enable ahead of time compilation for HIPExtensions using ninja (#37800)
e3934dfae8,amd,[ROCm] Enable bfloat16 for ops in BERT model (#37634)
8c91b78277,jit,[TensorExpr] Fix the shape info check in the TE fuser pass. (#37882)
fe88806784,misc,"Back out ""Revert D21171334: [pytorch][PR] Change StorageImpl to track byte count rather than element count"" (#37893)"
ad2305e556,quantization,Revert D21393512: [quant][graphmode] Support a new category of ops in graph mode quantization
222fdd4227,skip,Updating submodules
b57b596f20,InLastRelease,Reduction should not coalesce_dimensions when splitting for 32bit indexing (#37788)
cdc56d0b6c,cpp,Support c10::optional<Tensor> in custom C++ autograd function. (#37700)
75c201ac32,jit,Fix some amount of support for Bool in tensorexpr. (#37914)
2f61b04514,caffe2,Add Aten as dep to fakelowp and cpuinfo path to its include path (#37909)
f78d02ed51,quantization,[quant][tests] Enable tests to run on all qengine backends (#37843)
88c447bf71,improvements_frontend,Change DeprecationWarning to UserWarning in `torch.cuda` (#32142)
122d8215a3,skip,[RESUBMIT] Kill broadcasting from the codegen layer. (#37907)
6f06df8193,skip,Fix lint (#37922)
e729db48ca,quantization,Remove requantization scale constraint. (#37683)
ec7fd0caef,docs_frontend,[docs] Fix broken links in `contribution_guide.rst` and `governance.rst` (#37820)
f2148de92f,quantization,Revert D21409626: [quant][tests] Enable tests to run on all qengine backends
dd618216c5,jit,[JIT]Support adv indexing using list. (#37848)
8434247653,bug_fixes_frontend,modify `select_equals_backward` to propage only to a single value (#36316)
436cd2c02d,complex_frontend,Migrate check_convert to c10::complex (#37875)
0e3a05ec00,jit,[JIT] rename enable_profiling_mode to enable_profiling_mode_for_profiling_tests (#37825)
53e7d49a98,dispatcher,Port register_prim_ops_c10.cpp to new registration API (#37834)
4e2ea6e013,jit,[TensorExpr] Remove the Tensor argument from loopnest.reorderAxis (#37873)
5edf5efd37,complex_frontend,"Migrate CPU sum, eq, and ne to c10::complex (#37876)"
78529f6de7,skip,Whitespace cleanup (#37165)
8749aa2d55,skip,Clean up formatting in upsample ops (#37166)
4996961826,misc,"In interpolate, only call _interp_output_size in one place (#37168)"
59f03c69ab,misc,"In interpolate, give a short name to scale_factor_list (#37169)"
d6b51e4adf,skip,"In interpolate, join short lines (#37170)"
b1b6bc36a5,mobile,Enable xnnpack_integration test in CI. (#37838)
1ad46f470f,jit,[jit] `__copy__` for `RecursiveScriptModule` (#36830)
7a408576dd,quantization,Stopgap fix to `determine_target` predicate (#37934)
4c4816ad07,complex_frontend,[CPU] addmv for complex tensors (#37924)
945672bf3e,build_frontend,cmake: improve dependencies in incremental builds (#37661)
ab2373205f,build_frontend,Create a desktop shortcut for restoring pytorch environment on CircleCI (#37926)
ae308db681,jit,fix lilstm test in tensorexpr_te (#37913)
6293f1fb49,complex_frontend,Migrate cpu kernel for index and index_put to c10::complex (#37877)
28ac5cdc91,jit,fix profiling test (#37961)
b53e6bfd49,jit,[jit] normalize `getMethod` (#37472)
a3042ca89d,jit,[JIT] Rewrite unaliased if output mutation (#37694)
ec9342521b,jit,"[TensorExpr] Support Bool dtype in Or, Xor, And ops and in TensorExprKernel::bindInput. (#37938)"
728189588e,quantization,[reland][quant][graphmode] Support a new category of ops in graph mode quantization (#37936)
cd0724f9f1,cpp,Do not `std::move` returned value (#37891)
4bbf889bcf,jit,[jit][api][refactor] remove redundant deepcopy implementation (#37538)
bf970bce21,complex_frontend,Migrate some CUDA arithmetic kernels to c10::complex (#37878)
f5b3125af7,jit,[JIT] Peephole optimize list ops (#37612)
f29f96d47b,skip,Port existing zero_dim_dispatch optimizations from codegen and remove codegen capability. (#37615)
56fc347e49,quantization,[quant][fix] A typo in quantized::conv2d_relu (#37964)
3cc5062544,build_frontend,Update bazel to 3.1.0 (#37951)
f538cd627a,performance_frontend,Install HugePagesArena to optimize pytorch prediction performance (#37640)
28ed04c620,jit,[JIT] remove list_with_default op (#37886)
35693e9b4b,bug_fixes_frontend,Give at::cuda::blas::gemv<at::Half> parity with <float> and <double>. Nature is healing. (#37569)
675e77e88a,build_frontend,add docker image build ubuntu16.04-cuda9.2-cudnn7-gcc5.4-py3.6 (#37610)
288dd33770,quantization,quant: remove hypothesis and int32 from layernorm test (#37947)
b837d5d418,quantization,add quantized groupnorm operator (#36835)
4fa049c525,quantization,add quantized instancenorm operator (#36847)
09bedec29e,quantization,move quantization normalization layers to aten/src/ATen/native/quantized/cpu/ (#37352)
14fc83ebc7,complex_frontend,Add missing c10::complex::value_type (#37677)
634282112b,complex_frontend,updated create input and add test methods and added a whitelist for complex (#37835)
681c6fb60f,complex_frontend,Move complex utilities out of Half.h (#37676)
72e5b7ae5b,build_frontend,Add option to run python unittests in parallel (#37180)
952e0f00a4,skip,Skip c2_ref_tests on network failures (#37972)
385f7e59a7,build_frontend,Report test stats (#37803)
122587dcb4,onnx,[ONNX] Improve error checking for large model export (#37798)
76c964dfb0,quantization,Reland [quant][tests] Enable tests to run on all qengine backends (#37943)
9143d7fb68,caffe2,[Fakelowp] Open source fake fp16 FC ops (#37923)
65260d48c8,jit,Fix splitWithTail to insert the tail immediately after the outer loop. (#37941)
4e93844ab1,memory_format_frontend,remove deprecation warning on get_contiguous_memory_format (#37963)
978ad16290,rpc,[TensorPipe] Allow passing args to agent options constructor (#37918)
bc09478a60,rpc,[TensorPipe] Use the new multi-payload message API (#37919)
7be9796cc4,onnx,[ONNX] Support clamp_min and clamp_max (#37872)
30fc58cfcc,complex_frontend,"Migrate CUDA where, tril, triu to c10::complex (#37896)"
46ed3349f3,improvements_frontend,Add --check-untyped-defs to mypy.ini and test suite (#37594)
594b33ea10,improvements_frontend,Add support for non-persistent buffers. (#37191)
ee1ddcef8d,rpc,Acquire GIL when constructing/destructing ConcretePyObjectHolder (#37870)
b2cc9928dd,skip,Move resize logic for bmm from codegen to native code. (#37955)
ffed9dca42,rpc,[TensorPipe] Update submodule (#38013)
1667aa6451,jit,[CUDA_FUSER] Expand operation support for cuda fuser (#37849)
2b41b9bceb,quantization,[BE] Add @skipIfNoFBGEMM decorator (Reland) (#37894)
305444a0bd,build_frontend,"Update miniconda repository, be specific about cudatoolkit (#37186)"
85fccba224,rpc,Message Delay fix for test_check_failed_messages (#37978)
dd64d26d74,skip,Make speed_benchmark_torch report latency in us (#37953)
7bf9d983ea,quantization,[quant] Release qnnpack original weights for conv/linear (#37595)
3066d3ac1c,jit,Remove overly strict assertion for type demotion of scalars. (#38001)
067f08c148,jit,[TensorExpr] Move controlling knob out of the TE fuser pass. (#37970)
a44824c9ed,jit,[TensorExpr] Allow to enable/disable fallback mechanism thru an envvar PYTORCH_TENSOREXPR_FALLBACK. (#37971)
b452fef583,rpc,[Tensorpipe Agent] Base Structs for Tracking RPC Metrics (#37850)
25359f7392,rpc,[Tensorpipe Agent] Implement Global Interpreter Lock Wait Time Metric (#37851)
5d21a9cfc7,rpc,[Tensorpipe Agent] Network Data Profiling (#37852)
f0f587366c,rpc,[Tensorpipe Agent] Implementing getMetrics with currently available metrics (#37980)
8a8b7a16be,caffe2,Remove unpacked int8 blob after constructing the packed blob to save memory (#37973)
99349393ba,complex_frontend,Fixed gradcheck for complex (#37836)
ed4e7cec03,skip,Move _thnn_conv2d resize and zero code from codegen to native code. (#37956)
dc25190833,skip,Move resize / zero logic for _thnn_conv_depthwise2d from codegen to native code. (#37957)
c24c5f9684,profiler,Make RecordFunction callbacks thread local and modernize interface (#37491)
2d708cefcc,profiler,Move RecordFunction into ATen (#37548)
2ef4010593,profiler,Propagate TLS callbacks with ThreadLocalState (#37745)
facc5e0cc4,profiler,Make profiler thread local (#36291)
5e83a13e14,bc_breaking_frontend,stop creating integer type Tensors that require gradients (#37789)
379e717a1b,skip,"Back out ""Revert D18927220: if_constexpr for C++14"" (#37792)"
f2f8027760,jit,[TensorExpr] simplify trivial adds/subs/muls even in Float (#37960)
a42616f71a,complex_frontend,Fix torch.tensor dtype inference (#38030)
376c9a40dc,skip,Fix dummy typo in `skipIfNoFBGEMM` (#38058)
002f5ec51b,mobile,Add preprocessing that fuses decomposed linear into linear. (#37937)
d5df055bbb,jit,[WIP][JIT] Add JIT backend registration API (#35833)
e3fcc6ade8,rpc,Skip RPC profiling tests (#38045)
eaf9b28c55,quantization,[quantization] Use torchbind for Linear PackedParams (#34140)
bfa5070cbc,build_frontend,Fix rebuild with Ninja on Windows (#37917)
4ae187f6cb,skip,Set SCCACHE_IDLE_TIMEOUT to INFINITE(0) on Windows (#37993)
9efbc19f75,caffe2,Fix the issue with C2 cont build
5ee2302349,docs_frontend,Add links to more subdir READMEs in CONTRIBUTING.md (#38049)
29f19bf727,onnx,[ONNX] Enable tests for opset 12 (#37846)
4bc0a7f86a,quantization,Revert D20229168: [quantization] Use torchbind for Linear PackedParams
f8c93c5d3e,skip,Get rid of javasphinx dependency. (#38042)
32329c3338,caffe2,[nomni] fix outputs check to replaceSubgraph (#38005)
25413635d0,caffe2,[c2][opt] nomnigraph transform for ClipRangesGatherSigridHashV2 fusion (#38004)
12bbda053c,bug_fixes_frontend,Remove static initalizers from Vec256 (#38088)
3cade9cdd4,skip,Automatic update of fbcode/onnx to 807c62cf7e4c96ce49040bcf073b7e4a054f28a5 (#37983)
9fe8243536,bug_fixes_frontend,Fix minor issue in type stub for Optimizer (#38067)
c2f787ce77,InLastRelease,"Give _VariableFunctions class a different name, so pickling works (#38033)"
5a386a0a78,cpp,Fix ldflags string for HIPExtensions (#38047)
16e3df3ac6,jit,Fix typo: TupleUnpack. (#38043)
deeef50432,bug_fixes_frontend,Check the _geev input matrix for NaNs and infs (#37642)
f4d9713d12,complex_frontend,Migrate AT_DISPATCH_ALL_TYPES_AND_COMPLEX_AND3 to c10::complex (#37977)
d35ab0b7ae,caffe2,Fix CUDA memory management issues caused by not using PinnedCPUAllocator (#38066)
53aa7d8bc5,skip,Add option to skip tests after retries (#38079)
4c358b8b72,build_frontend,Run QEMU to test that default dispatch doesn't use AVX (#38094)
609d5a4476,visualization,[tensorboard] Let hparam render values correctly (#31544)
459f14e9f6,jit,[TensorExpr] Correctly print dtypes in Cast and Allocate. (#38091)
a253ea92fb,jit,[TensorExpr] Properly handle Bool dtype in several other places. (#38104)
ff1a627bae,jit,[TensorExpr] Don't include prim::Constant nodes with Tensor type into TE fusion groups - we can't handle them. (#38105)
0f60c8d878,jit,[TensorExpr] Correctly print 'bool' dtype in Cuda printer. (#38077)
0c936f94d6,complex_frontend,Revert D21449612: [pytorch][PR] Migrate AT_DISPATCH_ALL_TYPES_AND_COMPLEX_AND3 to c10::complex
9232356e5f,skip,remove uses of type() and type_as() part 1. (#38029)
726aa713d5,improvements_frontend,Replace torch.is_tensor usages with isinstance checks. (#38062)
b4946b96c6,mobile,Don't use Profiler key in lite interpreter (#37962)
91f451a5e6,rpc,[TensorPipe] Do not require user to provide worker name-to-rank map (#38052)
c1e7758b5e,quantization,"Back out ""Revert D20229168: [quantization] Use torchbind for Linear PackedParams"" (#38101)"
ff9a809ccd,quantization,[quant][graphmode][refactor] Remove unused code in quantization.cpp (#37974)
0ed7fc581c,quantization,[quant][graphmode][refactor] Split quantization.cpp (#37975)
a7c29dbfa2,performance_frontend,`unfold_backward` gets its own kernel (#36612)
6e1e2a60dc,jit,fix compilation error with gcc 5.5 (#38112)
4784af1d78,jit,[TensorExpr] Don't include aten::rand_like to TE fusion groups since we can't handle rand+broadcast case yet. (#38132)
41572116f6,quantization,Dont store redundant packed params in dynamic quantized RNN (#38134)
172bcdb8c8,docs_frontend,Add documentation for nn.Hardsigmoid and nn.functional.hardsigmoid. (#38120)
9957db22a9,caffe2,int8 fc with tests (#38017)
ad433e2003,jit,[TensorExpr] Fix a bug in the IR Simplifier that could introduce a division by zero (#38055)
c13dc2cab2,skip,Fix a minor typo in DistanceOpsKernel.cpp (#37596)
ca2206d071,docs_frontend,Add documentation for FeatureAlphaDropout (#36295)
615235fc80,rpc,Migrate OwnerRRef value store to generic torch Future (#38143)
c879c6fb98,skip,Vectorize non-persistent Softmax kernels (#36485)
e84aa0211d,jit,[JIT]Support List variable in adv indexing. (#37966)
55de7c3bb0,build_frontend,Add test jobs on CPU agents for CUDA builds on Windows (#37904)
fdc40616b2,dispatcher,s/callUnboxed/call/ (#37999)
63b1ae6983,bug_fixes_frontend,Fix overflow in torch.remainder when dividend is very large (#37758)
138476389e,quantization,[quant] Disable qnnpack test when TSAN is enabled (#38153)
ae534dc978,jit,[TorchScript] Explicitly disallow del with more than 1 operand. (#38089)
16e62f9305,dispatcher,Unboxing uses if_constexpr instead of SFINAE (#38145)
86d28706e0,skip,Remove uses of type() part 2 (#38140)
3d0279862d,rpc,Consolidate builtin/python_udf RPC to return ivalue::Future like torchscript RPC does (#35154)
8181711637,skip,Automatic update of fbcode/onnx to 79a7e0df7e86e0f32e7a05f563b24a566540c18b (#38106)
464e5a6c07,jit,[TensorExpr] Add print functions for Tensor and Function. (#38175)
7e9af67ca1,improvements_frontend,"Add minimal skeleton for _C type stubs, delete torch.autograd stub (#38080)"
30f4064cfb,bug_fixes_frontend,"Bind VariableFunctions as a module, not a class with static methods. (#38136)"
e109ff6379,rpc,Use py::pickle in RRef pickling pybind code (#38147)
4501083306,distributed,dedupe test skipping in common_distributed and test_distributed (#38078)
f6b1c046b6,skip,Revert D21483808: [pytorch][PR] Remove uses of type() part 2
b579433bf7,bug_fixes_frontend,"Revert D21487840: Bind VariableFunctions as a module, not a class with static methods."
64d083bb86,jit,fix a bracket (#38039)
e3414c1ef1,skip,AssertEqual now checks tensors dtype (#34154)
57d01be92b,skip,Replacing assertEqual with assertEqualIgnoreType wherever types missmatch (#38102)
48ad9f5a30,skip,assertEqual now requires matching dtypes (#38103)
33f4fca1a6,jit,[TensorExpr] remove Let and LetStmt in favour of binding in Block (#37606)
26928b164f,caffe2,remove internal file logging.h (#38182)
5077518c91,complex_frontend,[Resubmit] Migrate AT_DISPATCH_ALL_TYPES_AND_COMPLEX_AND3 to c10::complex (#38144)
f3e620ee83,build_frontend,explain redundant branch/tag filters (#38169)
503be4e05e,caffe2,fixing build failures with USE_NATIVE_ARCH ON (#35359)
324dc1623e,InLastRelease,add dtype checking for gather and scatter (#38025)
6f396e18c3,performance_frontend,Add per-device allocator object in CUDACachingAllocator (#37567)
6edf340338,improvements_frontend,"Delete torch/__init__.pyi, deferring to direct extension stubs (#38157)"
ebad4e463f,caffe2,add missing include file for fake_nnpi_ops_utils (#38215)
c26dde967c,skip,Kill resize-ing and zero-ing from codegen. (#37958)
fe53b52537,skip,"Macro generate ScalarTypeToCPPType, including all ScalarTypes. (#38071)"
f314d9a077,skip,"Remove codegen for IntArrayRefStride, which isn't used. (#38072)"
3569c59600,bug_fixes_frontend,Inverse logic of persistent set and prevent use in jit (#38131)
77d8a44802,skip,"If we're building on C++17, use actual ""if constexpr"" (#38154)"
b290da0e75,complex_frontend,"Migrate CPU tril, triu, masked_fill to c10::complex (#37897)"
c31913671c,docs_frontend,DOC: add BFloat16 dtype and BFloat16Tensor (#37051)
08c3339e7c,caffe2,[pyfi] override TP2 networkx -> PyFI networkx (#37764)
5137827ad0,performance_frontend,Lazily initialise thread local num_threads value (#37461)
5f9b9036c1,improvements_frontend,"Add instance methods tensor.isnan(), tensor.isinf(), tensor.isfinite() (#37942)"
00f3790a9d,skip,Using LoadLibraryEx and LOAD_LIBRARY_SEARCH_* flag for loading DLLs o… (#37763)
1456515f15,jit,[JIT] Disallow plain List type annotation without arg (#38130)
a553935e3c,jit,[JIT] Expose magic methods on script::Object (#38167)
c6b2844076,skip,Pin flake8 to 3.7.9 (#38269)
a37b865107,skip,test_linspace : remove explicit for-loop (#38191)
def9f15b57,build_frontend,.circleci: Improve docker image build workflow (#37976)
19d6e32e9a,docs_frontend,fix sample code (#38002)
333e29c45f,onnx,[ONNX] Fix pow op export (#38065)
7c2853be9d,build_frontend,Revert D21511048: [pytorch][PR] .circleci: Improve docker image build workflow
8e07b75cef,cpp,Have DeviceType available in torch namespace (#38036)
f41833957d,bug_fixes_frontend,bypass `getDeviceFromPtr` check when device is known (#36714)
1ab4f35499,skip,Revert D21496081: [pytorch][PR] Using LoadLibraryEx and LOAD_LIBRARY_SEARCH_* flag for loading DLLs o…
21ce4333b9,skip,"Remove `THFile`, `THDiskFile`, and `THMemoryFile` (#37830)"
cdd1b9a891,jit,[TensorExpr] Distinguish aten::max reduction op from aten::max elementwise op and only fuse the latter. (#38171)
42a222cf2c,docs_frontend,DOC: Add missing args for index_add (#38213)
6968c8153e,dispatcher,Warn against callOp (#37797)
43dd8760d7,skip,Move ThreadLocalDebugInfo to c10 (#37774)
eea9c6a048,skip,[RELAND] .circleci: Improve docker image build workflow (#38279)
375ddb01b5,complex_frontend,Fix tensor printing (#38031)
bf499cccb6,complex_frontend,Refactor native/cpu/zmath.h (#38037)
6e66e8562f,skip,Revert D21517822: [pytorch][PR] [RELAND] .circleci: Improve docker image build workflow
cebf5a8767,improvements_frontend,"Run mypy on some test files, add iinfo/finfo annotations (#38220)"
ec7beda822,caffe2,Use thrust::host_vector instead of std::vector (#38178)
09e4ff95ee,quantization,[quant][mobile] Ensure qconv doesn't assert with empty batch (#38252)
6943253421,quantization,[quant][mobile] Don't release bias tensor (#38284)
63c3b89c1c,skip,Simplify code with decltype(auto) (#30922)
0d977e9223,complex_frontend,[CUDA] addmv for complex tensors (#37940)
dcf1861f88,docs_frontend,add document for bucktization (#38119)
dad552666e,rpc,Add then(callback)->Future API to ivalue::Future (#37311)
3a63728149,caffe2,[caffe2/fakelowp] optimize ref int8 gemm (#38294)
cf82011361,build_frontend,Codegen CircleCI Windows configs (#38292)
5c44f2a16b,skip,Updating submodules
ba0851326c,complex_frontend,Revert D21449462: [CUDA] addmv for complex tensors
4c99a9b672,docs_frontend,Add documentation for hardswish (#37989)
e3584f8d7e,complex_frontend,Migrate CPU tensor factories to c10::complex (#38021)
6bb1c4a7ab,skip,Move (most) generated return statements for TH functions out of the switch. (#38073)
7eb9f1788c,build_frontend,Using LoadLibraryEX [Reland] (#38302)
9576b37caf,quantization,Fix test_channel_shuffle hypothesis params (#38327)
b29ec43555,quantization,Limit max numel for test tensors (#38304)
96d2ddba6c,caffe2,remove harcoded values for fc testing
d5e8d90a2c,complex_frontend,Migrate CPU reduction to c10::complex (#38022)
986d7e47c4,complex_frontend,Migrate CPU fill kernel to c10::complex (#38026)
779abf7538,complex_frontend,Implements torch.pow for complex on cuda and enables complex values as exponents for pow (#36793)
7c66ad8941,caffe2,[caffe2/fakelowp] fix bug in ref code (#38331)
291869d625,profiler,Remove unnecessary RPC profiling code after future merge (#38255)
82abd50f2b,complex_frontend,Added more autograd tests for C->C complex functions (#37856)
a90e574401,mobile,Enable linear/conv + relu fusion in mobile optimizer. (#38139)
6daaeb2bda,cpp,[pytorch] Add C++ error when PyTorch used with Python 2
906c50eb69,distributed,"Remove dead code in ddp.{h, cpp} (#37990)"
525295e696,jit,BC upgrader for dynamic Linear with torchbind (#38333)
b6d494d6da,rpc,[future] Minor: std::move() callback in future for the convenience operator case. (#37861)
7c13a07286,skip,[Reland] Remove uses of type() part 2 (#38288)
d5a7d790a1,improvements_frontend,Use torch.ne instead of torch.nonzero in gradcheck (#37857)
8ab6377273,th_aten_frontend,Port atan from TH to ATen (#37991)
f954dd7823,jit,Add dropout removal pass. (#38253)
3317fdf177,skip,Updating submodules
a4466eeff4,rpc,[Tensorpipe Agent] Tracking Active Call Metrics (#38265)
a2a53447e4,rpc,[Tensorpipe Agent] Add Call Counts to Metrics (#38266)
3134978816,jit,[JIT] Handle del statements with variables as targets (#37608)
cdf4d42c39,skip,[RELAND] [RELAND] .circleci: Improve docker image build workflow (#38335)
c2ac2127be,jit,[JIT] recursively compile class types (#38050)
80639604a8,skip,Revert D21536269: [pytorch][PR] [RELAND] [RELAND] .circleci: Improve docker image build workflow
e3357a7812,build_frontend,Fix typo in build environment name (#38343)
2c881417a7,quantization,Change input scale to double type for conv params. (#38346)
f7e7a15a5d,bug_fixes_frontend,Fix `NaN` comparison in `torch.median` (#38216)
4a266c93a6,performance_frontend,Allow specifying range in and cpu_serial_kernel and cpu_serial_kernel_vec (#37981)
eb3e9872c9,InLastRelease,[JIT] make torch.unique compilable (#38156)
70c6550cc9,misc,Forgotten changes for Tensor.random_()'s from and to bounds for floating-point types (#38287)
00be4abc38,misc,Fixing DistributionsHelper.h includes (#38298)
4f08bdddfc,misc,Add skipIfNoSciPy/get_all_int_dtypes/get_all_fp_dtypes to common_utils (#38299)
34523b70c1,misc,Renamed *_transformation to transformation::* (#38301)
cfe3c795ed,dispatcher,Port torch/csrc/jit/runtime/register_distributed_ops.cpp to new operator registration API (#38014)
6be3e5d3bb,caffe2,[caffe2] weight_decay in reduced precision adagrad
d001862aff,rpc,Minor code cleanup (#38340)
2e9d6d99be,rpc,Explicitly decref py::object in ConcretePyObjectHolder and PythonFunctionGuard (#38364)
797c608f50,rpc,Explicitly decref py::object in PythonRpcHandler (#38366)
c20b0080c6,skip,Partial revert of #38144 to fix ROCm CI. (#38363)
e39991e838,rpc,[TensorPipe Agent] Bind default IP address (#37910)
756788ea87,rpc,Keep py::object alive until jit::toIValue returns (#38348)
3d968088e0,InLastRelease,fix multinomial kernels to properly advance random states (#38046)
167a978a03,jit,Fix method stub creation for function attributes (#37994)
3a478b1cbf,skip,Updating submodules
9a2d8dfe63,jit,[TensorExpr] Benchmarks: set up profiling executor and fuser according to the given arguments. (#38295)
61bea93fca,performance_frontend,Further parallelize linspace in addition to AVX (#38093)
138769b1b8,amd,[ROCm] add exact_dtype=False to bfloat16 test (#38381)
f2c6346ebe,quantization,[quant][graphmode] Move avg_pool/adaptive_avg_pool to general value ops (#38330)
e7b4ef8fd3,skip,"Revert ""Partial revert of #38144 to fix ROCm CI. (#38363)"" (#38380)"
d86de916a9,th_aten_frontend,Migrate `exp` and `exp_` from the TH to Aten (CUDA) (#36652)
899a075b25,build_frontend,Split up BinaryAritmeticKernel.cu to speed up compilation time. (#38263)
f64d24c941,distributed,speed up SyncBatchNorm by batching distributed communication (#38246)
2a54533c64,caffe2,Fix the flooding log issues (#38356)
d403b85c00,quantization,[quant][graphmode] Move `aten::mean` to general value ops (#38160)
0526eb0f08,jit,Fix aten_add. aten_sub to handle 2-operand versions (#38367)
b90fc52c68,quantization,[quant] Implement unsqueeze/squeeze for per-channel qtensor (#38247)
eac54f18b8,performance_frontend,Vectorize SmoothL1Loss forward (CPU) (#37115)
6e13146d96,jit,[TensorExpr] TensorExprKernel: don't do any compilation or lowering in run(). (#37948)
b668bbc404,quantization,[quant][graphmode][refactor] Factor out common parts of general value ops (#38161)
328dd9e5d6,rpc,[future] Make new IValue future constValue semantics match torch::utils counterpart (#38355)
33977ca769,docs_frontend,"Update Cpp, rpc docs and Libraries section to match 1.5 (#38350)"
afa4dbd731,rpc,Use GIL to guard decref of jit::toPyObj return value in processRpc (#38376)
ff76de8ace,quantization,speed up hardswish and hardsigmoid tests (#38256)
dac9b61850,skip,Move Cuda Abs kernel to its own file. (#38274)
53439be643,caffe2,improve some reporting for fakelowp tests (#38428)
1676c7d618,complex_frontend,"Added autograd tests, disabled jit autograd tests for complex and added a separate list for tests for complex dtype only (#38399)"
2d221df52f,quantization,[quant] Add support for quantized::conv1d operator (#38248)
f6626aaf43,quantization,[quant] Add support for Quantized Conv1d and ConvRELU1d (#38283)
ae11718c45,quantization,[quant] Add quantized::conv1d op benchmarck (#38332)
7d7d73655d,quantization,[quant][graphmode] Add quantizedconv1d to graphmode (#38341)
2efa7e04c2,jit,[jit] move torchbind tests to separate file (#37473)
0d220ef381,jit,[torchbind] Better error message when missing init. (#37474)
e988b4fbb1,quantization,[quant][graphmode] Move interpolate to general value ops (#38162)
1fde373f2f,quantization,[quant][graphmode] Move clamp to general value ops map (#38163)
98d78a7f20,quantization,[quant][graphmode] Move hardtanh to general value ops map (#38164)
16696186e1,quantization,[quant][graphmode] Move elu to general value ops map (#38165)
7ce733d218,quantization,[quant][graphmode] Move leaky_relu to general value op map (#38166)
8d883f5c7c,jit,[JIT] [Easy] Add location to implicit conversions (#38442)
eb66dd0bc8,quantization,[quant][graphmode][refactor] Refactor propagateQuantizationOps (#38276)
ee8bf1c640,quantization,[quant][graphmode][refactor] insertDeQuantForAllUse (#38277)
5a979fcb99,InLastRelease,allow user passing relative paths in include_dirs within setuptools.setup (#38264)
336e1ec592,improvements_frontend,Clean up error handling in is_nonzero and where in TensorCompare.cpp (#38150)
b1d2c1765e,skip,Updating submodules
beedc6542e,skip,relax MAX_JOBS restriction for ROCm builds (#38425)
8d94615c2b,th_aten_frontend,Migrate erfc from TH to ATen (CUDA) (#38373)
54c16b44cf,amd,"[ROCm] increase timeout, enable test_backend_group (#36166)"
f99a693cd9,rpc,Remove unnecessary py::object copy in PyRRef ctor (#38402)
061ed739c1,build_frontend,Embed ATen/core/CMakeLists.txt into its parent (#38426)
f3d2e332f1,build_frontend,[PyTorch] Remove duplicate jit core sources filelists (#38430)
b5868b2833,bug_fixes_frontend,Relax sampler check in BatchSampler (#38403)
96885f73ed,skip,"make test_jit infer the profiling mode, add a job for simple executor (#38374)"
15da26f8aa,docs_frontend,DOC: Add documentation for Tensor.is_nonzero (#37845)
2b2d2168e8,bug_fixes_frontend,Issue #27441 Fix: Bug in updating ModuleDict & ParameterDict (#27814)
fedb70a8fb,amd,Fix encoding errors for hipify tool (#37906)
48c0331e01,new_features_frontend,Sparse softmax support (CPU) (#36305)
628e3b6fbd,improvements_frontend,Fix unreachable validation for gradcheck (#37915)
3e9b4332d2,build_frontend,Fix @skipIfNoFBGEMM for types (#38432)
0a159b0a3a,bug_fixes_frontend,Fix precision issues in CPU remainder (#38293)
ae392a77a6,bug_fixes_frontend,Add better device idx parse checks (#37376)
25f918548d,improvements_frontend,Allow GradScaler to be pickled (#38296)
7f11079769,skip,"Delete ""named_guard"" in native_functions.yaml (#38429)"
cbff959bd7,quantization,[quant] Return default qconfig when backend is 'none' (#38407)
328fc70b84,skip,Remove (most) Python 2 support from setup.py (#35617)
7026b39ac7,jit,Remove _uses_true_division (#35618)
d060deb5bb,jit,Remove _compatible_subtest (#35620)
313bea84ef,skip,Remove _get_wrapped_func (#35621)
7f7fdb1013,jit,Remove a use of checkScript(str) (#35623)
2f4da7c00c,skip,Remove a use of exec (#35624)
af597335d4,rpc,Remove unnecessary to_string in RPC logging code. (#38414)
d1eeb3b7bb,jit,[Tensorexpr] Fix and improve handling multiple gpu devices (#38365)
b57a339703,rpc,Guard against negative rpcTimeout being passed in to RpcBackendOptions (#38267)
5f2a274015,InLastRelease,Fix conv non zero padding being applied in wrong dim (#37881)
38d141ede5,jit,Support having a different forward method when we are not in scripting mode (#38158)
3300dd5227,build_frontend,.cirlceci: Keep tags that look like a sha1 (#38483)
f178bf10f1,rpc,Support rpc_async call with timeout in JIT (#37884)
4d4895a62a,rpc,Use Future's then() API to fix RPC profiling (#38352)
9d0e935b48,skip,skip torchbind on rocm (#38501)
0e80c12bb4,skip,[pytorch] fix -Wlogical-op-parentheses in SortingKthValue.cu (#38500)
69dca43c35,skip,Updating submodules
1b973aa2a2,build_frontend,Sort CirlceCI config.yml keys to facilitate diff review after codegen (#38496)
6d642a6f6c,skip,Remove (most) Python 2 support from C++ code (#35614)
b140ed6848,skip,Remove structseq_slice (#35625)
1f87f15ba3,skip,Remove _reset_warning_registry (#38485)
8b6bf2a457,docs_frontend,Add C++ Landing Page (#38450)
f4605ae5c3,quantization,[quant] Fusion support for conv1d + ReLU (#38438)
8e732514cd,quantization,[quant][graphmode] Add support for quantized conv1d + relu fusion (#38441)
de7025fbdb,quantization,[quant] Support for functional quantized::conv1d (#38449)
504637a171,quantization,[quant][graphmode] Support ops with fixed quantization parameters (#38278)
bbfd0ef244,caffe2,[c2] register cuda op for LpNorm (fallback) (#38517)
8cdc4807cd,skip,[RELAND] .circleci: Improve docker image build workflow (#38484)
0e0b9496fe,caffe2,[c2] [easy] stop gradient when diagnose (#38518)
bc49d938e2,skip,Revert D21585458: [pytorch][PR] [RELAND] .circleci: Improve docker image build workflow
25177e2796,quantization,[quant] Support empty batch input for quantized ops (#38508)
155a287aea,rpc,Enforce const on PyRRef functions (#38415)
ee52501976,quantization,[quant][graphmode][refactor] Factor out getInputTensorQParamOpFusionInfo (#38358)
fac9f36563,caffe2,"Back out ""[c2] register cuda op for LpNorm (fallback)"""
8df14c573e,skip,Add sccache support for hcc and hip-clang in ROCm (#38451)
3d0532f3ab,caffe2,[c2] fix compute_norm test (#38529)
960f4b51e3,jit,[JIT] Fix `@staticmethod` access from `self` on modules (#37702)
ec9b2f9a9d,quantization,[quant][graphmode][refactor] Factor out getFixedQParamOpFusionInfo (#38359)
ac613371a3,caffe2,Update NNPI backend to 0.5.2.5. (#4464)
000fea375c,complex_frontend,Support operations on c10::complex and integer scalars (#38418)
3cb2778d94,complex_frontend,Remove some unnecessary cast for complex numbers. (#38422)
0d51728d38,skip,Updating submodules
8bf3124572,jit,[TensorExpr] Fix bug when splitting inner reduce axis with tail (#38420)
c0bc182761,skip,"Revert ""Vectorize non-persistent Softmax kernels (#36485)"" (#38534)"
bf2bbd9648,skip,Add message to static_assert (#38519)
bae895cef0,bug_fixes_frontend,Issue 37819: Added check for kHIP in ATen/native/Copy.cpp (#38003)
acacad2575,caffe2,Adding support for manifold files in DBReader (#37727)
242af6c078,complex_frontend,Add tan_cuda for complex dtypes (#38400)
4b52e52577,build_frontend,Use `jit_core_sources` from build_varliables.bzl (#38526)
52e9953faf,docs_frontend,use version number instead of 'master' in html header title (#38149)
5a19fe7454,th_aten_frontend,migrate `gather` to ATen (CUDA) (#37659)
42a3fb3a4e,mobile,change to find_method of lite_interpreter API to return nullptr if method not found (#38503)
70ef9f5124,skip,Improve testing of logical_not. (#38505)
8d7582a2cf,build_frontend,codegen mobile and macos configs (#38539)
d44573a6dc,quantization,Remove _all_weight_values again (#38504)
62afc2d63d,jit,[JIT] Remove debug print statement added in #37994 (#38524)
daa85cfe2e,jit,[JIT] Exit Transform Rewrite (#38282)
dc918162b7,caffe2,Remove `Caffe2_MAIN_LIBS` (#38408)
1d1533e358,complex_frontend,Migrate CPU cross and some elementwise to c10::complex (#38023)
dd7eed5ae4,jit,[JIT] Export JIT backend extension headers in setup.py (#38525)
6232481cab,quantization,[quant][graphmode] Add RemoveReduantDequantize pass (#38434)
53a368fedd,cpp,[aten] Split some at::launch code into at::internal::launch_no_thread_state() (#38477)
b04c07a67c,docs_frontend,Added a Resource section to README (#38547)
6a23214a47,jit,[JIT] Adjust pybind includes in backend.h (#38562)
9cfc10d52e,misc,Updates assertEqual to use torch.isclose-like logic (#37294)
adf67b81c5,improvements_frontend,Make strip error messages work for cuda code (#38125)
87f40fef84,skip,Refactor check macros to reuse code (#38126)
67d76f6bdd,new_features_frontend,Add utility to enable cpp stacktraces in torch.utils.debug (#38127)
0d9bb5f580,jit,[JIT] Use GE optimizer guard in import (#38575)
8743d51182,skip,Updating submodules
8752d6a736,docs_frontend,DOC: Correct upsample doc to match interpolation (#38455)
f39222a13d,InLastRelease,Restore thread_local states in continuation thread on RPC servers (#38512)
31b57e38cb,jit,[jit] fix `index_put_` error in subscript assignment (#38378)
feb24577c2,skip,Reduce number of variables in codegen (#38369)
b9c537514c,jit,[JIT] Remove import statement thing in serialization docs (#38578)
db86c8c6f5,jit,Test BC for built-in torchbind methods (#38560)
83df3beaca,complex_frontend,Add complex support for torch.sum (#38382)
fe44741dba,skip,Updating submodules
873f9025bb,skip,Updating submodules
176174a68b,skip,Remove BC hack (#38571)
b27be3e0c5,skip,Avoid double dispatch in logical_not for compilation speed reasons. (#38565)
8292742ba0,quantization,fake_quant: move observer and fake_quant flags into buffers (#38368)
a86176dee2,docs_frontend,CTC target un-pad example (#38393)
711f258dc7,onnx,Enable tests in test_pytorch_onnx_onnxruntime (#37868)
e6993938de,rpc,"Avoid Releasing, Reacquiring lock per iteration in RPC Retry Thread (#38521)"
8338426ed8,caffe2,Fix infinite loop bug in minimizer (#38507)
67cd263876,caffe2,Fix merge_fp32_inputs_into_fp16 with no partition (#38594)
d904f3324f,caffe2,[NNPI] Support fp32 bias in NNPI Backend (#38596)
59bef16138,build_frontend,Add ci binary test for windows (#38297)
44cead3a31,docs_frontend,Improve syncbn doc format (#38423)
ca05fb2e86,complex_frontend,Add autograd tests for complex (#38658)
ece878e5b8,onnx,[ONNX] Add GreaterOrEqual and LessOrEqual to opset 12 ONNX export (#38311)
34ef473d92,rpc,[Tensorpipe Agent] Timeouts for RPC requests (#38448)
a84fd8de39,rpc,Handling Active Call Count through Future Callback (#38589)
09c430a2aa,complex_frontend,support complex types for tanh_backward_cpu (#37791)
eb224721d2,mobile,Enabled dropout removal pass in mobile optimizer. (#38254)
b2c06ad875,jit,[JIT] Export all jit/backend headers in BUILD.bazel (#38668)
59d92e442b,performance_frontend,Vectorize non-persistent Softmax (#38557)
5b12c29b17,onnx,[ONNX]Update Dropout Export (#37641)
262f70c986,mobile,[PyTorch] Remove module and operator observer macros. (#38489)
895479e612,build_frontend,Complete codegen of 'build' workflow YAML tree (#38631)
b29e7f9b9d,jit,"[TensorExpr] Use couldMoveBefore instead of couldMoveAfter checks in the fuser pass, add CPP tests. (#38592)"
5e2d8745c8,misc,"RIP CUDA <9.2: circleci, aten, and caffe2 (#36846)"
5fcb2f678f,rpc,[Distributed Autograd] Make debugInfoMap from strings to ints (#38416)
23207ae656,jit,towards guard what you use (#38576)
378956b481,bug_fixes_frontend,Make find_first_set works on x86 MSVC (#38637)
d7e08b456d,caffe2,FakeLowP Readme update (#38666)
8c07a98adc,bug_fixes_frontend,Error out of default_collate for lists of unequal size (#38492)
c430b7d80f,skip,Updating submodules
97abed7cbe,quantization,[quant] Remove TensorListObserver (#38584)
2f21dfb541,jit,[TensorExpr] Eager reduction initialization & removal from ReduceOp (#38585)
76fc9bd2ef,skip,Docker constants refactor (#38676)
49d687f23c,jit,[JIT][to_backend] Move code that is not related to the user-facing API out of `jit/backends/backend.h` (#38567)
724b2b6ebd,profiler,Profiler: Call `populate_cpu_children` inside `__str__` and fix typo (#37816)
f3048609d3,complex_frontend,[CUDA] torch.roll for complex dtypes (#38664)
958313a79f,InLastRelease,Fix memory usage increase reported in #38568 (#38674)
f184ec819d,improvements_frontend,"Do not use ""buffer"" in reentrant autograd err msg (#38625)"
91163addf8,skip,organize verbatim sources with subdirectories (#38688)
d5461e7ac8,quantization,[quant][graphmode] Move processing code to prepare_script (#38669)
86397f6b24,quantization,[quant] Remove get_qparams in Observers (#38435)
fc19747d64,bug_fixes_frontend,handle grad with `stride=0` on GPU MvBackward (#38321)
5e55f0805f,skip,override gcc version in cuda related test (#38675)
ddfd720e5d,dispatcher,Redundant schema registration Prevention for Manually Boxed Wrappers (#38588)
1a3f646b9c,skip,Regenerate .circleci/config.yml (#38705)
c4d3b042e8,build_frontend,Cleanup BUILD.bazel (#38699)
f6f1384811,jit,"[JIT] Refactor attributes to support buffers and parameters as first class citizens, add support for iterating over `named_buffers()` (#37905)"
f3b5c22dba,cpp,"Update On ""check-doxygen.sh must be run from docs/cpp/source director… (#38641)"
8d64986202,build_frontend,Fix target determination file diffing (#38661)
e5ada042b1,quantization,QAT ConvBN: remove explicit folding and use BN instead (#38478)
320c35681d,jit,[TensorExpr] (trivial) unique Kernel input names (#38678)
7d38db0f9a,quantization,[quant] Support for fused ConvBn1d and ConvBnRelu1d modules (#38452)
35beff0b9f,misc,RNG infrastructure improvements (#37984)
b14734d92e,improvements_frontend,"Add bfloat16 to CPU cauchy_kernel, log_normal_kernel, exponential_kernel (#38427)"
54d4b419db,InLastRelease,fix clip_grad_norm to work with parameters on the different devices (#38615)
dfbf9f397f,caffe2,"Back out ""Back out ""[c2] register cuda op for LpNorm (fallback)"""" (#38566)"
1ef77f9045,quantization,[quant][graphmode] Different rule for handling `aten::cat` (#38570)
819da00b3d,InLastRelease,Fixes floordiv dunder registrations (#38695)
6fd48e24f1,jit,"Add support, test for kwargs in jit._fork (#38357) (#38665)"
9ad14f6b43,bug_fixes_frontend,cover nn.Conv1d in mkldnn model conversion logic (#38528)
55914f8e83,skip,Add skipCUDAIfRocm to test_nn test_softmax_results. (#38724)
7492e98c7f,rpc,"[Tensorpipe Agent] RPC, RRef tests for Tensorpipe Agent (#38444)"
b782ad3b9e,rpc,[Tensorpipe Agent] Dist Autograd Tests for Tensorpipe Agent (#38445)
b2991c105a,rpc,[Tensorpipe Agent] Dist Optimizer Tests for Tensorpipe Agent (#38446)
87aa2d25ae,rpc,[Tensorpipe Agent] Enabling tests with OSS CI (#38447)
ab169fa5ac,bug_fixes_frontend,Fix find_first_set for x86 MSVC (Updated) (#38706)
959afe0726,cpp,"Overload bitwise NOT, AND, OR, XOR operators for `at::Tensor` (#38691)"
423a00ad39,dispatcher,Remove call_unboxed_super_slow_temp_shim (#38351)
befc76bb65,rpc,[RPC] [Minor] RPC entry point cleanup (#34292)
87b198d309,skip,add distributed/test_nccl to ROCM_BLACKLIST (#38730)
b995540a01,quantization,Revert D21632878: [quant] Support for fused ConvBn1d and ConvBnRelu1d modules
24b48372b9,skip,Revert D21626921: override gcc version in cuda related test
a94fb71b12,profiler,Memory profiling (#37775)
235f62417d,profiler,Fixes for profiling JIT code (#38453)
363a2d9455,dispatcher,Revert D21530545: Remove call_unboxed_super_slow_temp_shim
bcf8973654,improvements_frontend,Add `torch.utils.cmake_prefix_path` pointing to `share/cmake` folder (#38559)
cbd0adc7b4,complex_frontend,Migrate CPU unary ops to c10::complex (#37898)
9907a3eb65,onnx,Update Argmin/Argmax ONNX Export (#38329)
5fb26b1022,skip,Delete cuda9-cudnn7 build which is not defined in build.sh (#38750)
5af4e76683,dispatcher,"Back out ""Revert D21530545: Remove call_unboxed_super_slow_temp_shim"" (#38742)"
64584573f9,skip,Updates tests for integer division deprecation (#38621)
40ce90bfc1,skip,Revert D21560096: [Tensorpipe Agent] Enabling tests with OSS CI
7587188037,skip,Skips test_float_to_int_conversion_finite on MacOS (#38753)
530d48e93a,quantization,[quant] Support for fused ConvBn1d and ConvBnRelu1d modules (#38452) (#38749)
9e910a95b0,build_frontend,Add `torch_python` and `_C` library to bazel build (#38707)
42870ddf24,jit,Generate Dynamic Shapes (#37693)
1465970a34,build_frontend,Update valgrind version build from source (#38754)
c60daedb36,complex_frontend,Migrate CPU eye to c10::complex (#37899)
a3bab37d96,skip,Add BatchedTensorImpl (#38424)
c78691b4a6,complex_frontend,[CPU] torch.gather for complex dtypes (#36430)
8666ea0cd1,skip,Remove duplicated entries in `native_functions.yaml` (#38389)
ca1978c9db,skip,"For jobs need a merge, merge with origin/master for ghstack PRs. (#38745)"
f4f0dd470c,complex_frontend,Migrate CPU clamp to c10::complex (#38460)
fe66bdb498,th_aten_frontend,port masked_select from TH to ATen and optimize perf on CPU (#33269)
cae45e416e,skip,add skipIfRocm to TestAutograd.test_memory_profiler (#38790)
d8b9448c62,skip,[pytorch] reorder tracer code in generated VariableTypes (#38308)
c039540d10,caffe2,[Onnxifi] optimize the dispatcher ordering (#38766)
c82b873dbf,complex_frontend,Migrate CPU min max to c10::complex (#38461)
4b248393b7,complex_frontend,Kill AT_DISPATCH_ALL_TYPES_AND_C10_COMPLEX_AND2 (#38459)
90400f48fc,visualization,Enforce tensorboard minimum version as 1.15 (#35952)
51b25218c0,caffe2,Remove deprecated cuDNN API from caffe2 (#38680)
3b254acd99,complex_frontend,support complex types for tanh_cuda and tanh_backward_cuda (#38786)
96d7defb4b,complex_frontend,Revert D21593870: Kill AT_DISPATCH_ALL_TYPES_AND_C10_COMPLEX_AND2
f1991ca8e7,quantization,Interface changes to enable per channel quant. (#37618)
622f5b68f0,quantization,Enable per channel zero point. (#37619)
1f16d4ce1c,quantization,Changes to enable per channel requant. (#37620)
1c9a110b22,quantization,Added per channel kernels for depthwise conv. (#37621)
b8eae1e3b1,quantization,Enabled per channel quantized static linear/conv (#37622)
0a554aeed5,quantization,Changes to enable per channel support on dynamic linear. (#37623)
5b1814e44d,quantization,Added per channel separate test cases for fc and deconv tests. (#37624)
604533ddfa,build_frontend,[CircleCI] Add Python3.8-gcc9 config (#38747)
6736a76cec,rpc,"Back out ""[RPC] [Minor] RPC entry point cleanup"""
5b8a79ab49,InLastRelease,fix the device inconsistency for import convert_sync_batchnorm (#38729)
a7a69ad104,jit,Fast path for contiguous tensor (#38732)
267a8da1bb,skip,Fix broken windows build due per channel quantization stack land. (#38828)
9c88b23fa0,distributions,[bug] Binomial distribution BTRS algorithm has small chance of returning -1 (#38456)
c02e7c464a,opbench,Replace import cpp_benchmark with `torch.utils.cpp_benchmark` (#38832)
83fa3f1c36,profiler,Add HIP to the memory profiler device list (#38795)
f80df4ca79,th_aten_frontend,port `scatter_add` to ATen (CUDA) (#38262)
48116ac8d0,complex_frontend,"Revert ""Revert D21593870: Kill AT_DISPATCH_ALL_TYPES_AND_C10_COMPLEX_AND2"" (#38814)"
6cf5c71b32,skip,Updating submodules
57d6e19d6f,skip,Use union to cast between incompatible function pointers (#38842)
a8d8fc5532,quantization,[quant][graphmode] Different rule for add/add_/mul/mul_ (#38667)
4d5d9c0455,quantization,qat syncbn: add test coverage (#38738)
0b2a861507,quantization,convbn fusion: add backwards compatibility support (#38820)
65e8fe1832,quantization,Perf optimization for conv and gemm kernels. (#37626)
e9902358df,caffe2,Support fp16 output in OnnxifiOp (#38846)
664a3ab5c7,build_frontend,Enable py38 gcc9 build config (#38805)
d363cf4639,bug_fixes_frontend,Fix incorrect __torch_function__ handling in einsum (#38741)
1ea80b4234,amd,[ROCm] Set correct tolerance values for bfloat16 div tests (#38823)
6f0e53624d,skip,Enforce that named_tensor_meta_ is non-null only if there is a non-wildcard name (#38725)
2c2fe6356a,bug_fixes_frontend,Add a check for stride==0 in gradcheck (#38774)
a83f25314b,quantization,Some TODO fixes. (#37829)
0f1669181a,complex_frontend,Add specific list of supported types in autograd (#38325)
b88b7d552f,bug_fixes_frontend,Prevent custom Functions from creating non differentiable type that requires grad (#38326)
3487744821,new_features_frontend,Add `torch.logcumsumexp` (#36308)
07bed4b7ef,performance_frontend,remove redundant contiguous in unfold_backward. (#38871)
bf9395438f,skip,Disable test_nccl for ROCm (#38801)
b9105f42a1,complex_frontend,Kill AT_DISPATCH_ALL_TYPES_AND_C10_COMPLEX (#38792)
4e46c95826,InLastRelease,Fix cpp extension build failure if path contains space (#38860)
a40049fd2a,cpp,Better handling for msvc env when compiling cpp extensions (#38862)
481838f21b,build_frontend,Sphinx parallel build (#38785)
5dd65ba634,build_frontend,.circleci: Add simple backup and restore solution for RCs (#38690)
6d4d508d8e,distributed,Log incorrect device in ProcessGroupGloo (#38844)
acc181c2ea,docs_frontend,Document `torch.utils.cmake_prefix_path` (#38727)
b1982c4bdb,docs_frontend,Fix multiline signatures in docstring (#38768)
0e2a0478af,InLastRelease,Support paths with spaces when building ninja extension (#38670)
9b656dac7f,complex_frontend,Switch AT_DISPATCH_COMPLEX_TYPES_AND and AT_DISPATCH_ALL_TYPES_AND_HALF_AND_COMPLEX to c10::complex (#37697)
f9eb8824f1,bc_breaking_frontend,Remove datatype from Storage and StorageImpl (#38870)
9b9fc59b0a,skip,Add cuda version of clang9 image. (#38825)
d3b0cf9ae9,complex_frontend,Kill AT_DISPATCH_ALL_TYPES_AND_C10_COMPLEX_AND (#38462)
8e69c3be17,jit,"[nvFuser] Reduction support in codegen, fp16 support (#38627)"
455bf77da5,skip,Remove useless copy on zip file load (#36362)
8d8b586c7a,quantization,fake_quant: make qparams shape consistent (#38587)
a53422e0ee,caffe2,[FakeLowp] Open source more c2 ops (#38878)
4c0bf93a0e,skip,Revert D21057090: Remove useless copy on zip file load
22454c5aeb,skip,Collect and upload error logs if VisualStudio installation fails (#38902)
5183e3aa16,jit,[JIT] Rename canonicalize ops (#38734)
f90dc741eb,jit,[JIT] Normalize op aliases (#38735)
cd5d7a34b8,jit,[JIT] Factor out aliases to separate test (#38746)
f3f3097a4c,skip,Use old circleci windows image for both CPU and CUDA (#38909)
d035d05080,build_frontend,[pytorch] expose __ldg(const Half* ptr) to Clang in host mode (#38151)
7e6f6f522f,bc_breaking_frontend,[PATCH]  Migrate min from THC to ATen and remove _min (#38440)
5749ef75d3,skip,Update ShipIt sync
b8f2ecbfb6,rpc,Update TensorPipe submodule (#38923)
ba3893e736,bc_breaking_frontend,Rename `torch._C.Generator` to `torch.Generator` (#38773)
389e16c33b,bc_breaking_frontend,`torch.pow` Add type promotion support and fix issue with __rpow__ (#37098)
c34b333230,bug_fixes_frontend,improve accuracy of logsoftmax computation on cuda (#38945)
f07a60fcd4,skip,Updating submodules
1fa0bb6d9d,build_frontend,Use workspace to persist and restore images for Windows CI build and … (#38971)
b460465a18,mobile,[Mobile GPU][Integration] Vulkan backend integration (#36491)
341fd63ff6,skip,add eq.str op to lite interpreter (#38859)
6ddca30b2d,skip,"Updates assertEqual to require atol and rtol, removes positional atol (#38872)"
81daadf651,skip,Expose VC_YEAR in Windows binary test jobs (#38957)
1fef2075a5,build_frontend,Disable some unsupported module for 32-bit build (#38950)
4d1df74c7c,distributed,Use a temporary file during ReducerTest (#39004)
108321dc41,caffe2,move int8 fc operators and dependencies (#38935)
fc4dfbf700,bc_breaking_frontend,Remove reference of CUDA < 9.2 (#38977)
c82375306c,mobile,"[vulkan] Fix Bazel build, add aten/native/vulkan/stub/*.cpp (#39018)"
583ff947e1,bug_fixes_frontend,Fix max_pool2d for returning wrong shape with return_indices=True on cuda (#38992)
996b6a3d00,mobile,[vulkan] Fix python overrides tests for is_vulkan_available (#39016)
0ff1aa9058,th_aten_frontend,"Port TH cum{sum,prod}_cuda to ATen (#36458)"
e4a3c584d5,bug_fixes_frontend,Fix max_pool2d nchw backward bug (#38953)
224ce03ebe,skip,Revert D21681838: add eq.str op to lite interpreter
c40a79a027,caffe2,[c2] cuda impl for WeightScale op (#38712)
12c219de54,bug_fixes_frontend,Fix histc with empty tensor error (#38987)
0d649efb81,skip,Updates torchvision version (#38848)
ccab142197,jit,Add ROCm-specific half_support_literal for JIT. (#38899)
47869b1b12,build_frontend,Windows build updates (#39035)
8650376444,docs_frontend,DOC: fix import error (#38921)
2751dda7f6,docs_frontend,[docs] fix formula `torch.logcumsumexp` (#38952)
c611b57bd1,improvements_frontend,Add index number to THArgCheck error message (#38978)
2e6ee853ab,onnx,make onnx expect tests resiliant to producer_version changes (#39002)
f188b52b59,bug_fixes_frontend,Fix the issue that Bad interaction between no_grad and numpy conversi… (#38906)
44d418957e,mobile,[vulkan] TensorConversions remove explicit vulkan ifs (#39019)
7e85f6f922,bc_breaking_frontend,Removes pickle deprecation warning (#39003)
eddc3f61d0,build_frontend,Migrate Windows build jobs to VS 2019 for CUDA >= 10.1 (#38959)
ba14a701dc,InLastRelease,restore proper cuda assert behavior with DNDEBUG (#38943)
63e545e0fe,skip,"Revert D21717199: [pytorch][PR] Updates assertEqual to require atol and rtol, removes positional atol"
4fcd1c3123,jit,run te only for profiling executor (#38591)
a25062ab50,jit,[TensorExpr] Fix elimination of For loops with empty bodies (#38883)
362928d5dc,rpc,Remove unneeded const from process group agent header (#38804)
51274b501a,skip,Automatic update of fbcode/onnx to 20b3e10e6c3a9cdab90d2bb864d1c36d3e3651cd (#38203)
2b789e2e03,quantization,[quant] Onnx export of quantized models with new API (#38736)
de8c888232,bug_fixes_frontend,Fix torch.hub.hub_dir inconsistencies (#38969)
93d87a16eb,skip,Revert D21493165: Automatic update of fbcode/onnx to 20b3e10e6c3a9cdab90d2bb864d1c36d3e3651cd
916084d933,jit,[JIT] Allow @torch.jit.unused to be used on TS classes (#38522)
9b95f757af,jit,move num_profiled_runs to common_utils (#38687)
13120bf677,skip,"Updates assertEqual to require atol and rtol, removes positional atol (#38872)"
b7882f9bd6,skip,Improve cpu/Loops.h arity asserts. (#38809)
bbb5e106ad,skip,Improve error checking of CUDALoops. (#38810)
45f32ceb4e,skip,Move needs_dynamic_casting to a non-CUDA specific file. (#38813)
d627f2b174,skip,Support void return type in TensorIteratorDynamicCasting checks. (#38815)
b789c1790f,build_frontend,Update to use the stable windows image instead of the temporary one (#39066)
7f1c9886cd,onnx,[ONNX] Enable models tests (#38791)
626048efd3,build_frontend,Fix Windows binary jobs after migrating to the new circleci image (#39057)
1093e26d72,amd,[ROCm] HIP version guard for occupancy API compatibility (#38551)
d08a30a300,rpc,[TensorPipe Agent] Improve Response Error Message on Agent Shutdown (#38818)
e07ee1954d,rpc,[TensorPipe Agent] Message on Agent Shutdown (#38819)
0edf063c24,onnx,Enable Constant Folding Tests (#38751)
dfc4be205e,docs_frontend,Fix broken reference in sync bn doc (#38890)
53b55d8f38,cpp,Use ninja build as default for HIPExtensions (#38939)
3d2fce6bc3,bc_breaking_frontend,Change len(DataLoader) for IterableDataset (#38925)
1c74d965ed,skip,Fix attribute warning on gcc (#38988)
df4066bbb6,skip,Simplify precision-specification in tests. (#37181)
b636f5e324,caffe2,change the int8 test to use unquantized bias (fp32)
30063347e7,performance_frontend,remove serial_exec from scatter/gather kernel (#36181)
c835dedce9,bc_breaking_frontend,Fix the issue that PyTorch doesn't construct bool tensors from non-bo… (#38392)
c6e9e9359f,skip,[Codemod][GleanFbcode] Remove dead includes in caffe2/test (#39023)
248758d702,mobile,Expose qnnpack's maxpool when going through aten::max_pool2d (#38896)
bb12e4dca0,quantization,Add JIT fusion pass to fuse quantized add and relu. (#38897)
4239416c72,bc_breaking_frontend,Throws runtime error on attempted addcdiv integer division (#38762)
898d062bfd,caffe2,[disagg_acc] In batch broadcast (#38700)
20397285c6,skip,Replace use of np.allclose in tests. (#34287)
ff2e29144c,skip,Refactor backward compatibility tests to use override_qengines decorator (#38838)
fa184c351f,jit,[JIT][to-backend] Fix compilation unit and name mangling of generated module (#38679)
30dd4acbf6,skip,Test PyTorch using python-3.8 + GCC-9 on Bionic (#39030)
b12a879184,InLastRelease,Correct Javadoc link to master (#39038)
0f1f0a1f35,build_frontend,update circleci scripts for rocm ubuntu bionic support (#39097)
cf8001d2d0,jit,[TensorExpr] Fix a bug in Rfactor when there are multiple reductions (#38733)
d92ef9268d,skip,Revert D21728402: Simplify precision-specification in tests.
988e31c788,skip,Revert D21752017: [pytorch][PR] Test PyTorch using python-3.8 + GCC-9 on Bionic
90a8cdfdbf,skip,Automatic update of fbcode/onnx to eae3eb8c61cf5ad27cc9a416dbdc5274982385a6 (#39089)
05f097b5bb,new_features_frontend,Implement logaddexp (#38384)
b0420cc2de,caffe2,[Caffe2] Change shape_hints format (#39100)
01815be1e4,rpc,Infinite timeout for operations against ProcessGroup for RPC (#38577)
f5bc91f851,skip,Get rid of multiple inheritence in test_torch (#39110)
7543e7e558,th_aten_frontend,"Migrate minall, max, maxall from THC to ATen and cleanup THC (#39029)"
e088902b4a,jit,Add type-hint check for default arguments in TorchScript C++ frontend (#39021)
0d4eefcd82,skip,fix comments in gradcheck (#38877)
7e16dd299a,amd,[ROCm] enable mem leak check for rocm (#35953)
5702a28b26,skip,Fix index overflow in ConvTranspose3d (#38970)
bfcb687b9c,bug_fixes_frontend,Nearest interpolation gpu implementation fix [Resolves issue #38985] (#39055)
78acc9dffb,complex_frontend,Check reinterpret_cast of complex bidirectional (#38882)
1d1f16079d,quantization,[quant] Add save/load state_dict to quantized dynamic RNNs (#39105)
7b90ed1117,rpc,[TensorPipe] Pass names of endpoints to context/pipe for easier debugging (#38926)
7866854184,rpc,[TensorPipe] Add cases for TP in RPC test helpers (#38927)
0413e1e624,rpc,[TensorPipe] Fix timeout computation (#38928)
510971f86c,rpc,[TensorPipe] Fix lock inversion upon response read error handling (#38929)
eaca6f32b0,rpc,[TensorPipe] Do not mark future messages as complete after they have timed out (#38931)
49e4e41fdc,rpc,[TensorPipe] Always complete futures from thread pool (#38930)
54046c1024,rpc,[TensorPipe] Implement join correctly (#38933)
65aa2b65e5,rpc,[TensorPipe] Close and join TP context at shutdown (#38934)
72f2ff5950,rpc,[TensorPipe] Improve serialization (#39010)
377a355bcc,rpc,[TensorPipe] Detect duplicate worker names (#39011)
f58cc4b444,rpc,[RPC] Fix flaky test by waiting for async rref calls (#39012)
c2133179a9,skip,add overload name for op eq.str
7e1cc2daa5,skip,Revert D21729544: add overload name for op eq.str
b98948e6dd,distributed,implement dynamic bucket order in DDP (#35137)
5267b17a96,bug_fixes_frontend,Revert D21748644: [pytorch][PR] Fix index overflow in ConvTranspose3d
e029d678b6,improvements_frontend,Make collect_env more robust on Windows (#39136)
d26f7f09b5,skip,Fixup: rename BatchedTensorKey to Batched (#38798)
5e975cf8d6,bc_breaking_frontend,Stops cross-device data movement in tensor iterator (#38998)
feaf72088c,complex_frontend,short-circuit pow for complex 1 and 0 exponents (#39117)
7b343cc30f,skip,.cirlceci: Remove setup job (#39081)
ee3bd10445,skip,Moves angle/abs test to test_torch (#39154)
928e99b9bb,mobile,[vulkan] jni build support USE_VULKAN (#39188)
0b9d537056,caffe2,[dper][pruning] add histogram op (#38514)
9c19a12965,InLastRelease,fix asserts in cuda code (#39047)
0e8c65f756,skip,Add timeout to TestBottleneck (#39191)
41363b299a,skip,test_bottleneck_cuda works on ROCm 3.3 (#38249)
98a755bc8f,complex_frontend,Migrate AT_DISPATCH_FLOATING_AND_COMPLEX_TYPES_AND1 to c10::complex (#39045)
527ee63b7d,quantization,fused convbn: respect the strict argument when loading from state dict (#39205)
f7a8851e9e,skip,Fix argmin/max bug (#38946)
a04fb2ab22,build_frontend,[Reland] add xenial + cuda 9.2 + gcc 5.4 CI test (#39036)
ca6579bd40,skip,Regenerate config.yml (#39215)
2f49757372,th_aten_frontend,"Remove sumall from TH, THC, THCUNN (#39042)"
2331853236,caffe2,[caffe2] Fix the correctness check for GivenTensorFill operator
d0650af2fb,bug_fixes_frontend,Change __CUDACC__ and __HIPCC__ to __CUDA_ARCH__ and __HIP_ARCH__ in NumericUtils.h (#39213)
b08a4aaf3b,mobile,[PyTorch] Fix operator perf observer index issue.
fce01a9bab,jit,[JIT] Make new zip serialization for torch save/load significantly (~70%) faster (#38379)
debb7ba6f4,rpc,Update TensorPipe submodule (#39189)
587d453b0f,rpc,[TensorPipe] Ignore expected errors (#39182)
3ac0ec3dab,rpc,[TensorPipe] Don't use separate heap allocation for metrics (#39183)
99f6df3c07,rpc,[TensorPipe] Bind to hostname's IP address instead of localhost (#39184)
d1212e5814,rpc,[TensorPipe] Use PrefixStore to avoid conflicting keys (#39185)
d6715e6364,improvements_frontend,Improve warnings to actually point at user code (#39143)
4b5e87f94a,skip,Revert D21751663: [pytorch][PR] Fix argmin/max bug
10e2126b10,complex_frontend,"support complex types for `cumsum`, `cumprod` (#39063)"
b44f02f8f5,skip,Fix windows upload jobs (#39249)
f44fca882e,caffe2,Update NNPI backend to v0.6.0.5 (#4539)
86f46ac9ca,skip,Fix assertNotEqual error reporting (#39217)
7836eaceee,jit,[JIT] JIT should let people know we inferred an argument as a tensor (#38527)
85d0292c14,quantization,[quant][graphmode] Cleanup inplace API (#38827)
c25b3d4305,amd,"[ROCm] in test_cuda.py, re-enable skipped tests (#37952)"
a5d44800f0,InLastRelease,Implement CUDA_KERNEL_ASSERT for MSVC (#39218)
29c04acdbb,caffe2,Followup for cuda assert cleanups (#39220)
88c5fd94e7,caffe2,[nnpi eval] enable int8 eval with emulation Int8FC (#39112)
c3d3782c80,bug_fixes_frontend,Fix init-shutdown race condition in autograd engine (#39194)
a50d781c03,complex_frontend,Added real and imag views as tensor attributes (#39033)
1d0ec50a02,quantization,[quant][graphmode] Rename _quantize_script.py to quantize_script.py (#39122)
1c67c3d587,caffe2,test_fc_nnpi_fp16.py test_fc_num0_fix fix (#39248)
a5e023f28a,profiler,Set RecordFunction id only when needed (#39265)
7ab96461d0,caffe2,Remove some unnecessary code in Onnxifi (#39197)
001102c50c,skip,Avoid a TensorIterator/Loops reinterpret_cast in a test. (#39246)
9cacbe29e5,quantization,[quant] Add reduce_range argument for qlinear_dynamic (#39041)
25a6c5f60f,quantization,[quant] Dynamic Linear module to use reduce_range (#39125)
b0d6e4b604,InLastRelease,work around building onnx in older rocm docker images (#39253)
c02cb7aa08,caffe2,[nnpi fake ops] bug fix int8QuantizeNNPI (#39271)
b7b99ab0c8,onnx,[ONNX] Remove Aten ops from ONNX export (#37239)
fcef43965b,caffe2,[AMD] Fix broken test (#39297)
928ce29ee2,skip,Refactor c10::complex and cleanup c10::Scalar (#38593)
8556664d68,skip,Revert D21769463: [pytorch][PR] Refactor c10::complex and cleanup c10::Scalar
f872cf5ed0,jit,Add %= support in TorchScript (#38983)
68e62b9ab6,skip,Use TensorMethods.cpp (#37639)
5153cdbe87,jit,[TensorExpr] fix a bug in ReorderAxis when there are trailing loops (#38841)
caaea084e9,caffe2,[caffe2] minor typo fix in fused_rowwise_nbitfake_conversion_ops.h comment (#39315)
f9edbda7d7,skip,Loops: Separate out dynamic_casting concerns from complex overloads. (#39254)
9b05b1bacf,skip,Make needs_dynamic_casting multiple-complex-type aware. (#39255)
aa5afbdb92,misc,Add dynamic_cast asserts to CPU Loops. (#39258)
a566451017,complex_frontend,Migrate AT_DISPATCH_FLOATING_AND_COMPLEX_TYPES_AND2 to c10::complex (#39285)
dc4fd0409f,docs_frontend,DOC: remove java documentation (#38920)
7773a45c0d,bug_fixes_frontend,Division by zero crashes for fmod operator(#32699) (#38919)
1943a2c317,docs_frontend,Fix missing code in 'Installing C++ distribution of Pytorch' (#39237)
2fe0fc2684,skip,Revert D21374247: Use TensorMethods.cpp
c193bd41f5,quantization,fake_quantize: respect device affinity (#39031)
42b2dee6c2,bc_breaking_frontend,`verbose` unused in `torch.backends.cudnn` (#39228)
07518e120b,jit,[nvFuser] add torch.jit.fuser context manager (#38993)
ddf6d49445,skip,Avoid defining bogus CPPTypeAndStdComplexToScalarType<void> by using some decltype tricks. (#39261)
78244f8129,skip,Kill CPPTypeToScalarType. It's now subsumed by CPPTypeAndStdComplexToScalarType. (#39263)
39d037253c,skip,Test PyTorch using python-3.8 + GCC-9 on Bionic (Reland) (#39121)
bdaa78499e,complex_frontend,Reland Refactor c10::complex and cleanup c10::Scalar (#39306)
45baf0e1a0,rpc,[Profiler x RPC] Enable RPC Server Global Profiler (#38847)
2b6a48e962,skip,Remove supports_named_tensor from codegen entirely. (#38739)
cffa0bee04,skip,Don't generate DeviceGuard for CPU wrapping code. (#38806)
f76e05a2e1,skip,Automated submodule update: FBGEMM (#39322)
6d3e4aa0f9,jit,Made sure torchscript compiles in optimized mode (#38888)
7f1a96d43c,caffe2,Adding sparse Lp regularization operator to Caffe2 (#38574)
a3c87c4922,bug_fixes_frontend,Make Optimizer.state_dict() nondeterministic (#37347)
48e66859c1,InLastRelease,"Check illegal output dtype for torch.{min, max} (#38850)"
295a23f43f,rpc,[Futures] Added markCompletedIfNeeded API (#39080)
e6d86036e2,bug_fixes_frontend,Fix return types of Windows API functions in __init__.py (#39334)
c5def603a7,skip,Use @skipIfNoFBGEMM instead of direct check (#39068)
7b07208d86,caffe2,[Onnxifi] Generic way of passing output shape/type hints (#39229)
e286cb5e81,caffe2,Revert D21781515: [Onnxifi] Generic way of passing output shape/type hints
f117089810,performance_frontend,Restore thrust path for 1d tensors cumulative ops (#39180)
a47e2d4488,rpc,[Futures] Allow setErrorIfNeeded arg to have type FutureError (#39113)
3001facd7a,distributed,[doc] [distributed] fix typo (#39264)
625f4e39a7,quantization,[quant] Fix fusion pattern for add_relu (#39367)
f29fa06c52,quantization,[quant][graphmode][fix] Run preprocess for child module before parent module (#39368)
f16b04f8b3,caffe2,[caffe2] Update shape info delimiter (#39275)
ed26e8b0a0,caffe2,Resubmit [Onnxifi] Generic way of passing output shape/type hints (#39377)
858ab75046,onnx,ONNX Export Support for Celu (#38243)
f4365cf5ba,jit,[JIT] Add support for saving/loading of lowered modules (#38893)
68f23d566a,jit,[pytorch] Let jit.unused ignore unsupported method signature (#39336)
413f023784,complex_frontend,"Clean up cast from c10::complex<T> to thrust::complex<T>, and update the workaround CUDA version to <10.2 (#38941)"
283a3ff16d,bug_fixes_frontend,The exception raised when RandomSampler.replacement is non-boolean should be TypeError (#36547)
de5b8797e6,dispatcher,Remove unboxed only from AMP registrations for cat. (#39156)
e142d70383,rpc,[TensorPipe] Guess IP addr in separate function (#39397)
e358adb42c,rpc,[TensorPipe] Acquire lock when adding message to timeout map (#39398)
30146d7391,bug_fixes_frontend,More fixes about using Windows API through ctypes (#39376)
85b3fa031c,caffe2,[WIP] Layernorm Fake FP16 Op. (#39103)
b3fac8af6b,caffe2,"Initial support for building on Ampere GPU, CUDA 11, cuDNN 8 (#39277)"
bb0377bb24,rpc,Expose torch.futures.Future (#39008)
b5cd3a80bb,bug_fixes_frontend,"Return `None` instead `False`, and return `bool` to `None` in type stub (#39324)"
11f1014c05,improvements_frontend,Adding lost extra_repr() and __setstate __() to activation.py (#39084)
35719cdc85,bug_fixes_frontend,Fix some bugs of argmin/argmax and min/max (#39212)
cca29f2969,caffe2,[Onnxifi] Support quantized output in Onnxifi (#39230)
8bc5a4939f,mobile,Add prim::data to lite interpreter (#39335)
c3ddb3f7a4,amd,Add rocm image to circleci docker builder (#39262)
04ac41fe70,caffe2,[caffe2] format video_input_op_test.py (#39381)
fca928cabf,caffe2,[caffe2] fix test error in video_input_op_test (#39382)
a6f0051db2,rpc,Fix test_get_and_set_timeout for TensorPipe Agent (#39353)
0d96f26404,skip,"Kill THC_logical{Value, Tensor} (#39069)"
58cb369dfa,quantization,Replace calls to contiguous with contiguous(suggested memory format) (#38433)
09bea13981,complex_frontend,support flip and rot90 for complex dtype (#37826)
a864dbb360,InLastRelease,Make `_C` extension a thin C wrapper (#39375)
71af538e31,improvements_frontend,Updated assert to remove check on 3rd dim for MHA (#39402)
89c0efb30b,skip,Also set CMAKE_C_STANDARD for MSVC (#39304)
c6720f0d6b,docs_frontend,nit on functional autograd (#35493)
ebd4125e7e,jit,[JIT] Make torch.unique_consecutive compatible (#39339)
8638df45ae,caffe2,call DoRunWitType on Layernorm (#39409)
f166b934ee,jit,[JIT] Kill _cast_* operators (#39348)
36607c85ee,jit,[TensorExpr] eliminate zero length Allocations in IRSimplifier (#38794)
a952f9bb06,skip,"Fix for num_threads==1 in OpenMP ""parallel for"" (#36479)"
abe2be2063,build_frontend,[resubmit] Use TensorMethods.cpp (#39385)
15ad9dd30f,onnx,[ONNX] Bump up ONNX submodule to a82c6a7010e2e332d8f74ad5b0c726fd47c85376 (#39372)
a05ef17e46,rpc,Add rpc.functions.async_execution decorator for rpc_sync/rpc_async (#39216)
7417b4c66f,bug_fixes_frontend,Fix index overflow in ConvTranspose3d [attempt 2] (#39198)
3f099879f7,rpc,[TensorPipe] Re-enable RPC tests (#39406)
c767d65caf,dispatcher,"Added FPGA DispatchKey, DeviceType, Backend (#38938)"
aea09f5155,bug_fixes_frontend,Leak safety in RReLU (#39347)
b1dab266f7,rpc,[TensorPipe] Re-enable dist autograd tests (#39440)
5beb3b0c53,rpc,[TensorPipe] Re-enable dist optimizer tests (#39441)
884e16b41a,InLastRelease,`as_strided` : add size and stride length check (#39301)
6a60a8c1da,quantization,add_observer: respect device affinity for ReLU (#39337)
21ba3b4f40,bug_fixes_frontend,Fix `torch.backends.cudnn` mypy error (#38947)
ec5d579929,skip,.github: Add initial target specifier config (#39378)
5d2cfb3d4c,cpp,[torch] remove integer conversion resulted in a change of sign warning (#38968)
46447045ea,skip,Replace torch.allClose with self.assertEqual (#39424)
5cfd1a190e,skip,Do not call optimizations within freezing API (#38499)
dbec0febd2,docs_frontend,Update key_padding_mask arg docs in MHA module (#39321)
2ed4ed8733,jit,[TensorExpr] Fix two bugs in Rfactor (#39268)
e4657fe194,skip,Revert D21579607: [pytorch][PR] Do not call optimizations within freezing API
d31e84497c,jit,[TensorExpr] some cleanups / fixes for LoopOptions (#39408)
9ed5efda47,skip,Adds TestCase.compare_with_numpy (#39179)
cb530fcd3c,skip,Enable some test cases in `test_memory_format_operators` (#38648)
c0d3d2f60f,skip,Retry/skip test on URLError rather than on HTTPError (#39477)
d137710a64,caffe2,LayerNorm Fake FP16 Op debug (#39476)
5b23f56d5a,mobile,"Selective build on Training, query based. (#39452)"
3370c045ae,complex_frontend,Remove copy_imag and copy_real methods (#39065)
adc13432fe,mobile,Enabling lite interpreter in torch python API (#39181)
4f7c7e2e76,caffe2,[caffe2] compute r_correction only for radam to avoid sqrt(negative) (#39393)
4d880c0693,improvements_frontend,Device and torch._C function cleanup (#38173)
0102bbf01e,mobile,move to.prim_dtype to lite interpreter (#39456)
2f7f47eba1,onnx,[ONNX]Enable tests in test_operators.py (#39431)
cc991bbf19,caffe2,fix internal targets for layernorm (#39501)
4d597cb794,onnx,[ONNX] Update pytoch/onnx doc (#39480)
0829cadca3,new_features_frontend,"Implement rad2deg, deg2rad (#38852)"
67cea74dd3,rpc,Add rpc.async_function decorator for TorchScript functions (#39267)
4a0a38c17a,skip,"Revert D21652452: [pytorch][PR] Fix for num_threads==1 in OpenMP ""parallel for"""
03eca384fd,performance_frontend,Optimize GroupNorm on CPU (#28203)
72b0447f8d,dispatcher,[pytorch] move tracing logic to a separate dispatch backend (#38467)
8b2bb02e09,rpc,Implement timeout support for RRefs (#38590)
92c6776761,skip,Fix lint (#39517)
11a60b9942,complex_frontend,Clean up thrust::complex from rsqrt (#39294)
002b19da92,jit,Add SymbolicShape and replace all uses of VaryingShape<ShapeSymbol> with it (#38544)
ac25267753,skip,fix build table for ppc64le (#39475)
af91df68ed,amd,Remove cuda init patch (#39222)
b4aceb3884,skip,Fix lint (#39527)
ada2652ca6,jit,Restore docs coverage test via sphinx (#39331)
335e4a1e3b,new_features_frontend,"Add arcosh, arcsinh and arctanh to unary ops (#38388)"
7680358122,skip,Move some of the definitions in LegacyNNDefinitions.cpp closer to sites (#37531)
eb5e0376a2,mobile,Selective enabling of xnnpack based max_pool2d in ceil_mode. (#39447)
7676aa79ec,skip,.circleci: Move binary builds into their own workflow (#39379)
49b69b2ade,jit,[JIT] fix broadcasting lists of ints (#39481)
fe684679b0,bug_fixes_frontend,Fix overflow issues when unpacking large numbers (#39140)
da2004e132,skip,Upgrade lint. (#39483)
4e5af8d146,onnx,[ONNX] Fix type casting for reduce ops (#38829)
da2f8c9f1f,jit,deepcopy() of Objects should call __g/setstate__ (#39500)
8811e4d00d,jit,Add/fix typing annotations to some functions (#39075)
b861daf098,jit,Reduce time spent per guard by comparing TensorType with Tensor (#39098)
2a513a6a2b,skip,Do not raise decorator (#39532)
ed12df64ca,caffe2,misc updates to fake fp16 tests (#39405)
da8191a9ad,jit,Remove useless copy on zip file load (#36362)
f94a171e6f,quantization,[quant][graphmode] Test for another type of ops in insert_observer for if (#39380)
17aebe909f,caffe2,Added Operator_Schema's for missing FakeFP16 Operators (#39363)
7d56ef27ee,caffe2,Bumps supported file format in anticipate of torch.div changes (#39529)
876b9591dc,quantization,"Refactor unittests for activation functions relu, elu, and sigmoid (#39190)"
fa4ed17183,rpc,Explicitly decref in UnpickledPythonCall dtor (#38398)
11abb75362,rpc,Make @rpc.functions.async_execution processing generic (#39485)
8a6914ddb2,rpc,Add @rpc.functions.async_execution for rpc.remote (#39486)
9bfb91b50b,rpc,Fix possible deadlock in _wait_all_workers (#39535)
baf6ed0238,rpc,Release GIL when deleting users and unforked owners (#39555)
e2a178ca21,caffe2,Update cafe2 hypothesis_test_util to support hypothesis-5 (#39498)
77798a45a6,bug_fixes_frontend,Un-inline Functions.h into Functions.cpp (#39446)
51504cb8dd,bug_fixes_frontend,Fix IDE hint channels_last & preserve_format (#39120)
a6690bdb5b,caffe2,fix input schema check for spatialbn
0031108b60,jit,Support torch.Tensor subclass (like Parameter) input. (#39487)
88fe05e106,docs_frontend,"[Docs] Update torch.(squeeze, split, set_printoptions, save) docs. (#39303)"
97a2918a07,jit,reduce number of bailout nodes (#38281)
545a3e1eca,amd,Remove test_nccl from ROCM_BLACKLIST and enable only a couple of test_nccl tests (#39354)
e35199a691,opbench,observer bench: add CUDA (#39360)
e29d873e68,improvements_frontend,disable autograd while preparing Tensor for printing (#39420)
834569232b,caffe2,[online trainer] Add blob reorder (#39534)
856215509d,jit,[jit] update to serialization doc (#39025)
3669e45736,jit,[jit][subgraph_matcher] Enable regex matching for string attributes of node (#39454)
6a75f650dd,quantization,Implement Quantized Version of Threshold Function (#39352)
53c19423cf,rpc,Update TensorPipe submodule (#39598)
f2af07d7f6,skip,Fix circleci postnightly jobs (#39627)
479b04e26a,distributed,Improve DistributedSampler docs and add seed option (#39628)
b28422d444,jit,add overload name for str cmp (#39607)
644d6a09e6,jit,add overload name for aten::as_tensor (#39610)
2da5444221,bug_fixes_frontend,[Resubmit] Fix argmin/max bug (#39576)
e4627e5dba,quantization,[quant][graphmode] Fix add_relu patterns for scripting and tracing (#39455)
9db27a50b4,dispatcher,[pytorch] add operator name to callBoxed() error message (#39562)
183b04da3e,dispatcher,[pytorch] remove tracing logic from gen_variable_factories.py (#39514)
a25b1b918b,skip,Fix __STDC_FORMAT_MACROS redefinition issue for TypeDerived (#39608)
faf0a3bd7a,misc,Move bernoulli_() to DistributionTemplates (#38558)
6d13b583a7,quantization,[quant][graphmode] Support conv*d_relu in traced models (#39490)
67115b226a,quantization,[quant][graphmode] Dynamic Quant Do not depend on input shapes (#39412)
8a4597b808,quantization,[quant][graphmode] Dynamic quantInsert observers for module output (#39458)
26bc272793,quantization,quant: clean up normalization channels_last handling (#37802)
f9b675f7b6,quantization,groupnorm: eager static quant support (#39090)
2140874228,quantization,instancenorm: eager static quant support (#39091)
202625ba9e,quantization,groupnorm: eager mode QAT support (#39092)
b530176d10,quantization,instancenorm: eager mode QAT support (#39093)
952deba828,quantization,layernorm: eager mode qat support (#39094)
b443ca26c5,quantization,groupnorm: graph mode static quant support (#39095)
ebdff07d49,quantization,instancenorm: static quant graph mode support (#39096)
614dd03272,performance_frontend,Optimize GroupNorm on CUDA (#28204)
8177637374,jit,remove duplicated op schema for aten::pow (#39606)
b06b792bbd,jit,remove double registered ops (#39609)
ee2bc13f44,skip,Fix smoke test jobs (#39638)
1db4a31d92,quantization,[quant] QNNPACK deconvolution packing (#37405)
6c56671fd9,jit,[jit] avoid pre-convert tensor to cpu in pickling (#38898)
172f31171a,quantization,[quant] QNNPACK deconv kernel and tests (#36790)
b83fed8d4c,rpc,[futures] Add c++ ivalue::Future collectAll() helper (#39119)
820e81ba09,jit,add overload name for min/max with list input (#39614)
e41fe60867,bug_fixes_frontend,Add error message when negative stride is passed to as_strided (#39508)
a83f7a1d70,skip,Revert D17923732: Optimize GroupNorm on CUDA
e3e8f24cbe,InLastRelease,Remove duplicate 'with_gil' declaration. (#39540)
e4f9c74db3,InLastRelease,add dtype checks for scatter/gather family of functions. (#38646)
cc2f7fa502,skip,Revert D21930435: Revert D17923732: Optimize GroupNorm on CUDA
ab6c447f59,amd,[ROCm] Enable AMP autocast tests on ROCm (#39616)
a2125135ee,skip,[predictor] move fblearner/predictor to platform009
397b24bb37,rpc,Cleanup rref_impl (#39530)
df2d19723a,skip,c10/util/complex_math.h and c10/util/complex_utils.h should not be individually included (#39276)
83dd56632e,jit,Fast tanh for the LLVM backend. (#39528)
8251f1872f,skip,.circleci: Move ecr gc build job to ecr gc workflow (#38523)
bba30d1bd8,bc_breaking_frontend,Add undefined tensor gradient support to all backward functions (#39400)
0147216a46,rpc,[TensorPipe Agent] Documentation fixes and nits (#39467)
84d8d68397,skip,.circleci: Fold postnightly workfow into nightly (#39669)
b7b7433561,build_frontend,setup: Add long description to wheel packages (#39676)
dd5aa1fb22,skip,Cleanup unused args in max_unpooling3d (#39664)
9551fb22d6,quantization,[quant][graphmode] Preserve numerics in debug option for clamp ops (#39219)
8004d35979,skip,Remove tuple from reduction (#39433)
64192ca3da,skip,Skip unit tests relying on MKL if compiled without it (#39672)
1f7557d173,th_aten_frontend,Migrate `diag` and `trace` from TH to ATen (CUDA) (#36876)
d1cdf1fd56,docs_frontend,update convert_sync_batchnorm docs (#39646)
afb2d27b24,complex_frontend,Migrate AT_DISPATCH_FLOATING_AND_COMPLEX_TYPES to c10::complex (#39296)
e033db0477,rpc,Enable RRef timeout for tensorpipe (#39531)
d493918436,rpc,[dist_autograd] expose distributed backward C++ API (#38656)
f32c9eb579,jit,[jit] register distributed backward (#38494)
9f71997380,jit,some refactor on register_distributed_ops (#38657)
0251ba6108,onnx,Fix ONNX export of RNNs with no bias (#36894)
1790d35848,skip,Skip `test_minmax_illegal_dtype` on XLA (#39693)
aa5ccf9626,skip,Kill dead pairwise ops in THC (#39070)
338a1ccce5,rpc,Fix error handling for rpc.remote (#39605)
af05158c56,skip,torch.multinomial : fast-path for replacement=False (#39636)
7d85e77076,rpc,Use atomic operations to manipulate current RPC agent (#39663)
4ec86ca5ba,mobile,[iOS] Disable depthwise3x3_winograd on iOS (#39591)
9733390998,new_features_frontend,"Add `torch.flip{lr, ud}` (#38599)"
8565ae5a76,skip,Revert D21925406: [pytorch][PR] torch.multinomial : fast-path for replacement=False
18073ffca3,skip,Add tests for mismatched dtypes in torch.gather. (#39689)
3413f0a8ca,build_frontend,Fix dll load failure in virtual environments on Windows (#39622)
f1c60c04b8,jit,[JIT] Fix module interface test (#39592)
2633a9cca1,skip,Adding LpNorm regularization for sparse features in DPER3 (#38582)
f31aca3a11,skip,Cleanup cuda install scripts for Windows jobs (#39712)
3bdbb27ddb,bug_fixes_frontend,Fix Gather::apply accessing moved tensors (#39733)
b84a7fbbc1,bug_fixes_frontend,Fix error message in autograd (#39729)
f1e6e56641,docs_frontend,Add aarch64 ci badge (#39698)
0f39ed86a7,build_frontend,Cleanup debug info switches with MSVC (#39703)
4e30146368,build_frontend,Use `ProgramFiles` environment variable on Windows (#39707)
428bc90978,jit,[JIT] add dtype as type annotation (#39741)
c902146ba4,quantization,[quant][graphmode][refactor] propagateQuantizationOps (#39550)
bccf8831b8,skip,Allow initializing TestCase() outside of unittest.main() (#39695)
be3bbfc917,rpc,[futures] Add collectAny() to ivalue::Future for completeness (#39597)
4c5a808d37,caffe2,avoid dividing by 0 in div unit test (#39736)
56289ba31f,jit,[JIT] Improve error message when type annotation Future without a contained type (#39751)
e46060701d,caffe2,[caffe2] Fix of initializing ATen's CUDA before using caching allocator (#39759)
2a06a6935c,quantization,[quant][graphmode] Support propagate dequantize for nodes with multiple outputs (#39551)
0fe1ec3ce0,quantization,[quant][graphmode] Test weight observer for dynamic quant (#39687)
1b99be9088,jit,Freezing Module containing fork subgraphs (#37044)
3cf9b7d9ea,skip,move mm_cpu from BlasWrappersCPU.cpp to LinearAlgebra.cpp and delete the former file (#39700)
2193fa119e,jit,[JIT] consider side effects when trying moves in alias analysis (#39497)
307920731d,mobile,[iOS] Add nonVarTypeModeGuard to fix the unit test (#39743)
6bdfd6ae1a,jit,[TensorExpr] Fast sigmoid for LLVM (#39717)
9111ae7782,jit,Preserve user specified attributes and methods (#38830)
be13388adb,complex_frontend,Migrate AT_DISPATCH_COMPLEX_TYPES to c10::complex (#39564)
7cb4eae8b1,docs_frontend,correct some cpp extension code usages and documents (#39766)
acc13ac828,distributed,[PyTorch] Make DDP reducer work under distributed autograd (#37998)
0aecbbb762,bc_breaking_frontend,"Changes TensorIterator computation to not consider out kwarg, lets UnaryOps safe cast to out (#39655)"
2d589bc9da,quantization,[quant][graphmode] Fix a corner case in handling `if` in insert_observers (#39615)
9ba2530d42,amd,[ROCm] explicitly embed version within image name (#39735)
b1750cb884,misc,always resize_ min/max outputs (#39696)
08105a0068,performance_frontend,Remove unnecessary !op.is_read_write test in compute_names/compute_shape. (#39747)
7994d6e147,quantization,[quant][graphmode] Support quantization for `aten::append` (#39644)
4e892bd99c,rpc,[Easy Review] Fix ProcessGroupRpcBackendOptions Doc (#39787)
c22bbb2124,jit,[JIT] Add Type::repr_str to return human-readable str (#39544)
68b8740611,rpc,Update TensorPipe submodule (#39783)
d04a3fcc42,misc,Refactor CUDA bernoulli_kernel by using uniform_and_transform (#39652)
eb7843ed01,quantization,[quantization] Remove duplicated piece of code in test (just a nit). (#39770)
3fb1e73a4e,rpc,Add rpc.async_execution support for rpc.remote on script functions (#39758)
6748fbd38a,jit,Remove `MultiheadAttention` weights from constants (#39768)
a1071e5d36,jit,Fix parsing of subscript expressions using python resolver (#39269)
7f55197a57,jit,Peel Loop (#39434)
a5fbd3ef8a,mobile,[vulkan][build_fix] Fix Vulkan Build; Prepacking uses new register api (#39771)
cb519801d6,skip,[vulkan][CI] CI android build abi x86 with USE_VULKAN (#39767)
95489b590f,bc_breaking_frontend,Throws runtime error when performing integer division using torch.div (#38620)
bfa76ff407,docs_frontend,[Doc] Clarify that variance estimor is biaised for normalization layers (#39752)
be838504a3,skip,Remove `THTensor_(fill)` & `THTensor_(zero)` (#39727)
96870181c6,docs_frontend,Remove duplicated entries in `random.rst` (#39725)
262dbdf0a5,caffe2,[caffe2/nomnigraph] handle when PATH env is not defined (#39373)
780fa2b489,bc_breaking_frontend,Switch torch.save to zipfile serialization and swap quantization to that (#39460)
97dfdaaad8,performance_frontend,torch.multinomial : fast-path for replacement=False (#39742)
4c4b9916ef,skip,Include AT_PARALLEL_OPENMP/AT_PARALLEL_NATIVE/AT_PARALLEL_NATIVE_TBB to ATen/Config.h (#39612)
f8561acb13,quantization,graph mode: add docs to pre-calibration passes (#39683)
5c10b17491,quantization,graph mode: more docs for insert observers pass (#39739)
94dfc76e3f,quantization,graph mode qat: make fake_quantize scriptable (#39750)
5d2f6d86e5,quantization,graph mode: add quantization type enum (#39795)
a752832da9,docs_frontend,Fix `Tensor.tolist` signature in the docstring (#39732)
e399e470b6,mobile,[vulkan] speed_becnhmark_torch add vulkan arg to use Vulkan backend (#39076)
425927bb2b,quantization,[quant] Add reduce_range params for quantized_lstm (#39604)
e1392922f2,quantization,[quant] Enable per-channel quantization for LSTM Modules (#39666)
c3d4053bc0,quantization,[quant][graphmode] Support quantized::batch_norm2d_relu fusion for tracing (#39645)
ba27fd04d3,bug_fixes_frontend,Fixes type promotion for `cat` (#39777)
1360bb986c,skip,Revert D21976091: [vulkan][CI] CI android build abi x86 with USE_VULKAN
2d1cf950bb,skip,Impose maximum level restriction for BatchedTensors (#39580)
aaaf2eb6b3,skip,"Add batching rule for torch.sum(tensor, dims) (#39581)"
da3073e9b1,skip,Revert D21960728: Include AT_PARALLEL_OPENMP/AT_PARALLEL_NATIVE/AT_PARALLEL_NATIVE_TBB to ATen/Config.h
ad91a3a11f,caffe2,Skipping L2 regularization on sparse biases
1f027ac02d,skip,Disable testTHCAllocator on HIP (#39843)
f33c31eace,skip,"Separate ""configuration"" properties in TensorIterator (#39789)"
4c7d81f847,skip,Add documentation for properties in TensorIterator. (#39792)
7957d83498,skip,[ONNX] Export linspace (#39403)
2b29feace4,jit,[TensorExpr] Fix IRPrinter for function calls with uniqued names (#39753)
7a792879f2,skip,Prevent clobbering of docker images by parallelnative/paralleltbb builds (#39863)
01986e9890,caffe2,Wait for all op types in SimpleNet (#39493)
85f1f67f33,skip,Wrap Caffe2 (RowWise)SparseAdagrad fusion operator as a PT op (#38704)
91d539097b,onnx,[ONNX] Fix regression disabling checker (#39073)
8893c0670d,skip,Revert D21511611: Wrap Caffe2 (RowWise)SparseAdagrad fusion operator as a PT op
32bf63890b,skip,Revert D21992267: [pytorch][PR] [ONNX] Export linspace
ae3567427f,skip,.circleci: Remove upload_binary_sizes job (#39786)
0b90b9cdd3,bug_fixes_frontend,Allow shuffle when auto-batching disabled in DataLoader (#39865)
9ca7fdcef0,skip,Attempt to fix macos ci by pinning numba (#39875)
b5848833f0,bug_fixes_frontend,Add runtime check for MSVC redist (#39841)
e22dd561ad,complex_frontend,Migrate pow kernel to c10::complex (#39286)
eace053398,improvements_frontend,Move all torch.nn.modules type annotations inline (#38211)
36501ff5d9,mobile,"[vulkan] VulkanTensor, add strides in interface (#39077)"
63dc1363e6,jit,[TensorExpr] Eliminate Cond statements when each branch is a different kind of empty (#39754)
8c8d9f8971,skip,Move pip install after setting up VS environment (#39898)
f59e38974a,bug_fixes_frontend,fix multinomial for empty batch (#39873)
0aa70039f9,skip,Delete redundant device/dtype in TensorIterator add_input/add_output (#39798)
bdecedd2d7,jit,[JIT] use python type resolver for all types (#39880)
bbf364b0c1,mobile,move basic math ops to lite interpreter (#39861)
a92231b70e,complex_frontend,Typo in Dispatch.h (#39882)
b10c53e9b8,performance_frontend,Vectorize on output for reduction kernels (#37206)
2cd27be5b5,skip,Fix CUDA device guard usage when first arg of kernel is scalar (#39870)
14e841c292,quantization,[quant][graphmode] Remove dedup pass (#39825)
2854811ab8,jit,[JIT] Allow self-referential annotations in classes (#39821)
80e5ebf989,jit,[nvFuser] Transform replay refactor and minor updates (#39579)
71372b452a,mobile,[vulkan] addmm support non-vulkan inputs (#39078)
0526af1af6,mobile,[vulkan] Conv2d with optional clamp (#39115)
c068233300,jit,Add CHECK-SOURCE-HIGHLIGHTED to file check utils. (#39692)
246d7bb41d,quantization,[quant][graphmode] Quantizing traced modules (#39826)
52cc0c2c37,skip,Revert D22011184: [pytorch][PR] Fix CUDA device guard usage when first arg of kernel is scalar
ae6a68ad09,rpc,[TensorPipe] Add extensive logging (#39781)
3876889218,complex_frontend,Remove LegacyComplex.h (#39834)
004aa089a6,jit,[jit][subgraph_rewriter] Support list of filters (#39867)
124cdf2290,new_features_frontend,Add experimental deterministic flag (#38683)
4574abc395,skip,Replace __host__ __device__ with C10_HOST_DEVICE in THCIntegerDivider.cuh (#39797)
48678aa39f,skip,pin ninja version to fix windows CI (#39944)
2bab9149cc,caffe2,Extend int8 quantize op to take scale and zero point from input
d367f575b9,mobile,[CI][vulkan] android build abi x86 with USE_VULKAN (#39912)
baa604812c,bug_fixes_frontend,add optional request headers to torch.hub (#39740)
f3f9415f81,improvements_frontend,Add file_name argument to load_state_dict_from_url (#39749)
1e05e5e0ae,caffe2,Correct #39759 for HIP. (#39801)
99084104b6,quantization,[quant][graphmode][refactor] isScalar check (#39892)
558c20f50a,caffe2,Int8 PTQ ops for online training (#39818)
fdf6d37895,memory_format_frontend,re-enable some corner cases in memory format transpose test (#39891)
0d19ae5a14,skip,[pytorch] fix (ProfiledType|TraceType)None.cpp (#39934)
a9aa6367c2,skip,[futures] Add torch.futures.collect_all()/wait_all() python api. (#39790)
14099374bd,rpc,Update TensorPipe submodule (#39945)
8bc821f0d0,skip,Revert D21976891: [futures] Add torch.futures.collect_all()/wait_all() python api.
8749aaca83,skip,Abort setup_pytorch_env.bat if one of the steps failed (#39951)
b2620722c3,skip,"Kill meanall from TH, THC (#39907)"
727e77a809,quantization,[quant] Enable reduce_range for graphmode (#39874)
d9539cd835,bc_breaking_frontend,[testing] Dont use zipfile for storage __reduce__ (#39893)
356d564886,rpc,[rpc] use annotation_str for RRef type serialization (#39932)
34d1098dc2,rpc,[rpc] fix RRef alias annotation (#39933)
e62d655744,skip,[Reland] Include AT_PARALLEL_OPENMP/AT_PARALLEL_NATIVE/AT_PARALLEL_NATIVE_TBB to ATen/Config.h (#39881)
db2b273d1f,bug_fixes_frontend,Reland: Fix CUDA device guard usage when first arg of kernel is scalar (#39956)
8d3fcb43cf,skip,Revert D22008317: [Reland] Include AT_PARALLEL_OPENMP/AT_PARALLEL_NATIVE/AT_PARALLEL_NATIVE_TBB to ATen/Config.h
ddd45ae919,caffe2,Extend int8 FC op to take scale and zero point from input
bdef721caf,mobile,[fbcode] Add find_method into lite interpreter python binding.
e2825392b6,skip,Update torchvision commit from Mar 11 to Jun 11 2020 (#39970)
905c6730b7,skip,Adding /FS for NVCC if /Zi is used (#39994)
b803b4ce09,rpc,"[torch.distributed.rpc] Add stringify WorkerInfo, better error message for py_rref (#39974)"
f1d10978a4,caffe2,Added Mean and Variance calculation function. (#39986)
8072f0685f,caffe2,Add zero input support for batch permutation op (#39851)
d5236f8517,distributed,Avoid initializing unnecessary tensors in nccl.reduce (#39688)
5b194b0fb2,complex_frontend,Remove thrust::complex from reciprocal (#39899)
4947ee3811,complex_frontend,Kill thrust::complex from log kernels (#39902)
ede9bc97c3,amd,Fix the processing logic of bernoulli on amd (#40001)
cf64af1ad2,complex_frontend,Revert D22036002: [pytorch][PR] Kill thrust::complex from log kernels
541814f2b7,skip,Remove dead ScatterGather code (#39963)
c8c53c802e,improvements_frontend,Add `generator=` kwarg for DataLoader & random samplers (#39737)
c6b69a4e4d,bc_breaking_frontend,Delete Python <= 3.5 specific checks from the code (#39879)
ac8d63a52f,amd,Update jenkins caffe2 scripts for ROCm circleci images. (#39908)
1d642e2adf,improvements_frontend,Improve cuda error message for MSVC (#39987)
019eeb3183,bug_fixes_frontend,Kill DataLoader worker when we can't join (#39869)
569c85b45d,rpc,"[futures] Add assert to Future constValue() accessor, add hasValue(). (#39950)"
42f0ea49ca,skip,[Codemod][GleanFbcode] Remove dead includes in caffe2/binaries
79450edad3,jit,[JIT] IRParser: properly parse negative numbers. (#39981)
4c3436838f,dispatcher,Show which type was the wrong one when a signature is invalid (#39491)
f6b0fbe2c5,caffe2,topk tensor k support (#39407)
cc3fc786b7,bug_fixes_frontend,"[resubmit] [pytorch][PR] Fix for num_threads==1 in OpenMP ""parallel for"" (#39533)"
0c25428597,rpc,[futures] Reland: Add torch.futures.collect_all()/wait_all() python api. (#39964)
51e341df4f,skip,[bernoulli_kernel] Replace CPU_tensor_apply functions with cpu_serial_kernel (#39711)
ecfe0c9a25,rpc,[TensorPipe] Use registry for transports and channels (#39957)
d602950cb4,rpc,[torch.distributed.rpc] Add WorkerInfo python repr magic method (#40004)
84d8a42fdb,mobile,[android] Remove android fbjni subproject (#39691)
eb358f49c2,complex_frontend,Overload complex math functions on both :: and std:: (#39829)
f37b8e73f4,quantization,[quant][graphmode] Support prim:TupleUnpack and prim::TupleConstruct (#39895)
00651b8c93,distributed,[distribtued.nn] Implement TorchScript-compatible RemoteModule API (#37139)
f13be5fde1,distributions,Check if generator has next normal sample cache methods in normal_distribution (#39816)
d4faf14cb2,skip,[Yet Another Reland] Include AT_PARALLEL_OPENMP/AT_PARALLEL_NATIVE/AT_PARALLEL_NATIVE_TBB to ATen/Config.h (#40045)
399dd84c8c,rpc,Fix TensorPipeAgent shutdown to ensure it drains all outstanding work. (#40060)
5d4a662846,bug_fixes_frontend,DNNL: fix F.max_pool2d and F.avg_pool2 issue when stride=None (#39221)
1a388da10a,quantization,[quant] add quantized::batch_norm (#39910)
18fe9d267c,skip,Revert D22050656: [Yet Another Reland] Include AT_PARALLEL_OPENMP/AT_PARALLEL_NATIVE/AT_PARALLEL_NATIVE_TBB to ATen/Config.h
f0b40cac30,skip,[pytorch] simplify android circleci definition data model
9204d76b5f,skip,"Back out ""[pytorch][PR] Remove `THTensor_(fill)` & `THTensor_(zero)`"""
bcb44796ba,mobile,[pytorch] consolidate android gradle build scripts (#39999)
655f1ea176,skip,Refactor LSTM tests (#38851)
144e8dc5a3,quantization,[quant][graphmode] Use quantizedbatch_norm in graph mode (#39911)
12cb80b5b8,dispatcher,TORCH_FN (#39823)
8939849f72,dispatcher,Revert D21986243: TORCH_FN
ebd869153c,skip,Clarifies compare_with_numpy behavior (#40064)
ee5ad6ce25,quantization,[quant][graphmode] Pass debug option into insert_quant_dequant pass (#39915)
23db54acdf,improvements_frontend,[DataLoader] add repr for WorkerInfo (#39975)
d71804a57d,skip,Eliminate TensorIterator::add_output with explicit dtype. (#39800)
c065049592,skip,Add smoke test to Windows CI (#39941)
2beb9690c3,skip,Change AccumulateGrad to yield `.grad`s that match weights' memory layout (#34904)
48db06e39a,skip,"Dynamic quantization support for LSTMCell, RNNCell and GRUCell (#37159)"
12cf8390e6,docs_frontend,Update aarch64 CI badge (#39914)
305921734a,quantization,Revert D22013026: [quant][graphmode] Pass debug option into insert_quant_dequant pass
b372000d69,quantization,[quant][graphmode] Run RemoveRedundantDequantize in the end (#39923)
5f6e55fb32,complex_frontend,Clean up thrust::complex from tanh_backward (#39827)
e55e0cb1a9,skip,"Revert D20978736: Dynamic quantization support for LSTMCell, RNNCell and GRUCell"
5add2e861c,skip,Revert D21628596: Refactor LSTM tests
ad86c94f14,bug_fixes_frontend,Reduce memory requirement for test_argminmax_large_axis (#40036)
33b82c7271,jit,[JIT] Add registry for backend lowering functions (#39552)
56b4b44107,skip,Batching rule for torch.mul (#39859)
dd581b4512,rpc,DOC: fix rpc reference in top-level index (#40077)
5843854e66,rpc,[TensorPipe] Fix transport/channel priorities (#40090)
4b5530de72,performance_frontend,optimize upsample performance linear mode on CPU (#34864)
f1e575a0bf,skip,Revert D20496044: [pytorch][PR] Change AccumulateGrad to yield `.grad`s that match weights' memory layout
b3dd4d9c33,jit,[JIT] remove callable check to compile objects with __call__ (#40041)
f1a5f66115,skip,[xplat] Add Windows specific ATen build definitions (#40092)
181ea1acce,quantization,[quant][graphmode] Support squeeze/unsqueeze (#39924)
d57ca73c53,complex_frontend,Remove item and data_ptr for std::complex (#39838)
49732f0450,skip,Remove global CMAKE_INSTALL_RPATH_USE_LINK_PATH directive (#37737)
ec1833bc3c,quantization,Revert D22069566: Revert D22013026: [quant][graphmode] Pass debug option into insert_quant_dequant pass
7f270233fb,misc,Upgrade DNNL to 1.5 (#40088)
7021635d61,jit,fix more duplicated names (#40062)
145df306ae,distributed,Avoid using default process group in ProcessGroupAgent. (#39909)
ee365c58e1,bug_fixes_frontend,Fix destructor ordering for cuda handle pools (#39345)
461aa8a1e2,quantization,[quant][graphmode] Support quantizing `repeat` (#39925)
ddeaa74382,quantization,[quant][graphmode] Refactor dynamic quant tests (#40039)
fa4244d783,quantization,[quant][graphmode] Test JIT tracing for dynamic quant cases (#40040)
41fa4bef2a,quantization,[quant] Support general op modules with inplace options (#39919)
f69b72c738,dispatcher,"Back out ""Revert D21986243: TORCH_FN"" (#40110)"
da8cd8260b,onnx,Fix KeypointRCNN test (#39589)
54c0ee1ebc,caffe2,LayerNorm use Fused Multiply and Add (#40012)
ba98c0e38c,bc_breaking_frontend,Split TensorIteratorConfig out of TensorIterator (#39803)
64689c2474,caffe2,Remove unecessary copy within blob serialization (#40096)
cb1a1942ee,quantization,Revert D22071277: [quant][graphmode] Test JIT tracing for dynamic quant cases
b5d54db6f4,quantization,Revert D22071278: [quant][graphmode] Refactor dynamic quant tests
3d8de74e17,misc,Bumps readable file format version for torch.full inferring float from int values (#40089)
15758bca55,quantization,"Refactor LSTM tests, [Remove randomness in weights] (#40101)"
dcec099d48,misc,Wrap Caffe2 (RowWise)SparseAdagrad fusion operator as a PT op (#39904)
f42c948df5,quantization,[quant][graphmode] Support another use pattern of mean (#40038)
bf544c4a7b,mobile,[android][fbjni] Test_app and Readme update with the recent fbjni dep state (#40058)
23739654cd,skip,Resubmit Remove `THTensor_(fill)` & `THTensor_(zero)` (#40108)
15823ac6d5,distributed,Enhance DDP docstrings for DDP + RPC support. (#39916)
03529ed14d,jit,Remove hacky double registration of to_here op in reg_distributed_ops (#39602)
3258cb61b1,quantization,"Dynamic quantization support for LSTMCell, RNNCell and GRUCell [Remove randomness in weights] (#40102)"
e7a3a43d8f,skip,[pytorch] upload android build size to scuba (#40010)
00505adbad,caffe2,Add net_pos Tiles added during in-batch broadcast (#40078)
9d588f7ce2,skip,Removes dunder div (#39151)
6de6041585,mobile,[iOS] Disable NNPACK on iOS builds (#39868)
0152baa33a,jit,move some math ops back to full jit (#40149)
44c7a2ab69,rpc,[TensorPipe] Silence some more harmless warnings (#40094)
dea58a7660,amd,[resubmit] Kill thrust::complex from log kernels (#40079)
161fd5f507,skip,Implement tensor.size(int) for BatchedTensor (#40028)
dec62dbfa3,skip,Change VmapTransforms to use SmallVector instead of `vector<int64_t>` (#40042)
8619d26338,skip,Add batching rule for torch.expand (#40097)
216f512be2,mobile,Remove requirement of qnnpack engine for arm build. (#40112)
5200814cfa,skip,Fix test_hook_* issues (#40135)
1ec8ece2b9,skip,[RELAND] Change AccumulateGrad to yield `.grad`s that match weights' memory layout (#40129)
08227fea4f,skip,Revert D22079377: [pytorch][PR] [RELAND] Change AccumulateGrad to yield `.grad`s that match weights' memory layout
c958dd5472,rpc,[TensorPipe] Add guards against transferring GPU tensors (#40167)
a71aefe857,mobile,[android][test_app] cleanup (#40136)
95e51bb7f8,cpp,change BuildExtension.with_options to return a class not a c-tor (#40121)
70192c651c,skip,[Reland #3] Include AT_PARALLEL_OPENMP/AT_PARALLEL_NATIVE/AT_PARALLEL_NATIVE_TBB to ATen/Config.h (#40122)
5e77999ecb,new_features_frontend,Add global hooks to `torch.nn.Module` (#38972)
55bcb5dccc,jit,Fix inconsistent results of string `split` func on JIT mode (#38772)
2ba5f98dd1,skip,Revert D22068657: [pytorch][PR] Remove global CMAKE_INSTALL_RPATH_USE_LINK_PATH directive
f6739ec8e8,quantization,[quant][graphmode] Refactor dynamic quant tests (#40127)
c252dddcdd,quantization,[quant][graphmode] Test JIT tracing for dynamic quant cases (#40128)
1e03d603c6,skip,[JIT] Infer NamedTuple type attributes of nn.Modules correctly (#39116)
b5bf21a6bd,jit,[JIT] Expose `__deepcopy__` on script::Object (#40068)
7f88f037ac,quantization,Stop running target bot on ci-all (#40186)
bc9e8af218,distributed,[distributed.nn] Change remote module template instantiator to write to tmp folder (#40173)
34e28ede57,skip,Fix flaky test (#40175)
f4ffe99da5,rpc,Fix flaky rref timeout test (#40141)
7f0e4265ac,amd,ROCm thunk work-around for future transition to ROCm 3.5.1 (#40181)
1670ea9474,bug_fixes_frontend,"Remove overload of GPU max_pool3d with kernel_width; fix nan, inf in GPU {fractional,adaptive} max_pool{2,3}d (#39903)"
3ea15af630,caffe2,[Onnxifi] Allow adding timeout for OnnxifOp run (#40081)
a2ef54c598,mobile,[pytorch] fix CUDA_KERNEL_ASSERT macro for android build (#40151)
e34e32850e,skip,Revert D22076711: [Reland #3] Include AT_PARALLEL_OPENMP/AT_PARALLEL_NATIVE/AT_PARALLEL_NATIVE_TBB to ATen/Config.h
27d789500b,jit,[test] split tracer related tests out of test_jit (#40142)
693ab77c00,jit,[test] split onnx export test out of test_jit (#40143)
74142f76fa,rpc,Adding torch.futures to API docs (#40051)
30364f0b01,distributed,Remove obsolete warning message from DDP (#40190)
0b3755b1d0,mobile,Add optimization blacklist as second arg to optimizeForMobile method. (#37462)
1800032712,quantization,[quant][graphmode] Add warning for prim::Loop (#40195)
fb02007e9f,caffe2,Export box_cox operator in caffe2
edd3fbc61e,quantization,Add aarch64 specific quantize_tensor using arm intrinsics. (#40113)
efd9fc7434,complex_frontend,Remove thrust::complex from sqrt (#39901)
76fbfba644,bug_fixes_frontend,Move _dummy_type to _utils.py (#40177)
fd7e09a52b,quantization,[quant][graphmode] Clean up and add more logging (#40196)
4553b0b537,skip,Reduce number of Window test configurations (#38482)
d1a0e88075,skip,Ensure NCCL_BLOCKING_WAIT=1 works for dist.barrier() (#40207)
7c9e78fdf5,rpc,"[TensorPipe] Add options for agent, including backend killswitches (#40162)"
f3f30d4354,rpc,[JIT x RPC] Consolidate RRef type class and RRef impl class (#35694)
5f309505ce,quantization,Move the check on orig_weight sizes. (#40200)
d4e4f13173,quantization,[quant][graphmode] Add support for detach (#40197)
4ad8ebe738,quantization,quant layer/group/instance norm: make weights and biases optional (#39203)
37362fff66,quantization,graph mode: util for fusion of functions which require observation (#39413)
fcc9a1e664,quantization,graph mode: move hardsigmoid op to `single_input_general_value` category (#40055)
fef253e711,skip,[codemod][custom_rule] Migrate some scripts to use named outputs for custom_rule
aa84ec5325,quantization,[quant][api] Expose graph mode quantization API in `torch.quantization` (#40198)
6a42d85fc6,skip,.circleci: Move docker_build workflow to codegen (#40189)
645d6c014c,performance_frontend,preserve output tensor's stride in TI's fast setup (#38895)
034eddca01,rpc,Fix typos in RPC Docs (#40219)
74a2cb87e3,mobile,[android][cmake] Remove NO_EXPORT for libtorch mobile build (#39584)
30648985a7,distributed,Revert D22108899: Ensure NCCL_BLOCKING_WAIT=1 works for dist.barrier()
442ec1dd4e,quantization,[test] split remaining quantization tests out of test_jit (#40144)
83d7718c5c,skip,.circleci: Add docker builds based on rev-parse (#40194)
d3b786afdb,mobile,[android] Add libtorch headers to pytorch_android aar (#39507)
0891764e80,mobile,[android] ANDROID_STL=c++_shared (#39588)
d14d47b9b5,jit,Get rid of global constructors in cuda codegen (#40183)
55cdd31bd0,skip,Assert that kernels are called with the right signature (#38361)
85128113f9,mobile,[Selective build] Enable selective build in VariablType
cb8b2f0636,skip,Revert D21534052: Assert that kernels are called with the right signature
430d5cec0e,caffe2,print position of the operator that failed to onnxifi (#40232)
89ef8f8141,amd,add test_openmp to ROCM_BLACKLIST (#40204)
41f2dbde31,cpp,Add `AdamW` to C++ frontend (#40009)
c1958de49d,skip,[Codemod][FBSourceGoogleJavaFormatLinter] Daily `arc lint --take GOOGLEJAVAFORMAT`
8b5732e8ad,improvements_frontend,Move `torch.cuda` annotations inline (#40075)
35f357927d,rpc,[futures] Add specific python unittest coverage for collect_all/wait_all (#40233)
954a59a2f5,complex_frontend,Add at::tensor(complex) and torch::tensor(complex) overload (#39793)
52a2adb3f4,skip,[android] test_app example linking to pytorch_android aar content (#39587)
262ad8e6ab,skip,[android] gradle version update (#40176)
9788a74da8,quantization,[quant][bug] Fix histogram observer with 0 input (#40191)
8c73e74fdf,complex_frontend,Clean up thrust::complex usage in geometric kernels (#39293)
d58b8222b7,jit,[JIT] Add support for with statements (#34705)
7e82382ad5,rpc,Allow profiler to be enabled remotely with RPC (#38748)
13bd5992d0,distributed,Remove `finalize_bucket_sparse` from DDP (#40130)
8f51c39649,rpc,Improve torch.futures docs (#40245)
a6420b8c75,skip,Increase bazel test timeout to 8 minutes (#40263)
ccea3726da,misc,[Reland #4] Include AT_PARALLEL_OPENMP/AT_PARALLEL_NATIVE/AT_PARALLEL_NATIVE_TBB to ATen/Config.h (#40211)
6e2c88980e,skip,.circleci: Add git to the ecr gc docker images (#40262)
02e091902f,rpc,Release DistAutogradContainer context for each dist_autograd test case (#38711)
86b1afa039,dispatcher,Assert that kernels are called with the right signature (#40251)
8315bb2359,skip,"Back out ""[pytorch][PR] [JIT] Infer NamedTuple type attributes of nn.Modules correctly"" (#40270)"
2393bab036,rpc,[TensorPipe] Update documentation (#40222)
b7bfdcbe3e,distributed,[caffe2/torch] Use logger in jit instantiator
b0324a97f5,quantization,_jit_pass_fold_convbn wrapped with fuse_conv_bn_script (#40224)
a11870b45d,skip,Revert D22118971: [android] gradle version update
ece8ef2fc6,mobile,Run canonical graph optimizations in optimize_for_mobile. (#38840)
96057c0080,bc_breaking_frontend,Fix missing deprecation warning for Tensor.nonzero(). (#40187)
07e581d639,caffe2,Remove useless name check for inputs (#4618)
d9c804ce22,quantization,[PyTorch Numeric Suite] Add support for dynamic quantization of linear module (#39024)
52e4e3a9b8,distributed,NCCL Comment typo fix (#40242)
b670ff2d3a,improvements_frontend,Add typing for _CudaStreamBase and _CudaEventBase classes (#40256)
3684dfafc2,rpc,Fix typos in RPC examples (#40280)
465138ec39,quantization,refactoring TestQuantizeScript (#39677)
cdbf78fba0,skip,Revert D22118945: [android] test_app example linking to pytorch_android aar content
ca0540a7eb,rpc,Remove variable shadowing from tensorpipe lambda (#39126)
b48742322a,amd,move ROCm 3.5 thunk upgrade from build.sh into test.sh (#40286)
c3ce35e67b,rpc,Update TensorPipe submodule
65f67bbe92,caffe2,improvements to sls 4bit
41865d8f19,onnx,[ONNX] Update black_listed_operators for opset 12 (#39414)
73a156e81f,onnx,[ONNX] Update pytorch/onnx docs for new export API args (#39802)
c73095e78f,bc_breaking_frontend,Add note to serialization docs about zipfile format (#40288)
6df97c20c2,skip,Make test case precision property (#40057)
f92089b8ca,skip,[pytorch] tweak code analyzer script to handle new namespaces (#40276)
4463f59c2c,rpc,Let torch.futures.wait_all re-throw errors (#40291)
3ca05500fa,rpc,Improve RPC documents (#40296)
d6d579397d,rpc,Improve docs for init_rpc (#40298)
caf0c286b8,rpc,Fix RPC API doc links (#40299)
a9f0156271,rpc,Fix RRef to_here() docs (#40300)
5d0044389a,rpc,Minor RPC doc improvements (#40305)
314d645e05,rpc,Add a warning to mention that async_execution does not work with autograd profiler (#40309)
a80dd02a22,distributed,[Resubmit] Ensure NCCL_BLOCKING_WAIT=1 works for dist.barrier() (#40249)
4194456158,profiler,Add _enable_record_function python API (#40306)
fb17b05f33,performance_frontend,Make dynamic casting case also benefit from unrolling (#34749)
6d70d1574f,caffe2,rename the LayerNorm operator and add it to the replacement map (#40318)
b2f489dc57,quantization,[quant][graphmode] Rename graph mode quantization API to `quantize_jit` (#40212)
5555d210b1,complex_frontend,Cleanup TensorIteratorDynamicCasting.h (#39839)
4f761f325c,skip,"Back out ""[pytorch][PR] Removes dunder div"""
4b028a8e07,jit,[jit] support pad_sequence/pack_sequence (#39844)
5c133eb2db,cpp,fix small typo in optim adamw (#40283)
cfe1c6ef9e,skip,Update XLAPreAutograd keys. (#40265)
7a837019a4,caffe2,[caffe2] optimize 2/4-bit row-wise quantization (#387)
59ca1d31ca,quantization,[quant][graphmode] docstrings for top level APIs (#40328)
e04a611b91,quantization,[quant][graphmode] clang format changes (#40329)
9da277c635,quantization,[quant][graphmodel] linear_relu (#40021)
0079e429d6,quantization,Remove incorrect warning message on rounding mode (#40301)
4cbf87dc92,quantization,[PyTorch Numeric Suite] Add support for dynamic LSTM (#40065)
c1dfc05cc9,mobile,[android][test_app][reland] test_app example linking to pytorch_android aar content (#40313)
a47fb57957,bc_breaking_frontend,Change memory format promotion rules of point wise operators. (#37968)
f69460d0cb,distributed,Add unit test to verify DDP + RPC correctness. (#40139)
3852215170,mobile,[vulkan] jit passes for vulkan conv2 prepack and fuse with clamp (#39282)
ac8c3c0ad1,skip,Fix update_s3_html for nightly jobs (#40338)
e632bf8d57,rpc,Add thrift and tensorpipe backend tests for test_ddp_under_dist_autograd. (#40210)
3bbedb34b9,bug_fixes_frontend,restore generic IndexToScatterGatherOffset specialization (#40349)
13d54c6471,quantization,quantized elu: require observation (#40100)
03ed802a90,quantization,quantized elu: eager mode static handling (#40103)
cd0afe2b8e,quantization,quantized elu: eager mode QAT handling (#40104)
c6dbfcaf9e,quantization,quantized elu: graph mode handling (#40111)
ab8a99bd36,quantization,graph mode: add hardswish inplace handling (#40284)
37c88a4731,skip,Pin the version of scipy for Windows test jobs (#40369)
eb92ed6239,skip,Append forward slashes to PIP_UPLOAD_FOLDER (#40352)
881c1adfcd,bug_fixes_frontend,Fixed buffer update in BatchNorm when track_running_stats is set to False (#38084)
396087bfd8,amd,"[ROCm] Enable BFloat16 for pow, exp, erf ops on ROCm (#40236)"
db5b273961,skip,Rename dont_resize_outputs() to resize_outputs(false) (TensorIterator… (#40148)
52f3a09663,amd,ROCm: Use correct device type when exporting tensors to DLPack (#40124)
e4766fb4d9,skip,"Meta tensors, but without code deduplication (#38490)"
0e146d2df4,rpc,Update TensorPipe submodule (#40374)
766889b6bf,onnx,ONNX: fix bug in export of ops involving torch.bool type (#40006)
c04d39aaf2,quantization,[quant][bug] Histogram observer bug fix with min == max (#40310)
3fa0b1e325,onnx,ONNX: fix bug in export of cumsum operator (#40044)
49887d1fc0,caffe2,reference Swish implementation (#40150)
eaa91071ca,onnx,[ONNX] Support large attribute and subgraph for large model (#38793)
9f9e7c1d71,quantization,[quant][refactor] Tests for torch.jit.quantized (#40330)
3894de569e,skip,Reenable memory format test for some unary functions (#39102)
c72ab19458,complex_frontend,Add addmv for complex dtypes (#40238)
17d3f74ea3,memory_format_frontend,Relax cudnn conditions for channels-last convolutions (#38904)
14f7e95c1a,rpc,Add prefix of remote events for RPC profiling (#40066)
87c5f02f3d,quantization,jit: Conv3d + BatchNorm3d fusion (#40082)
03af4dcbbf,performance_frontend,Utilise the vector version for sinh and cosh (UnaryOpsKernel) (#36396)
6ba807cb43,skip,DNNL: enable conv3d (#35662)
8df35fd755,skip,DNNL: enable batchnorm3d (#35663)
c873895722,skip,DNNL: enable max_pool3d and avg_pool3d (#35664)
43331609a4,th_aten_frontend,"Port addmm, addbmm, addr to ATen (CUDA) (#38421)"
dbcc5b7533,skip,DNNL: enable dilation conv (#40220)
a8ab78c815,docs_frontend,Added a link to Contribution guide in Readme (#40353)
02ae9a1583,bug_fixes_frontend,add TypeError to c10 and fix segfault in error checking in Tensor constructor (#40106)
c4fc278fa8,skip,Build docker for CUDA11 (#40231)
7a3c223bbb,th_aten_frontend,Migrate `var` & `std` to ATen (#39967)
8ec2ae9a9f,complex_frontend,"Add view_as_real, view_as_complex for complex tensors (#39099)"
9498e24ca8,skip,Revert D22138737: DNNL: enable dilation conv
13a8ec3cc5,skip,Revert D22102406: DNNL: enable max_pool3d and avg_pool3d
0d0608532c,skip,[JIT] Fork/Join inline docs (#39952)
17fe0e2b8a,skip,Revert D22102407: DNNL: enable batchnorm3d
016cf7d66e,skip,Revert D22102408: DNNL: enable conv3d
ae2f1f0372,distributed,[DDP Note] Remove refs to RoundRobin PG until we officially support it (#40380)
9e5d62582c,mobile,[android][gradle] packaging headers in aars for publishing (#40392)
8066fba226,bc_breaking_frontend,[RELAND2] Change AccumulateGrad to yield `.grad`s that match weights' memory layout (#40358)
d7d75e37bb,quantization,Add state dict for LSTM and RNNCell and helper functions for accessing weights and bias (#40333)
b02c932fb6,quantization,qat eager: remove unneeded modules (#40396)
64f925eb0c,quantization,[quant][graphmode] Add support for functional linear (#40331)
0d24ed0c81,docs_frontend,Add note to torch.save (#40394)
5766da503b,bug_fixes_frontend,"Device name should be a string, not bytes (#40322)"
18122facb9,quantization,[quant][graphmode] Add warning for debug option for add_scalar/mul_scalar (#40383)
7bf1dd582a,bug_fixes_frontend,Fix Cuda IPC deadlock (#40347)
6c40ec55df,skip,Revert D22165477: [pytorch][PR] [JIT] Fork/Join inline docs
ba89a89376,quantization,[quant][graphmode][refactor] InsertQuantDeQuantHelper (#40384)
e9efad6878,amd,[ROCM][CI] Skip fp16 bench and 2-GPU runs (#40243)
78b3d5f878,rpc,[TensorPipe] Register multiplexing channel over UV (#40389)
1ec4337b7d,skip,Use Int8QuantParamsBlob to pass the scale and zeropoint params (#40390)
08ae7d3a71,skip,[Codemod][FBSourceGoogleJavaFormatLinter] Daily `arc lint --take GOOGLEJAVAFORMAT`
2acee6dc93,skip,Revert D22124313: Use Int8QuantParamsBlob to pass the scale and zeropoint params
e509c58a1c,build_frontend,Set C++14 compatibility flag in torch_compile_options (#40399)
54c05fa34e,rpc,Add basic GPU support to distributed autograd. (#40312)
3e6fa778a5,cpp,Testcppextensionjit rebuild once (#40169)
79736ff9c2,complex_frontend,Simplify complex case for `div_cpu` (#39996)
c4594a97ae,quantization,quant docs: clean up hardswish (#40323)
8e74fb6a0c,quantization,quant docs: add and clean up hardsigmoid (#40340)
d27f8eaf92,quantization,quant docs: add and clean up hardtanh (#40341)
d15fcc7e49,quantization,quant docs: add and clean up LayerNorm (#40342)
6e3fdd77ca,quantization,quant docs: add and clean up GroupNorm (#40343)
5e683517a7,quantization,quant docs: add and clean up InstanceNorm{n}d (#40345)
d71ec51c0e,quantization,quant docs: add and clean up BatchNorm{n}d (#40346)
9bf255573f,quantization,quant docs: add and clean up ELU (#40377)
f652abc1dd,jit,[jit] Enable `copy.deepcopy` and `copy.copy` for RecursiveScriptModule (#32685)
3b040c478a,improvements_frontend,Make custom_fwd a no-op when not executed under autocast (#36171)
a54bb4e907,profiler,Fix demangle 't' issue in profiler (#40416)
d8c384544e,profiler,Destroy CUDA events after profiling (#39962)
b82bd654cc,profiler,Increase shapes column length (#40440)
27982d5711,caffe2,fixes to layernorm emulation (#40422)
6a421d50ab,memory_format_frontend,Enabling concat fast path for channels last inputs (#39448)
4269b9a8fc,skip,.circleci: Fix backup uploads
bc8760b3db,skip,.circleci: Fix pip installation of awscli
168cddf5f1,skip,.circleci: Fix upload to backup directory
2dc0b84aca,skip,Skip test_mem_leak on Windows (#40498)
bb848df10b,rpc,[1.6] Remove table of contents at the top of rpc.rst (#40482)
0dc93ac119,rpc,[v1.6.0 patch] Install method docstrings from PyRRef to RRef (#40620)
b0cce716f7,quantization,Add beta warning for quant docs (#40540)
4cc605e80a,docs_frontend,(1.6) Update docs feature classifications (#40539)
8682ac147b,docs_frontend,Docs merge (#40569)
44f79651a7,skip,Tweak `file_diff_from_base` for release/1.6 branch (#40712)
6d85b2c989,skip,Pin XLA CI to use r1.6 release branch. (#40721)
ea1b0dba18,skip,Remove constexpr for NVCC on Windows (#40676)
bdfcbfa18c,skip,[release/1.6] .jenkins: Install torch from test channel (#40706)
a9996bb482,caffe2,Fixes caffe2 loading issues on Windows (#39513) (#40487)
fe45c2c986,jit,Allow slicing sequential container (#40538)
c5bd737f0c,jit,[JIT] script if tracing fix (#40468) (#40572)
f993e5ac88,rpc,[1.6] Update TensorPipe submodule (#40634)
4316199832,rpc,Add examples and tests for combining static/class method with async execution (#40619) (#40688)
0c90b6da5c,jit,[1.6 cherrypick] Fix zip serialization for file > 2GiB (#40757)
dede34eab7,complex_frontend,[1.6 cherrypick] Doc fix for complex views
75a074abdc,bc_breaking_frontend,1.6 Port: Dynamic Versioning (#40542)
eaf7dad5d6,bc_breaking_frontend,[1.6 cherrypick] Support Pathlike for zipfile serialization (#40793)
415e499330,bug_fixes_frontend,Fix zip serialization for file > 2GiB for Windows (#40852)
bf4d905ea1,bug_fixes_frontend,Fix wrong MSVC version constraint for CUDA 9.2 (#40794) (#40849)
091537a764,jit,[JIT][1.6] Shape analysis fixes. (#40716)
ddea6c552f,bc_breaking_frontend,Ports full dtype inference deprecation to 1.6 (#40799)
31d9776c04,docs_frontend,[1.6] fix autograd doc subsubsection display issue (#40796)
41816dc97f,jit,[1.6] Fix dictConstruct ordering and enable dict mix (#40797)
b4b8f5b9d4,distributed,Release GIL during DDP construction. (#40877)
c5c8a85a82,cpp,"If ninja is being used, force build_ext to run. (#40881)"
2533b9da83,complex_frontend,Fix complex printing for sci_mode=True (#40513) (#40919)
4dd37bfbf7,jit,[jit] Remove unnecessary clone APIs for script::Module and RecursiveScriptModule (#40297) (#40748)
ea273c68f9,jit,Inplace construct of TorchScript Module and inplace option for quantization (#40750)
e89c4f0dec,quantization,[quant] Fix fuse linear pass (#40549) (#40751)
9184c9832e,Uncategorized,Re-apply PyTorch pthreadpool changes (#40951)
b44b1d868e,Uncategorized,Update psimd to psimd:072586a71b55b7f8c584153d223e95687148a900 (#40953)
d53427c541,Uncategorized,Update FXdiv to FXdiv:b408327ac2a15ec3e43352421954f5b1967701d1. (#40954)
0ffdd5aa1d,Uncategorized,Update cpuinfo to cpuinfo:63b254577ed77a8004a9be6ac707f3dccc4e1fd9. (#40955)
8c3f662224,Uncategorized,Update FP16 to FP16:4dfe081cf6bcd15db339cf2680b9281b8451eeb3. (#40956)
2b175ba909,Uncategorized,update requires_gard on loop inputs correctly (master) (#40926) (#41014)
63a94c021a,Uncategorized,shape inference of undefined for prim::grad (#40866) (#41015)
3f13c9a2c8,Uncategorized,infer tensor properties based on an input tensor rather than defaults for xxx_like ctors (#40895) (#41016)
01e9562313,Uncategorized,[1.6 cherrypick] Fix delegating to jit.load from torch.load (#41013)
11b70b0041,Uncategorized,[JIT] Switch executor from Simple to Legacy. (#41017)
f0f0cbdd4a,Uncategorized,Docstring changes for dynamic quantized classes (#40931) (#41032)
11baccf1b5,Uncategorized,"[release/1.6] .circleci: Output binary sizes, store binaries (#41075)"
c35b4c770b,Uncategorized,Bucket of shape analysis fixes (#41044)
eaf3f2fd34,Uncategorized,Added index_put to promotelist (#41036)
6220cc4380,Uncategorized,[quant][graphmode][fix] dequantize propagation for {add/mul}_scalar + aten::repeat (#40933)
0406b69b79,Uncategorized,[quant][graphmode][fix] Fold conv bn (#40865) (#40970)
d0045e5520,Uncategorized,Some fixes for graph mode quantization (#40935)
a857af50a4,Uncategorized,[quant][graphmode][fix] cloning schema in insert_observers (#40624) (#40934)
2ed3ad2891,Uncategorized,fix autodoc for torch.distributed.launch (#40963) (#41089)
f3c1ea7455,Uncategorized,[PyTorch Numeric Suite] Remove unnecessary Logger in input arguments (#40890) (#41086)
f862a6ba4d,Uncategorized,Remove unused Logger in get_matching_activations (#41023) (#41087)
83262b1ba1,Uncategorized,`torch._six.PY37` should be true for Python-3.8 as well (#40868) (#41091)
af9600b1f5,Uncategorized,[Caffe2] Move in-header virtual function implementation to .cc files (#41090)
77ffb25925,Uncategorized,Add guard for non-default stream in DDP's autograd engine callback (#40115) (#41151)
8f4d01d9f1,Uncategorized,Disables unary op casting to output dtype (#41097) (#41160)
59bb44a8e8,Uncategorized,Add a link in RPC doc page to point to PT Distributed overview (#41108) (#41156)
89d7f194d8,Uncategorized,make IterableDataset DataLoader.__len__ warning clearer (#41183)
e0b7480f34,Uncategorized,"Revert ""make IterableDataset DataLoader.__len__ warning clearer (#41183)"""
c164fc4d7f,Uncategorized,Patch #40883 to 1.6 release. (#41033)
40bf15a8ac,Uncategorized,Remove copy_ warnings for angle and abs for complex tensors (#41152) (#41191)
7fa9b2923b,Uncategorized,quantizer.cpp: fix cuda memory pinning (#41139) (#41194)
c9a1853d2f,Uncategorized,[1.6] Make IterableDataset DataLoader.__len__ warning clearer (#41185)
9409e03903,Uncategorized,[ONNX][1.6] Update interpolate recompute_scale_factor default (#41117)
43d746305c,Uncategorized,Preserve CUDA gencode flags (#41212)
d9e9e0087a,Uncategorized,[v1.6] [RPC docs] Remove mention of TensorPipe's SHM and CMA backends as they're not built (#41229)
cefb9e0cd6,Uncategorized,Update pthreadpool to pthreadpool:029c88620802e1361ccf41d1970bd5b07fd6b7bb. (#40524) (#41190)
